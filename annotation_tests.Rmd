---
title: "annotation_tests"
output: html_document
---

#Testing nonsense canadensis vs pardinus.
##Build the common database (linked through UniProtKb codes)
```{bash}

cd /GRUPOS/grupolince/reference_genomes/lynx_canadensis

awk -F"ID=rna-|;|gene=" '{printf ("%s\t%s\n", $2,$6)}' lc4.NCBI.isoforms | less -S
sort | uniq

paste <(awk '$3=="mRNA"' lc4.NCBI.nr_main.gff3 | sed -e 's/.*ID=rna-\(.*\);Parent.*/\1/') <(awk '$3=="mRNA"' lc4.NCBI.nr_main.gff3 | sed -e 's/.*;gene=\(.*\);model.*/\1/') > lc4.NCBI.nr_main.gene_rna_codes.txt #Both have 19333 lines

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gene_rna_codes.txt /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/all_genes_db
unset SSHPASS

#I uploaded the second column in that file to the UniProt website (https://www.uniprot.org/uploadlists/) to convert gene IDs. I selected "from UniProt Gene names to UniProtKB", inserted Homo sapiens as the species, and submitted the search. Once it finished, I filtered in only the reviewed results, and selected the desired columns (in my case I included my input list as the 7th column).

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
sshpass -e scp /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/all_genes_db/lc4.NCBI.nr_main.gene.uniprot_codes.txt dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/reference_genomes/lynx_canadensis/
unset SSHPASS

cd /GRUPOS/grupolince/ortologous
join -t$'\t' -1 2 -2 2 <(awk -F"\t" '{printf ("%s\t%s\t%s\n", $3,$4,$2)}' HUMAN.1to1_and_multi_orthologs.joined_codes.txt | sort -k2,2 | uniq) <(join -t$'\t' -1 3 -2 2 <(cut -f1,2,7 /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gene.uniprot_codes.txt | tail -n+2 | sort -k3,3) <(sort -k2,2 /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gene_rna.codes.txt) | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\n", $2,$3,$4,$1)}' | sort -k2,2) | awk -F"\t" '{$3=substr($3, 1, length($3)-2); printf ("%s\t%s\t%s\t%s\t%s\n", $2,$1,$3,$5,$6)}' > HUMAN.lc.1to1_and_multi_orthologs.joined_codes.txt

#Obtain list of orthologs with equal number of exons:
cd /GRUPOS/grupolince/ortologous
rm HUMAN.lc.1to1_and_multi_orthologs.joined_codes.same_exon_N.txt
while read -r UNIPROT HUMAN LYPA LYCA OTHER
  do
  EXONS_LYPA=$(grep "$LYPA" /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.gff3 | awk -F"\t" '$3=="CDS" {printf ("%s\t%s\t%s\n", $1,$4-1,$5)}' | wc -l)
  EXONS_LYCA=$(grep "$LYCA" /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gff3 | awk -F"\t" '$3=="CDS" {printf ("%s\t%s\t%s\n", $1,$4-1,$5)}' | wc -l)
  if [ $EXONS_LYPA -eq $EXONS_LYCA ]
    then
    echo -e "$UNIPROT\t$HUMAN\t$LYPA\t$LYCA\t$OTHER" >> HUMAN.lc.1to1_and_multi_orthologs.joined_codes.same_exon_N.txt
  fi
  done < HUMAN.lc.1to1_and_multi_orthologs.joined_codes.txt


```


##Test individual genes one by one:
```{bash}

Examples: 
030336817 & LYPA23C012615
030302033 & LYPA23C013074
030303389 & LYPA23C001864
030296026 & LYPA23C011774
030308933 & LYPA23C007836
030316053 & LYPA23C003045

LC
grep '030316053' /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gff3 | awk -F"\t" '$3=="CDS" {printf ("%s\t%s\t%s\n", $1,$4,$5)}' > /GRUPOS/grupolince/reference_genomes/lynx_canadensis/example.bed

bedtools getfasta -fi /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lr1_based_on_lc4.fa -bed /GRUPOS/grupolince/reference_genomes/lynx_canadensis/example.bed -fo /GRUPOS/grupolince/reference_genomes/lynx_canadensis/example.fa


LP
grep 'LYPA23C003045' /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.gff3 | awk -F"\t" '$3=="CDS" {printf ("%s\t%s\t%s\n", $1,$4,$5)}' > /GRUPOS/grupolince/Lyp_annotation_Apr14_final/example.bed

bedtools getfasta -fi /GRUPOS/grupolince/reference_genomes/lynx_rufus_genome/c_lr_zz_0001_recal1.fa -bed /GRUPOS/grupolince/Lyp_annotation_Apr14_final/example.bed -fo /GRUPOS/grupolince/Lyp_annotation_Apr14_final/example.fa

```

#Retrieve first codon of genes with nonsense mutations:
```{bash}

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov/annotation
grep 'stop_gained' c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov_polarized_filtered6_SNP.lr_ann.vcf | awk -F"\t|\\\\|" '{$14=substr($14, 5, length($14)); printf ("%s\n", $14)}' | sort | uniq > /GRUPOS/grupolince/reference_genomes/lynx_canadensis/annotation_tests/lc_nonsense_genes.txt

cd /GRUPOS/grupolince/reference_genomes/lynx_canadensis/annotation_tests/
rm lc_nonsense_comparison.txt
while read -r gen_lc; do
  grep "$gen_lc" /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gff3 | awk -F"\t" '$3=="CDS" {printf ("%s\t%s\t%s\n", $1,$4-1,$5)}' > ${gen_lc}.bed
  method_lc=$(grep "$gen_lc" /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gff3 | cut -f2 | sort | uniq)
  strand_lc=$(grep "$gen_lc" /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gff3 | cut -f7 | head -n1)
  bedtools getfasta -fi /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lr1_based_on_lc4.fa -bed ${gen_lc}.bed -fo ${gen_lc}.fa
  if [ $strand_lc = "+" ]
    then
    start_lc=$(grep -v '>' ${gen_lc}.fa | head -n1 | cut -c-3)
    seq_lc=$(grep -v '>' ${gen_lc}.fa | tr -d '\n')
    rf_lc=$(grep "$gen_lc" /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gff3 | awk -F"\t" '$3=="CDS" {print}' | cut -f8 | head -n1)
  elif [ $strand_lc = "-" ]
    then
    start_lc=$(grep -v '>' ${gen_lc}.fa | tail -n1 | rev | cut -c-3 | tr ACGT TGCA)
    seq_lc=$(grep -v '>' ${gen_lc}.fa | tr -d '\n' | rev | tr ACGT TGCA)
    rf_lc=$(grep "$gen_lc" /GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.NCBI.nr_main.gff3 | awk -F"\t" '$3=="CDS" {print}' | cut -f8 | tail -n1)
  fi
  unset gen_lp
  gen_lp=$(grep "$gen_lc" /GRUPOS/grupolince/ortologous/HUMAN.lc.1to1_and_multi_orthologs.joined_codes.txt | cut -f3 | sed 's/23A/23C/g' | head -n1)
  echo "lynx canadensis gene is" ${gen_lc} "and lynx pardinus gene is" ${gen_lp}
  if [ -n "$gen_lp" ]
    then
    grep "$gen_lp" /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.gff3 | awk -F"\t" '$3=="CDS" {printf ("%s\t%s\t%s\n", $1,$4-1,$5)}' > ${gen_lp}.bed
    bedtools getfasta -fi /GRUPOS/grupolince/reference_genomes/lynx_rufus_genome/c_lr_zz_0001_recal1.fa -bed ${gen_lp}.bed -fo ${gen_lp}.fa
    method_lp=$(grep "$gen_lp" /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.gff3 | awk -F"\t" '$3=="CDS" {print}' | cut -f2 | sort | uniq)
    strand_lp=$(grep "$gen_lp" /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.gff3 | cut -f7 | head -n1)
    if [ $strand_lp = "+" ]
      then
      start_lp=$(grep -v '>' ${gen_lp}.fa | head -n1 | cut -c-3)
      seq_lp=$(grep -v '>' ${gen_lp}.fa | tr -d '\n')
      rf_lp=$(grep "$gen_lp" /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.gff3 | awk -F"\t" '$3=="CDS" {print}' | cut -f8 | head -n1)
    elif [ $strand_lp = "-" ]
      then
      start_lp=$(grep -v '>' ${gen_lp}.fa | tail -n1 | rev | cut -c-3 | tr ACGT TGCA)
      seq_lp=$(grep -v '>' ${gen_lp}.fa | tr -d '\n' | rev | tr ACGT TGCA)
      rf_lp=$(grep "$gen_lp" /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.gff3 | awk -F"\t" '$3=="CDS" {print}' | cut -f8 | tail -n1)
    fi
    echo -e "$gen_lc\t$gen_lp\t$start_lc\t$start_lp\t$method_lc\t$method_lp\t$rf_lc\t$rf_lp\t$seq_lc\t$seq_lp" >> lc_nonsense_comparison.txt
  fi
  done < lc_nonsense_genes.txt

#Seems like most stop_gained mutations vary between callings due to the definition of the genes (i.e. they occur in regions that are annotated in lc but not in lp), and also part of those due to small calling differences (low AF).

#BUT! Investigate whether 'stop_lost' when lp is the reference (i.e. positions that are truncated in the annotation should be correct when polarised but should yield 'WARNING NO STOP CODON' messages, AND the derived should be annotated as 'stop_lost' in most cases, particularly in Eurasian lynx) are more rare when lc is the reference (they are), and if they become 'stop_gained' in certain Iberian lynx individuals.

#It seems like 'WARNING_NO_STOP_CODON' sites have more HIGH effect mutations than other sites with warnings (proportionally), and these concentrate on Iberian lynx. However, in total Eurasian lynx have more.
grep -v 'WARNING_TRANSCRIPT' c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf | grep -E '#|\\\\|HIGH' | bcftools query -f '%INFO/AC\t%INFO/AN[\t%GT]\n' > kaka
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/kaka /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/
unset SSHPASS


```



#Count derived alleles per nonsense category.
##W-g:
###Iberian lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_nonsense_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_nonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_nonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i} | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i} | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i} | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i} | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i} | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i} | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i} | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_nonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_nonsense_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS


```

###Canada lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_nonsense_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


REF=/GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_nonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_nonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i} | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i} | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i} | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i} | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i} | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i} | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i} | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_nonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_nonsense_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

##W-g warning-less:
###Iberian lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_nonsensenowarn_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_nonsensenowarn_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_nonsensenowarn_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  grep -v 'WARNING' ${i} > ${i}.delete
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i}.delete | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i}.delete | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i}.delete | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i}.delete | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i}.delete | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i}.delete | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i}.delete | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i}.delete | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_nonsensenowarn_"${VAR}"_"${TYPE}".lr_ann.txt"
  rm ${i}.delete
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_nonsensenowarn_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS


```

###Canada lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_nonsensenowarn_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


REF=/GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_nonsensenowarn_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_nonsensenowarn_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  grep -v 'WARNING' ${i} > ${i}.delete
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i}.delete | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i}.delete | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i}.delete | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i}.delete | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i}.delete | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i}.delete | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i}.delete | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i}.delete | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i}.delete | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_nonsensenowarn_"${VAR}"_"${TYPE}".lr_ann.txt"
  rm ${i}.delete
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_nonsensenowarn_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

##Orthologs only:
###Iberian lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_ortholnonsense_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_ortholnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_ortholnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  cut -f3 /GRUPOS/grupolince/ortologous/HUMAN.lc.1to1_and_multi_orthologs.joined_codes.txt | grep -F -f - ${i} > ${i}_orthol.erase
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i}_orthol.erase | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i}_orthol.erase | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i}_orthol.erase | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i}_orthol.erase | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i}_orthol.erase | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i}_orthol.erase | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i}_orthol.erase | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_orthol.erase | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_ortholnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
  rm ${i}_orthol.erase
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_ortholnonsense_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

###Canada lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_ortholnonsense_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


REF=/GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_ortholnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_ortholnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  cut -f4 /GRUPOS/grupolince/ortologous/HUMAN.lc.1to1_and_multi_orthologs.joined_codes.txt | grep -F -f - ${i} > ${i}_orthol.erase
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i}_orthol.erase | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i}_orthol.erase | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i}_orthol.erase | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i}_orthol.erase | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i}_orthol.erase | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i}_orthol.erase | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i}_orthol.erase | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_orthol.erase | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_orthol.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_ortholnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
  rm ${i}_orthol.erase
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_ortholnonsense_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

##Orthologs & same number of exons only:
###Iberian lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_ortholexonsnonsense_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_ortholexonsnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_ortholexonsnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  cut -f3 /GRUPOS/grupolince/ortologous/HUMAN.lc.1to1_and_multi_orthologs.joined_codes.same_exon_N.txt | grep -F -f - ${i} > ${i}_ortholexons.erase
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i}_ortholexons.erase | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i}_ortholexons.erase | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i}_ortholexons.erase | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i}_ortholexons.erase | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i}_ortholexons.erase | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i}_ortholexons.erase | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i}_ortholexons.erase | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_ortholexons.erase | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_ortholexonsnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
  rm ${i}_ortholexons.erase
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_ortholexonsnonsense_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS


```

###Canada lynx reference:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_ortholexonsnonsense_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


REF=/GRUPOS/grupolince/reference_genomes/lynx_canadensis/lc4.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation
rm ${CALLING}"_ann_individual_summary_ortholexonsnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tnonsense_V\tnonsense_A\tstart_lost_V\tstart_lost_A\tstop_lost_V\tstop_lost_A\tstop_lost_spl_V\tstop_lost_spl_A\tstop_gained_V\tstop_gained_A\tstop_gained_spl_V\tstop_gained_spl_A\tsplice_donor_V\tsplice_donor_A\tsplice_acceptor_V\tsplice_acceptor_A" > ${CALLING}"_ann_individual_summary_ortholexonsnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  cut -f4 /GRUPOS/grupolince/ortologous/HUMAN.lc.1to1_and_multi_orthologs.joined_codes.same_exon_N.txt | grep -F -f - ${i} > ${i}_ortholexons.erase
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  NONSENSE_V=$(grep '|HIGH|' ${i}_ortholexons.erase | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STARTLOST_V=$(grep '|start_lost|' ${i}_ortholexons.erase | wc -l)
  STARTLOST_A=$(grep '|start_lost|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_V=$(grep '|stop_lost|' ${i}_ortholexons.erase | wc -l)
  STOPLOST_A=$(grep '|stop_lost|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPLOST_SPL_V=$(grep '|stop_lost&splice_region_variant|' ${i}_ortholexons.erase | wc -l)
  STOPLOST_SPL_A=$(grep '|stop_lost&splice_region_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_V=$(grep '|stop_gained|' ${i}_ortholexons.erase | wc -l)
  STOPGAINED_A=$(grep '|stop_gained|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  STOPGAINED_SPL_V=$(grep '|stop_gained&splice_region_variant|' ${i}_ortholexons.erase | wc -l)
  STOPGAINED_SPL_A=$(grep '|stop_gained&splice_region_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_DONOR_V=$(grep '|splice_donor_variant&intron_variant|' ${i}_ortholexons.erase | wc -l)
  SPLICE_DONOR_A=$(grep '|splice_donor_variant&intron_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SPLICE_ACCEPTOR_V=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_ortholexons.erase | wc -l)
  SPLICE_ACCEPTOR_A=$(grep '|splice_acceptor_variant&intron_variant|' ${i}_ortholexons.erase | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$NONSENSE_V\t$NONSENSE_A\t$STARTLOST_V\t$STARTLOST_V\t$STOPLOST_V\t$STOPLOST_V\t$STOPLOST_SPL_V\t$STOPLOST_SPL_V\t$STOPGAINED_V\t$STOPGAINED_V\t$STOPGAINED_SPL_V\t$STOPGAINED_SPL_V\t$SPLICE_DONOR_V\t$SPLICE_DONOR_V\t$SPLICE_ACCEPTOR_V\t$SPLICE_ACCEPTOR_V" >> ${CALLING}"_ann_individual_summary_ortholexonsnonsense_"${VAR}"_"${TYPE}".lr_ann.txt"
  rm ${i}_ortholexons.erase
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/lynx_canadensis_VCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_ortholexonsnonsense_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```


#Plot counts:
##W-g.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating
refs=c("lp","lc")
wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
for (ref in refs) {
if (ref=="lp") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_nonsense_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
} else if (ref=="lc") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov_ann_individual_summary_nonsense_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
}

nonsense_db$dataset <- as.factor(nonsense_db$dataset)
nonsense_db$dataset = factor(nonsense_db$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
nonsense_db$population = factor(nonsense_db$population,levels=c("ki","no","po","sm","do"))
print.data.frame(nonsense_db)

nonsense_db_alleleR <- nonsense_db %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
nonsense_db_alleleR

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_nonsense_db_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(nonsense_db_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(nonsense_db_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_value","se_value")
    average_nonsense_db_alleleR <- rbind(average_nonsense_db_alleleR,row_data,stringsAsFactors=F)
  }
}
average_nonsense_db_alleleR$population = factor(average_nonsense_db_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_nonsense_db_alleleR$population)[levels(average_nonsense_db_alleleR$population)=="sm"] <- "an"
average_nonsense_db_alleleR$ratio = factor(average_nonsense_db_alleleR$ratio,levels=c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor"))
levels(average_nonsense_db_alleleR$ratio) <- c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor")
average_nonsense_db_alleleR$avg_value <- as.numeric(average_nonsense_db_alleleR$avg_value)
average_nonsense_db_alleleR$se_value <- as.numeric(average_nonsense_db_alleleR$se_value)
average_nonsense_db_alleleR

if (ref=="lp") {
lp_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lp")
} else if (ref=="lc") {
lc_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lc")
}
}

joined_average_nonsense_db_alleleR <- rbind(lp_ref_average_nonsense_db_alleleR,lc_ref_average_nonsense_db_alleleR)


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
#type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.75,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

ggplot_joined_average_nonsense_db_alleleR <- ggplot(data=filter(joined_average_nonsense_db_alleleR,ratio!="nonsense"), aes(population,avg_value,colour=ref)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average nonsense genetic load",ifelse(type=="fixed","Derived fixation rate", "Check code"))) +
  scale_y_continuous() +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      #legend.position="none",
      legend.title=element_text()
  )
ggplot_joined_average_nonsense_db_alleleR

ggsave(paste0(type,"_nonsense_genetic_load.pdf"), width=30, height=12, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_joined_average_nonsense_db_alleleR)

```

##W-g warning-less.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating
refs=c("lp","lc")
wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
for (ref in refs) {
if (ref=="lp") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_nonsensenowarn_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
} else if (ref=="lc") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov_ann_individual_summary_nonsensenowarn_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
}

nonsense_db$dataset <- as.factor(nonsense_db$dataset)
nonsense_db$dataset = factor(nonsense_db$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
nonsense_db$population = factor(nonsense_db$population,levels=c("ki","no","po","sm","do"))
print.data.frame(nonsense_db)

nonsense_db_alleleR <- nonsense_db %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
nonsense_db_alleleR

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_nonsense_db_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(nonsense_db_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(nonsense_db_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_value","se_value")
    average_nonsense_db_alleleR <- rbind(average_nonsense_db_alleleR,row_data,stringsAsFactors=F)
  }
}
average_nonsense_db_alleleR$population = factor(average_nonsense_db_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_nonsense_db_alleleR$population)[levels(average_nonsense_db_alleleR$population)=="sm"] <- "an"
average_nonsense_db_alleleR$ratio = factor(average_nonsense_db_alleleR$ratio,levels=c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor"))
levels(average_nonsense_db_alleleR$ratio) <- c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor")
average_nonsense_db_alleleR$avg_value <- as.numeric(average_nonsense_db_alleleR$avg_value)
average_nonsense_db_alleleR$se_value <- as.numeric(average_nonsense_db_alleleR$se_value)
average_nonsense_db_alleleR

if (ref=="lp") {
lp_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lp")
} else if (ref=="lc") {
lc_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lc")
}
}

joined_average_nonsense_db_alleleR <- rbind(lp_ref_average_nonsense_db_alleleR,lc_ref_average_nonsense_db_alleleR)


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
#type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.75,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

ggplot_joined_average_nonsense_db_alleleR <- ggplot(data=filter(joined_average_nonsense_db_alleleR,ratio!="nonsense"), aes(population,avg_value,colour=ref)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average nonsense genetic load",ifelse(type=="fixed","Derived fixation rate", "Check code"))) +
  scale_y_continuous() +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      #legend.position="none",
      legend.title=element_text()
  )
ggplot_joined_average_nonsense_db_alleleR

ggsave(paste0(type,"_nonsensenowarn_genetic_load.pdf"), width=30, height=12, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_joined_average_nonsense_db_alleleR)

```

##Orthologs only.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating
refs=c("lp","lc")
wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
for (ref in refs) {
if (ref=="lp") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_ortholnonsense_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
} else if (ref=="lc") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov_ann_individual_summary_ortholnonsense_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
}

nonsense_db$dataset <- as.factor(nonsense_db$dataset)
nonsense_db$dataset = factor(nonsense_db$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
nonsense_db$population = factor(nonsense_db$population,levels=c("ki","no","po","sm","do"))
print.data.frame(nonsense_db)

nonsense_db_alleleR <- nonsense_db %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
nonsense_db_alleleR

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_nonsense_db_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(nonsense_db_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(nonsense_db_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_value","se_value")
    average_nonsense_db_alleleR <- rbind(average_nonsense_db_alleleR,row_data,stringsAsFactors=F)
  }
}
average_nonsense_db_alleleR$population = factor(average_nonsense_db_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_nonsense_db_alleleR$population)[levels(average_nonsense_db_alleleR$population)=="sm"] <- "an"
average_nonsense_db_alleleR$ratio = factor(average_nonsense_db_alleleR$ratio,levels=c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor"))
levels(average_nonsense_db_alleleR$ratio) <- c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor")
average_nonsense_db_alleleR$avg_value <- as.numeric(average_nonsense_db_alleleR$avg_value)
average_nonsense_db_alleleR$se_value <- as.numeric(average_nonsense_db_alleleR$se_value)
average_nonsense_db_alleleR

if (ref=="lp") {
lp_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lp")
} else if (ref=="lc") {
lc_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lc")
}
}

joined_average_nonsense_db_alleleR <- rbind(lp_ref_average_nonsense_db_alleleR,lc_ref_average_nonsense_db_alleleR)


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
#type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.75,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

ggplot_joined_average_nonsense_db_alleleR <- ggplot(data=filter(joined_average_nonsense_db_alleleR,ratio!="nonsense"), aes(population,avg_value,colour=ref)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average nonsense genetic load",ifelse(type=="fixed","Derived fixation rate", "Check code"))) +
  scale_y_continuous() +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      #legend.position="none",
      legend.title=element_text()
  )
ggplot_joined_average_nonsense_db_alleleR

ggsave(paste0(type,"_ortholnonsense_genetic_load.pdf"), width=30, height=12, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_joined_average_nonsense_db_alleleR)

```

##Orthologs & same number of exons only.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating
refs=c("lp","lc")
wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
for (ref in refs) {
if (ref=="lp") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_ortholexonsnonsense_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
} else if (ref=="lc") {
nonsense_db <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_lcnm3_origcov_ann_individual_summary_ortholexonsnonsense_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,ends_with("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.)))
}

nonsense_db$dataset <- as.factor(nonsense_db$dataset)
nonsense_db$dataset = factor(nonsense_db$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
nonsense_db$population = factor(nonsense_db$population,levels=c("ki","no","po","sm","do"))
print.data.frame(nonsense_db)

nonsense_db_alleleR <- nonsense_db %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
nonsense_db_alleleR

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_nonsense_db_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_value"=character(0),"se_value"=character(0)) #next, create the empty dataframe

for (pop in unique(nonsense_db_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(nonsense_db_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(nonsense_db_alleleR,ratio==r & population==pop) %>% select(value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_value","se_value")
    average_nonsense_db_alleleR <- rbind(average_nonsense_db_alleleR,row_data,stringsAsFactors=F)
  }
}
average_nonsense_db_alleleR$population = factor(average_nonsense_db_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_nonsense_db_alleleR$population)[levels(average_nonsense_db_alleleR$population)=="sm"] <- "an"
average_nonsense_db_alleleR$ratio = factor(average_nonsense_db_alleleR$ratio,levels=c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor"))
levels(average_nonsense_db_alleleR$ratio) <- c("nonsense","start_lost","stop_lost","stop_lost_spl","stop_gained","stop_gained_spl","splice_donor","splice_acceptor")
average_nonsense_db_alleleR$avg_value <- as.numeric(average_nonsense_db_alleleR$avg_value)
average_nonsense_db_alleleR$se_value <- as.numeric(average_nonsense_db_alleleR$se_value)
average_nonsense_db_alleleR

if (ref=="lp") {
lp_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lp")
} else if (ref=="lc") {
lc_ref_average_nonsense_db_alleleR <- average_nonsense_db_alleleR %>% mutate(ref="lc")
}
}

joined_average_nonsense_db_alleleR <- rbind(lp_ref_average_nonsense_db_alleleR,lc_ref_average_nonsense_db_alleleR)


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
#type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.75,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

ggplot_joined_average_nonsense_db_alleleR <- ggplot(data=filter(joined_average_nonsense_db_alleleR,ratio!="nonsense"), aes(population,avg_value,colour=ref)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  geom_errorbar(aes(ymin=avg_value-se_value, ymax=avg_value+se_value), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average nonsense genetic load",ifelse(type=="fixed","Derived fixation rate", "Check code"))) +
  scale_y_continuous() +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      #legend.position="none",
      legend.title=element_text()
  )
ggplot_joined_average_nonsense_db_alleleR

ggsave(paste0(type,"_ortholexonsnonsense_genetic_load.pdf"), width=30, height=12, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_joined_average_nonsense_db_alleleR)

```
