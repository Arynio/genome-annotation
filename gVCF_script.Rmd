---
title: "gVCF_script"
author: "Dani"
date: "17 de abril de 2017"
output: html_document
---

#0a: Define paths.

```{r Define paths, eval=FALSE, engine='bash'}

B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAMs path
G_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
V_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani #VCFs path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

```

#0b: Prepare reference genome. Prepare two files with data from the reference genome: a dictionary with contig names and sizes, and a fasta index file. This step should only be performed once (per reference genome).

```{r Prepare reference genome, eval=FALSE, engine='bash'}

#Karolina's code to prepare the reference genome. This should only be performed once per reference genome.
cd /home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/
java -jar /home/tmp/Software/Picard/picard-tools-1.66/CreateSequenceDictionary.jar \
 R=lp23.fa \
 O=lp23.dict
samtools faidx lp23.fa

```

#1a: Produce gVCF files. Perform a calling per sample to produce a gVCF file with variant information for every position in the genome (variant or not).

```{r Produce gVCF files, eval=FALSE, engine='bash'}

#For 5x samples:

cd $B_PATH #this works for the 5x samples (25x samples are stored in another folder and are named differently)
POP=("*_lp")
for pop in ${POP[@]}
  do
  echo "${pop}"
  ls ${pop}_*_recal_round-1.bam > ${pop/*_lp/lp}_recal_round-1.bam.list;
  INPUT_BAMS_FOR_CALLING=($(cat ${pop/*_lp/lp}_recal_round-1.bam.list)) 
  for id in ${INPUT_BAMS_FOR_CALLING[@]}
    do
    echo "${id}"
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar $GATK \
    -T HaplotypeCaller \
    -R $REF \
    -I ${id} \
    --emitRefConfidence GVCF \
    -o $G_PATH/${id/.bam/.g.vcf.gz}
    done
  done

#For 25x samples:
cd $B_PATH/genome_project_samples_25x #this works for the 25x samples
POP=("*_lp")
for pop in ${POP[@]}
  do
  echo "${pop}"
  ls ${pop}_*_recal_round-1_25x.bam > ${pop/*_lp/lp}_recal_round-1_25x.bam.list;
  INPUT_BAMS_FOR_CALLING=($(cat ${pop/*_lp/lp}_recal_round-1_25x.bam.list)) 
  for id in ${INPUT_BAMS_FOR_CALLING[@]}
    do
    echo "${id}"
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar $GATK \
    -T HaplotypeCaller \
    -R $REF \
    -I ${id} \
    --emitRefConfidence GVCF \
    -o $G_PATH/genome_project_samples_25x/${id/.bam/.g.vcf.gz}
    done
  done

#This was only used to test one sample (lp_do_0443):
cd $B_PATH
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T HaplotypeCaller \
-R $REF \
-I c_lp_do_0443_recal_round-1.bam \
--emitRefConfidence GVCF \
-o $G_PATH/c_lp_do_0443_BIS_recal_round-1.g.vcf

#This was only used to produce the gVCF file for the Euskadi historical Lynx lynx sample:
cd $B_PATH
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T HaplotypeCaller \
    -R $REF \
    -I h_ll_pv_0223_sorted_indelrealigner_marked_sorted.bam \
    --emitRefConfidence GVCF \
    -o $G_PATH/h_ll_pv_0223_sorted_indelrealigner_marked_sorted.g.vcf.gz

```

##1a_bis: Immunocapture
```{bash}

#Immunocapture
cd /home/emarmesat/grupolince/immunocapture/alignments_merged_cap_wg_ontarget

POP=h_lp_al
screen -S gvcfs_samples_$POP
POP=h_lp_al
script gvcfs_samples_$POP.log
POP=h_lp_al

REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa

for id in $POP*filtered.bam
do
echo "${id}"
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar /opt/GATK-3.7/GenomeAnalysisTK.jar -T HaplotypeCaller -R $REF -I ${id} --emitRefConfidence GVCF -o ${id/.bam/.g.vcf.gz}
done

```

#1b: Perform sanity checks on gVCFs. Perform various sanity checks on all gVCFs.

```{r Perform sanity checks on gVCFs, eval=FALSE, engine='bash'}

cd $G_PATH
shopt -s extglob #the extglob shell option gives you more powerful pattern matching in the command line.
SAMPLELIST=($(ls c_*.g.vcf.gz | cut -d "." -f1 | sort | uniq))
rm toy_c_gVCF_raw.stats
echo "sample_name,total_SNPs,homoz_ref,heteroz,homoz_alt,unaccounted" > c_gVCF_raw.stats 
for sample in "${SAMPLELIST[@]}"
  do
  echo "${sample}"
  #done
  NAME="${sample}"
  TOTAL_SNPS="$(zgrep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${sample}".g.vcf.gz | wc -l)"
  echo $TOTAL_SNPS
  TOTAL_00="$(zgrep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${sample}".g.vcf.gz | zgrep '0/0:' | wc -l)"
  echo $TOTAL_00
  TOTAL_01="$(zgrep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${sample}".g.vcf.gz | zgrep '0/1:' | wc -l)"
  echo $TOTAL_01
  TOTAL_11="$(zgrep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${sample}".g.vcf.gz | zgrep '1/1:' | wc -l)"
  echo $TOTAL_11
  UNACCOUNTED="$(($TOTAL_SNPS - $TOTAL_00 - $TOTAL_01 - $TOTAL_11))"
  echo $UNACCOUNTED
  echo "$NAME,$TOTAL_SNPS,$TOTAL_00,$TOTAL_01,$TOTAL_11,$UNACCOUNTED" >> c_gVCF_raw.stats
  done
shopt -u extglob #disable extglob

#Save locally the .stats file
scp dkleinman@genomics-b.ebd.csic.es:$G_PATH/c_gVCF_raw.stats /Users/Dani/ownCloud/backup/annotation/gVCFs_analysis/

```

#1c: Analyse the sanity checks file. Perform per individual analyses on the sanity checks file.

```{r Analyse the sanity checks file}
library("readr")
library("dplyr")
library("ggplot2")

sanity_checks <- read_csv("/Users/Dani/ownCloud/backup/annotation/gVCFs_analysis/c_gVCF_raw.stats")
sanity_checks
rowSums(sanity_checks[,-c(1,2)])==sanity_checks[,2] #check if the sum of AA, AB and BB SNPs equal the total SNP count (for each individual)
pop_summary_sc <- sanity_checks %>% 
  mutate(species=substr(sanity_checks$sample_name,3,4),population=substr(sanity_checks$sample_name,6,7)) %>%
  group_by(species,population) %>%
  summarise(N=n(),mean_total_SNPs=mean(total_SNPs),mean_homoz_ref=mean(homoz_ref),mean_heteroz=mean(heteroz),mean_homoz_alt=mean(homoz_alt),mean_unaccounted=mean(unaccounted))
pop_summary_sc

plot_pop_total_SNPs <- ggplot(pop_summary_sc, aes(population,mean_total_SNPs)) + geom_col() + facet_grid(. ~ species,scales="free_x",space="free_x")
plot_pop_total_SNPs

plot_pop_heteroz <- ggplot(pop_summary_sc, aes(population,mean_heteroz)) + geom_col() + facet_grid(. ~ species,scales="free_x",space="free_x")
plot_pop_heteroz

plot_indiv_total_SNPs <- ggplot(sanity_checks, aes(x=substr(sample_name,0,12),y=total_SNPs,fill=substr(sample_name,0,7))) + geom_col() + theme(axis.text.x=element_text(angle=90,hjust=0,size=6,colour="black")) 
plot_indiv_total_SNPs

plot_indiv_heteroz <- ggplot(sanity_checks, aes(x=substr(sample_name,0,12),y=heteroz,fill=substr(sample_name,0,7))) + geom_col() + theme(axis.text.x=element_text(angle=90,hjust=0,size=6,colour="black")) 
plot_indiv_heteroz

```

#2a: Combine gVCF into VCF. Run joint genotyping of all desired gVCF files to produce a multisample VCF file.

```{r Combine gVCF into VCF, eval=FALSE, engine='bash'}

!!!!!!!!!! REPEAT THE VCF ONCE ALL gVCFs ARE READY !!!!!!!!!!!

#First, I generate a VCF file using all lp gVCF files. It doesn't work on compressed files, so I have to unzip all .g.vcf.gz files using the gunzip command, and then repeat. 
#Later on, when trying to work both with lp and ll gVCFs, server B is running very slow and the generation of .idx files (necessary for the VCF calling) is not working fine or whatever. We decide that it's best to work with compressed files so I compress three random lp gVCFs, but then I encounter the same problem that I got before (when using just the lp files): 'Unable to create iterator for rod named variant'.
#Eventually, Karolina and I realize that all the compressing and decompressing of the gVCFs has messed the files. We decide to start all over again, targeting the compressed format (g.vcf.gz). She makes the ll gVCFs and I take care of the lp ones, and she creates the single VCF combining all gVCFs.

#Option A: when all gVCFs are named the same (same name structure) and in the same folder (this is the code that I used in the end to redo gVCFs ONLY for the 5x lp samples):
cd $G_PATH
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms64g -Xmx128g -jar $GATK \
-T GenotypeGVCFs \
-R $REF \
$(for var in *.g.vcf.gz; do echo -V ${var}" ";done) \
-o $V_PATH/all_c_ll_lp.vcf

#Option B: Maria's code to better define the populations and to obtain gVCFs when BAMs with different name structure are considered.

#List of populations
#c_lc_zz
#c_ll_ba
#c_ll_cr
#c_ll_ka
#c_ll_ki
#c_ll_la
#c_ll_no
#c_ll_og
#c_ll_po
#c_ll_to
#c_ll_tu
#c_ll_vl
#c_ll_ya
#c_lp_do
#c_lp_sm
#c_lr_zz
#h_ll_ba

#Code to define the populations to be used, and then print all gVCFs in a list. This version returns a list of the "original" samples (all samples except for the subsampled version of the 28x ones):
cd $G_PATH
POPS=(c_ll_ba-c_ll_cr-c_ll_ka-c_ll_ki-c_ll_la-c_ll_no-c_ll_og-c_ll_po-c_ll_to-c_ll_tu-c_ll_vl-c_ll_ya-c_lp_do-c_lp_sm)
for POP in ${POPS[@]}
  do
  echo $POP
  rm "all_c_original_coverage_$POP"_n"$NUMBER_IND".gVCFlist
  IFS='-' read -r -a POPS1 <<< "$POP" # this creates an array stripping by "-"
  for POP1 in "${POPS1[@]}"
    do
    echo "$POP --> $POP1"
    ls *${POP1}_*_recal_round-1.g.vcf* | grep -v "tbi" | grep -v "idx" >> "$POP".gVCFlist
    done
  NUMBER_IND=$(printf "%03d" `wc -l "$POP".gVCFlist | cut -f1 -d " "`);
  mv "$POP".gVCFlist "all_c_original_coverage_$POP"_n"$NUMBER_IND".gVCFlist
  done

#Code to define the populations to be used, and then print all gVCFs in a list. This version returns a list of all samples, including both the subsampled (5x) version of those with 28x, and the 28x themselves:
cd $G_PATH
POPS=(c_ll_ba-c_ll_cr-c_ll_ka-c_ll_ki-c_ll_la-c_ll_no-c_ll_og-c_ll_po-c_ll_to-c_ll_tu-c_ll_vl-c_ll_ya-c_lp_do-c_lp_sm)
for POP in ${POPS[@]}
  do
  echo $POP
  rm "all_c_samples_$POP"_n"$NUMBER_IND".gVCFlist
  IFS='-' read -r -a POPS1 <<< "$POP" # this creates an array stripping by "-"
  for POP1 in "${POPS1[@]}"
    do
    echo "$POP --> $POP1"
    ls *${POP1}_*_recal_round-1*g.vcf* | grep -v "tbi" | grep -v "idx" >> "$POP".gVCFlist
    done
  NUMBER_IND=$(printf "%03d" `wc -l "$POP".gVCFlist | cut -f1 -d " "`);
  mv "$POP".gVCFlist "all_c_samples_$POP"_n"$NUMBER_IND".gVCFlist
  done

#Code to define the populations to be used, and then print all gVCFs in a list. This version returns a list with only those (original, 28x) samples that were subsampled:
cd $G_PATH
POPS=(c_lp_do-c_lp_sm)
for POP in ${POPS[@]}
  do
  echo $POP
  rm "all_c_lp_samples_28x_$POP"_n"$NUMBER_IND".gVCFlist
  IFS='-' read -r -a POPS1 <<< "$POP" # this creates an array stripping by "-"
    for POP1 in "${POPS1[@]}"
    do
    echo "$POP --> $POP1"
    ls *${POP1}_*_recal_round-1_subsampled.g.vcf* | grep -v "tbi" | grep -v "idx" | sed 's/_subsampled//g' >> "$POP".gVCFlist
    done
  NUMBER_IND=$(printf "%03d" `wc -l "$POP".gVCFlist | cut -f1 -d " "`);
  mv "$POP".gVCFlist "all_c_lp_samples_28x_$POP"_n"$NUMBER_IND".gVCFlist
  done

#Next, use the following line to exclude from the all samples list the list with only 28x samples in order to obtain a list with only 5x samples (including the subsampled versions of 28x samples)
cd $G_PATH
grep -v -f all_c_lp_samples_28x*.gVCFlist all_c_samples_c*.gVCFlist > all_c_samples_5x_c_ll_ba-c_ll_cr-c_ll_ka-c_ll_ki-c_ll_la-c_ll_no-c_ll_og-c_ll_po-c_ll_to-c_ll_tu-c_ll_vl-c_ll_ya-c_lp_do-c_lp_sm_n103.gVCFlist

#Next, run the VCF calling using the "original" samples (28x when possible, and 5x elsewhere):
cd $G_PATH
POPS=(c_ll_ba-c_ll_cr-c_ll_ka-c_ll_ki-c_ll_la-c_ll_no-c_ll_og-c_ll_po-c_ll_to-c_ll_tu-c_ll_vl-c_ll_ya-c_lp_do-c_lp_sm)
INPUT_gVCFs=all_c_samples_5x_*.list #insert here one of the lists generated above ()
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar $GATK \
-T GenotypeGVCFs \
-R $REF \
-V $INPUT_gVCFs \
-o all_c_samples_5x_recal_round-1.vcf

INPUT_gVCFs=all_c_original_coverage_*.list #insert here one of the lists generated above ()
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar $GATK \
-T GenotypeGVCFs \
-R $REF \
-V $INPUT_gVCFs \
-o all_c_original_coverage_recal_round-1.vcf

```

#2b: Fix sample names in the VCF.

```{r Fix sample names in the VCF, eval=FALSE, engine='bash'}

#First, it's important to rename those samples in the global VCF that don't have the proper name (in our case it's 5 samples: the 4 that were sequenced at Macrogen and the DON sample from before 1990). The first time that I tried to split the VCF, I ran into some errors due to these names.

cd $V_PATH
#!/bin/bash
#cat << "EOF" > list_to_remove.txt #Unmark this line when running it (I marked it in R because it doesn't understand it and messes the colours of subsequent lines)
LL112_rgsm c_ll_vl_0112
LL146_rgsm c_ll_ya_0146
LL212_rgsm c_ll_cr_0212
LL90_rgsm c_ll_ki_0090
h_lp_do_0007 c_lp_do_0007
EOF

$BCF reheader -s list_to_remove.txt -o all_c_ll_lp_renamed.vcf all_c_ll_lp.vcf #copy the VCF and rename the wrong named samples in the new VCF

#Next I checked whether both files were identical (except for the sample names, obviously) with diff, and they were, so I deleted all_c_ll_lp.vcf

```

#2c: Split the VCF into per species VCFs. Generate a VCF for the Iberian lynx and another one for the Eurasian lynx, and check whether the reference allele has changed.

```{r Split the VCF into per population VCFs, eval=FALSE, engine='bash'}

#Split the VCF in order to get one for each species. It will be necessary to get rid of substitutions. During this step, all fixed positions within each species (including substitutions) will also be removed (with minor allele count = 1).
cd $G_PATH
declare SPECIES=$(ls c_*.g.vcf.gz | cut -c1-4 | uniq)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  ls ${i}*g.vcf.gz | sed 's/_recal_round-1.g.vcf.gz//g' > list_to_remove.txt
  $BCF view -S list_to_remove.txt --min-ac 1:minor -Ov -o $V_PATH/"${i}"_species.vcf $V_PATH/all_c_ll_lp_renamed.vcf
  done
rm list_to_remove.txt

#Check whether the reference allele has changed between VCFs. To this end, let's compare all SNPs common to both species' variants list.
grep -v '#' $V_PATH/c_lp_species.vcf | cut -d$'\t' -f1,2,4,5 | awk '{print $1"_"$2" "$3" "$4}' | sort -k 1,1 > $V_PATH/lp_variants.txt #creates variants list for lp.
grep -v '#' $V_PATH/c_ll_species.vcf | cut -d$'\t' -f1,2,4,5 | awk '{print $1"_"$2" "$3" "$4}' | sort -k 1,1 > $V_PATH/ll_variants.txt #creates variants list for ll.
join -1 1 -2 1 -e0 -o'0,1.2,1.3,2.2,2.3' $V_PATH/ll_variants.txt $V_PATH/lp_variants.txt > lp_ll_joined_variants.txt #joins both lists and outputs only the common SNPs.
awk '{if($2 == $4) print 1; else print 0; }' lp_ll_joined_variants.txt | sort | uniq #this should only return the value "1" when all SNPs share the same reference allele, or both "0" and "1" if some SNPs have different reference alleles between species. In this case it only returns "1", so everything is fine.
cat lp_ll_joined_variants.txt | awk '{if($2 == $4) print $0" 1"; else print $0" 0"; }' lp_ll_joined_variants.txt | awk '$6 == 0' #in case there's any row where the reference allele has changed, return those rows. In this case, none are returned.

```

#3a: Extract SNPs. Subset the VCF files in order to keep only SNP variants.

```{r Extract SNPs, eval=FALSE, engine='bash'}

#During this step, all multiallelic SNPs as well as all INDELs will be dropped from the respective VCFs.
cd $V_PATH
declare SPECIES=$(ls c*_species.vcf | cut -c1-4 | uniq)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -selectType SNP \
  -restrictAllelesTo BIALLELIC \
  -R $REF \
  -V "${i}"_species.vcf \
  -o "${i}"_species_SNPs.vcf
  done

#Check whether there's any position with the reference allele fixed (AC=0) or with the alternative allele fixed (AC=AN)
grep -v '#' c_lp_species_SNPs.vcf | cut -d$'\t' -f8 | cut -d$';' -f1,3 --output-delimiter=' ' | cut -d$'=' -f2,3 --output-delimiter=' ' | cut -d$' ' -f1,3 | awk -F , '{if($1 == $2 || $1 == 0) print 0; else print 1; }' | sort | uniq #this should only return the value "1" when all positions are variable (i.e. when all positions have at least one reference or one alternative allele), whereas both "1" and "0" would be returned when there's any position with a fixed allele.

```

#3b: Extract INDELs. Subset the VCF files in order to keep only INDELs.

```{r Extract INDELs, eval=FALSE, engine='bash'}

#This section should only be used if INDELs are needed.
cd $V_PATH
declare SPECIES=$(ls c*_species.vcf | cut -c1-4 | uniq)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -selectType INDEL \
  -R $REF \
  -V "${i}"_species.vcf \
  -o "${i}"_species_INDELs.vcf
  done

```

#4a: Tag SNPs. Tag SNPs which don't reach certain quality thresholds.

```{r Tag SNPs, eval=FALSE, engine='bash'}

#SNPs that don't meet certain quality criteria should be tagged (and eventually removed).     
  #QD: QualByDepth (variant confidence divided by the unfiltered depth of non-reference samples). Default < 2.0.
  #FS: FisherStrand (phred-scaled p-value using Fisher's Exact Test to detect strand bias in the reads). Default > 60.0.
  #MQ: RMSMappingQuality (root mean square of Mapping Quality of reads across all samples). Default < 40.0.
  #MQRankSum: MappingQualityRankSumTest (u-based z-approximation from Mann-Whitney Rank Sum Test for Mappin Qualities, i.e. reads with reference alleles vs. those with the alternate allele. Will only be applied to heterozygous calls). Default < -12.5. In theory, this would alleviate contamination problems.
  #ReadPosRankSum: ReadPosRankSumTest (u-based z-approximation from Mann-Whitney Rank Sum Test for distance from end of the read for reads with the alternate allele. Will only be applied to heterozygous calls). Default < -8.0. In theory, this would alleviate damage problems.
  #SOR: StrandOddsRatio (evaluates whether there's strand bias in the data). Default > 3.0.
cd $V_PATH
declare SPECIES=$(ls c*_species_SNPs.vcf | cut -c1-4 | uniq)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T VariantFiltration \
  --filterName "snpsfilter" \
  --filterExpression "QD<2.0 || FS>60.0 || MQ<40.0 || MQRankSum<-12.5 || ReadPosRankSum<-8.0 || SOR>3.0" \
  -R $REF \
  -V "${i}"_species_SNPs.vcf \
  -o "${i}"_species_SNPs_tagged.vcf
  done

```

#4b: Filter SNPs. Remove all SNPs tagged in the previous step.

```{r Filter SNPs, eval=FALSE, engine='bash'}

cd $V_PATH
declare SPECIES=$(ls c*_species_SNPs_tagged.vcf | cut -c1-4 | uniq)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -select 'vc.isNotFiltered()' \
  -R $REF \
  -V "${i}"_species_SNPs_tagged.vcf \
  -o "${i}"_species_SNPs_tagged_filtered.vcf
  done
  

B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAMs path
G_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
V_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani #VCFs path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path


  #MQRankSum: MappingQualityRankSumTest (u-based z-approximation from Mann-Whitney Rank Sum Test for Mappin Qualities, i.e. reads with reference alleles vs. those with the alternate allele. Will only be applied to heterozygous calls). Default < -12.5. In theory, this would alleviate contamination problems.
  #ReadPosRankSum: ReadPosRankSumTest (u-based z-approximation from Mann-Whitney Rank Sum Test for distance from end of the read for reads with the alternate allele. Will only be applied to heterozygous calls). Default < -8.0. In theory, this would alleviate damage problems.
  
#Tests with different filters
cd $V_PATH

grep -v '#' c_ll_species_SNPs.vcf | wc -l #10488154

java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-select "MQRankSum<-12.5 || ReadPosRankSum<-8.0" \
-R $REF \
-V c_ll_species_SNPs.vcf \
-o c_ll_species_SNPs_MQRS12,5_RPRS8,0.vcf

grep -v '#' c_ll_species_SNPs_MQRS12,5_RPRS8,0.vcf | wc -l #232
  
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-select "MQRankSum<-8.0 || ReadPosRankSum<-8.0" \
-R $REF \
-V c_ll_species_SNPs.vcf \
-o c_ll_species_SNPs_MQRS8,0_RPRS8,0.vcf

grep -v '#' c_ll_species_SNPs_MQRS8,0_RPRS8,0.vcf | wc -l #738

java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-select "MQRankSum<-12.5 || ReadPosRankSum<-5.0" \
-R $REF \
-V c_ll_species_SNPs.vcf \
-o c_ll_species_SNPs_MQRS12,5_RPRS5,0.vcf

grep -v '#' c_ll_species_SNPs_MQRS12,5_RPRS5,0.vcf | wc -l #258

java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-select "MQRankSum<-8.0 || ReadPosRankSum<-5.0" \
-R $REF \
-V c_ll_species_SNPs.vcf \
-o c_ll_species_SNPs_MQRS8,0_RPRS5,0.vcf

grep -v '#' c_ll_species_SNPs_MQRS8,0_RPRS5,0.vcf | wc -l #756

java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-select "MQRankSum<-2.5 || ReadPosRankSum<-2.5" \
-R $REF \
-V c_ll_species_SNPs.vcf \
-o c_ll_species_SNPs_MQRS2,5_RPRS2,5.vcf

grep -v '#' c_ll_species_SNPs_MQRS2,5_RPRS2,5.vcf | wc -l #113081


```

#5a: Split the species VCFs into per population VCFs. Generate a VCF for each population.

```{r Split the species VCFs into per population VCFs, eval=FALSE, engine='bash'}

#Split both species VCFs in order to get a sub-VCF for each population. All these sub-VCFs must include all positions so that they are comparable (i.e. positions that become monomorphic whitin a population mustn't be dropped).

#Version that keeps all sites in all subVCFs.
cd $G_PATH
declare SPECIES=$(ls c_*.g.vcf.gz | cut -c1-4 | uniq)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  declare POP=$(ls "${i}"*.g.vcf.gz | cut -c1-7 | uniq)
  for j in ${POP[@]}
    do
    echo "${j}"
    ls ${j}*g.vcf.gz | sed 's/_recal_round-1.g.vcf.gz//g' > list_to_remove.txt
    cat list_to_remove.txt
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V $V_PATH/"${i}"_species_SNPs_tagged_filtered.vcf \
    -o $V_PATH/"${j}"_perpop.vcf \
    --sample_file list_to_remove.txt \
    --preserveAlleles
    done
  done
rm list_to_remove.txt

#Version that drops monomorphic positions within each species.
cd $G_PATH
declare SPECIES=$(ls c_*.g.vcf.gz | cut -c1-4 | uniq)
for i in ${SPECIES[@]}
  do
  echo "${i}"
  declare POP=$(ls "${i}"*.g.vcf.gz | cut -c1-7 | uniq)
  for j in ${POP[@]}
    do
    echo "${j}"
    ls ${j}*g.vcf.gz | sed 's/_recal_round-1.g.vcf.gz//g' > list_to_remove.txt
    $BCF view -c1 -S list_to_remove.txt -Ov -o $V_PATH/"${j}"_perpop.vcf $V_PATH/"${i}"_species_SNPs_tagged_filtered.vcf
    done
  done
rm list_to_remove.txt

```

#5b: Perform sanity checks on VCFs. Perform various sanity checks on all VCFs.

```{r Perform sanity checks on gVCFs, eval=FALSE, engine='bash'}

cd $V_PATH
shopt -s extglob #the extglob shell option gives you more powerful pattern matching in the command line.
POPLIST=($(ls c_*_perpop.vcf | cut -d "_" -f1,2,3 | sort | uniq))
rm c_VCF_raw.stats
echo "pop_name,sample_number,total_SNPs" > c_VCF_raw.stats 
#echo "pop_name,total_SNPs,homoz_ref,heteroz,homoz_alt,unaccounted,unaccounted_cat" > c_VCF_raw.stats 
for pop in "${POPLIST[@]}"
  do
  echo "${pop}"
  #done
  NAME="${pop}"
  SAMPLE_NUMBER="$($BCF query -l "${pop}"_perpop.vcf | wc -l)"
  echo $SAMPLE_NUMBER
  TOTAL_SNPS="$(grep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${pop}"_perpop.vcf | wc -l)"
  echo $TOTAL_SNPS
  #TOTAL_00="$(grep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${pop}"_perpop.vcf | grep '0/0:' | wc -l)"
  #echo $TOTAL_00
  #TOTAL_01="$(grep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${pop}"_perpop.vcf | grep '0/1:' | wc -l)"
  #echo $TOTAL_01
  #TOTAL_11="$(grep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${pop}"_perpop.vcf | grep '1/1:' | wc -l)"
  #echo $TOTAL_11
  #UNACCOUNTED="$(($TOTAL_SNPS - $TOTAL_00 - $TOTAL_01 - $TOTAL_11))"
  #echo $UNACCOUNTED
  #UNACCOUNTED_CAT="$(grep -v '#' /home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/"${pop}"_perpop.vcf | cut -d$'\t' -f10 | cut -d ":" -f1 | sort | uniq | paste -s -d ",")"
  #echo $UNACCOUNTED_CAT
  
  echo "$NAME,$SAMPLE_NUMBER,$TOTAL_SNPS" >> c_VCF_raw.stats
  #echo "$NAME,$TOTAL_SNPS,$TOTAL_00,$TOTAL_01,$TOTAL_11,$UNACCOUNTED,$UNACCOUNTED_CAT" >> c_VCF_raw.stats
  done
shopt -u extglob #disable extglob

#Save locally the .stats file
scp dkleinman@genomics-b.ebd.csic.es:$V_PATH/c_VCF_raw.stats /Users/Dani/ownCloud/backup/annotation/gVCFs_analysis/

```

#5c: Analyse the sanity checks file. Perform per population analyses on the sanity checks file.

```{r Analyse the sanity checks file}
library("readr")
library("dplyr")
library("ggplot2")

sanity_checks <- read_csv("/Users/Dani/ownCloud/backup/annotation/gVCFs_analysis/c_VCF_raw.stats")
sanity_checks
sanity_checks <- sanity_checks %>% 
  mutate(species=substr(sanity_checks$pop_name,3,4)) %>%
  select(1,4,2,3)
sanity_checks

plot_SNPs_samples_corr <- ggplot(sanity_checks, aes(sample_number,total_SNPs)) + geom_point(aes(colour=species)) + scale_colour_manual(values=c("blue","red"))
plot_SNPs_samples_corr

```

#6: Polarize SNPs. Later on, use VCFtools in order to polarize according to the ancestral genome of preference.
