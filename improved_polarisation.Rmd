---
title: "improved_polarisation"
output: html_document
---

#Tiger-cat-rufus-pardinus:
##0. Prepare file which includes the state of all four species:
```{bash}

cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani

#First, retrieve only informative sites (i.e. variants in my VCF).
bedtools intersect -a ../lynx2cat_wTiger.sorted.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf > lynx2cat_wTiger.sorted.dani_variants.bed

#Next, add the Lynx rufus state (the REF column in my VCF), and remove the last column of the Abascal file (his ancestral state summary codes).
bedtools intersect -a lynx2cat_wTiger.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf -wb | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s:%s:%s\t%s\n", $1,$2,$3,$4,$5,$6,$11)}' > lynx2cat_wTiger_wRufusstep0.sorted.dani_variants.bed

#Next, integrate the Lynx rufus state together with the others in a single column. Rename TCL (tiger, cat, lynx) as TCRP (tiger, cat, rufus, pardinus).
awk -F"\t|=|:" '{printf ("%s\t%s\t%s\t%s=%s%s%s:%s:%s\n", $1,$2,$3,"TCRP",substr($5,1,2),$8,substr($5,3,3),$6,$7)}' lynx2cat_wTiger_wRufusstep0.sorted.dani_variants.bed > lynx2cat_wTiger_wRufusstep1.sorted.dani_variants.bed

```

##1. Infer ancestral state by parsimony:
```{bash}

cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani

#First, retrieve only informative sites (i.e. variants in my VCF).
bedtools intersect -a ../lynx2cat_wTiger.sorted.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf > lynx2cat_wTiger.sorted.dani_variants.bed

#Next, add the Lynx rufus state (the REF column in my VCF), and remove the last column of the Abascal file (his ancestral state summary codes).
bedtools intersect -a lynx2cat_wTiger.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf -wb | awk -F"\t|:" '{printf ("%s\t%s\t%s\t%s:%s:%s\t%s\n", $1,$2,$3,$4,$5,$6,$11)}' > lynx2cat_wTiger_wRufusstep0.sorted.dani_variants.bed

#Next, integrate the Lynx rufus state together with the others in a single column. Rename TCL (tiger, cat, lynx) as TCRP (tiger, cat, rufus, pardinus).
awk -F"\t|=|:" '{printf ("%s\t%s\t%s\t%s=%s%s%s:%s:%s\n", $1,$2,$3,"TCRP",substr($5,1,2),$8,substr($5,3,3),$6,$7)}' lynx2cat_wTiger_wRufusstep0.sorted.dani_variants.bed > lynx2cat_wTiger_wRufusstep1.sorted.dani_variants.bed

#Next, apply parsimony criteria to infer the ancestral state, and print the scaffold, position, new ancestral state and previous ancestral state (i.e. the Lynx rufus base).
awk '{                                       
split($0,a,":");
split(a[1],b,"=");
split(b[2],c,"");
if (c[1]==c[2] && c[1]==c[3] && c[1]==c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]);
else if (c[1]==c[2] && c[1]==c[3] && c[1]!=c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]);
else if (c[1]==c[2] && c[1]==c[4] && c[1]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]);
else if (c[1]==c[3] && c[1]==c[4] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]);
else if (c[2]==c[3] && c[2]==c[4] && c[2]!=c[1]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]);
else if (c[1]==c[2] && c[3]==c[4] && c[1]!=c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[2],c[3]);
else if ((c[1]=="?" || c[1]=="-") && c[2]==c[3] && c[2]!=c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]);
else if ((c[1]=="?" || c[1]=="-") && c[2]==c[4] && c[2]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]);
else printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,"N",c[3]);
}' lynx2cat_wTiger_wRufusstep1.sorted.dani_variants.bed > /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRP_polarizedfixed/ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRP_polarizedfixed/

#Generate file with consistent sites (sites where the polarisation doesn't change).
awk '$5==$6 {print $0}' ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed > consistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed 

#Generate file with inconsistent sites (wrongly polarised or unpolarisable).
awk '$5!=$6 {print $0}' ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed > inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed 

#Global checks:
##Number of variants in my vcf:
grep -v '#' /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf | wc -l #4388391
##Number of syntenic variants in the TCRP file:
wc -l < ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed #3899717 (88.9% of all variants)
##Of which inconsistent:
wc -l < inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed #210730 (5.40% of the syntenic variants)
###Of which wrongly polarised:
awk '$5!="N" {print $0}' inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed | wc -l #124560 (3.19% of the syntenic variants)
###And unsolvable:
awk '$5=="N" {print $0}' inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed | wc -l #86170 (2.21% of the syntenic variants)

#Misdel checks:
##Number of misdel variants in my vcf:
bedtools intersect -a /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #9193
##Number of syntenic misdel variants in the TCRP file:
bedtools intersect -a ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #8532 (92.8% of all variants)
##Of which inconsistent:
bedtools intersect -a inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #68 (0.8% of all variants)

```

###Test counts (of variants, substitutions or vars+subs) for the consistent variants.
####Of consistent syntenic variants.
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_consistent_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

rm ${CALLING}"_ann_individual_summary_consistent_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_consistent_"${VAR}"_"${TYPE}".lr_ann.txt"
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for file in "${INDLIST[@]}"
  do
  echo "${file}"
  ind=$(echo "${file}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  echo "grepping consistent sites"
  bedtools intersect -a ${file} -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/consistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed -header > current_consistent.vcf
  echo "counting variants"
  i=current_consistent.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/${CALLING}"_ann_individual_summary_consistent_"${VAR}"_"${TYPE}".lr_ann.txt"
  done
rm ${VAR}_*.temp.borrar
rm current_consistent.vcf

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

####Of inconsistent syntenic variants.
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_inconsistent_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

rm ${CALLING}"_ann_individual_summary_inconsistent_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_inconsistent_"${VAR}"_"${TYPE}".lr_ann.txt"
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for file in "${INDLIST[@]}"
  do
  echo "${file}"
  ind=$(echo "${file}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  echo "grepping inconsistent sites"
  bedtools intersect -a ${file} -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed -header > current_inconsistent.vcf
  echo "counting variants"
  i=current_inconsistent.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/${CALLING}"_ann_individual_summary_inconsistent_"${VAR}"_"${TYPE}".lr_ann.txt"
  done
rm ${VAR}_*.temp.borrar
rm current_inconsistent.vcf

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

####Of all syntenic variants.
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_syntenic_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

rm ${CALLING}"_ann_individual_summary_syntenic_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_syntenic_"${VAR}"_"${TYPE}".lr_ann.txt"
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for file in "${INDLIST[@]}"
  do
  echo "${file}"
  ind=$(echo "${file}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  echo "grepping syntenic sites"
  bedtools intersect -a ${file} -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed -header > current_syntenic.vcf
  echo "counting variants"
  i=current_syntenic.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/${CALLING}"_ann_individual_summary_syntenic_"${VAR}"_"${TYPE}".lr_ann.txt"
  done
rm ${VAR}_*.temp.borrar
rm current_syntenic.vcf

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

##2: Adjust polarisation.
###Replace inconsistent AA.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#First make two subset VCFs: one with the inconsistent sites, and one with the rest (which includes all consistent sites as well as all those such as INDELs or triallelic that were eventually filtered out).
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
REF=//GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed

bedtools subtract -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_consistent_and_filteredout_sites.vcf

bedtools intersect -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites.vcf

#Discard INDELs from the inconsistent sites VCF in order to avoid duplicate rows, which can mess up the subsequent re-polarisation loop.
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_inconsistent_sites.vcf \
-o ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

grep -v '#' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf > ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf
mv ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

#Discard INDELs from the consistent sites VCF to be able to later paste it with the inconsistent one (because the AA column shifts place when the file is parsed by GATK).
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_consistent_and_filteredout_sites.vcf \
-o ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf

#Next, fix the AA annotation for the inconsistent sites.
screen -S "${CALLING}-aafilled_fixed.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script "${CALLING}-aafilled_fixed.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)

#For sites with an inconsistent polarisation between the old and the new parsimony (as inferred above), replace the previously inferred AA ("old") with the newly inferred one ("new").
rm c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites_SNP_fixed.vcf
TOTAL=$(wc -l < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed)
COUNTER=0
while read -r row
  do
  ((COUNTER++))
  #PATTERN=$(echo "$row" | awk -F"\t" '{printf ("%s\t%s\n", $1,$3)}')
  #SCAFFOLD=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $1)}')
  #POSITION=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $3)}')
  OLD_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$6)}')
  NEW_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$5)}')
  #sed -n '/^'"$PATTERN"'/{s/'"$OLD_AA"'/'"$NEW_AA"'/;p;q}' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf >> ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf
  sed "${COUNTER}q;d" ${CALLING}_aafilled_inconsistent_sites_SNP.vcf | sed 's/'"$OLD_AA"'/'"$NEW_AA"'/' >> ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "fixed polarization of $COUNTER sites out of $TOTAL"
  fi
  done < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed

---

bedtools sort -i <(cat ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf) -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_fixed_SNP.vcf

```


###Use VcfFilterJdk to polarize the AA-filled VCF.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#Polarize the AA-filled VCF based on the new INFO/AA column. Alleles will be switched whenever the ancestral allele matches the alternative one, and genotypes will be properly recoded as well. The following code was originally provided by Pierre Lindenbaum and modified by José Luis Castro.

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed/
screen -S ${CALLING}-polarizedfixed.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarizedfixed.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


java -jar /opt/jvarkit/dist/vcffilterjdk.jar -e 'if(variant.getNAlleles()!=2 || !variant.hasAttribute("AA")) return true; 
final String aa = variant.getAttributeAsString("AA",""); 
if(!variant.getAlleles().get(1).getDisplayString().equalsIgnoreCase(aa)) return true; 
VariantContextBuilder vb=new VariantContextBuilder(variant); 

Allele oldalt = variant.getAlleles().get(1);
Allele oldref = variant.getAlleles().get(0); 
Allele ref= Allele.create(oldalt.getDisplayString(),true); 
Allele alt= Allele.create(oldref.getDisplayString(),false);

vb.alleles(Arrays.asList(ref,alt)); 

List genotypes= new ArrayList<>(); 
for(Genotype g: variant.getGenotypes()) 
  { 
  if(!g.isCalled()) 
  { genotypes.add(g); continue;} 
  GenotypeBuilder gb = new GenotypeBuilder(g); 
  List alleles = new ArrayList<>(); 
  for(Allele a:g.getAlleles()) { 
    if(a.equals(oldalt)) { a=ref;} 
    else if(a.equals(oldref)) { a=alt;} 
    alleles.add(a); 
    } 
  if(g.hasPL()) { 
    int pl[] = g.getPL(); 
    int pl2[] = new int[pl.length]; 
    for(int i=0;i< pl.length;i++) pl2[i]=pl[(pl.length-1)-i]; 
    gb.PL(pl2); 
    } 
  if(g.hasAD()) 
    { int ad[] = g.getAD(); 
    int ad2[] = new int[ad.length]; 
    for(int i=0;i< ad.length;i++) ad2[i]=ad[(ad.length-1)-i];
    gb.AD(ad2); 
  } 
  genotypes.add(gb.alleles(alleles).make()); 
  }

vb.attribute("AF",1.0d - Double.parseDouble(variant.getAttributeAsString("AF",""))); vb.attribute("AC",variant.getGenotypes().stream().flatMap(G->G.getAlleles().stream()).filter(A->A.equals(oldref)).count()); 
vb.genotypes(genotypes); 
return vb.make();' -o ${CALLING}_polarizedfixed.vcf ${CALLING}_aafilled_fixed_SNP.vcf

```

##3: Annotate the VCF.
```{r Annotate using SnpEff, eval=FALSE, engine='bash'}

#This must be run in server B, because the snpEff config directory is located in my home of server B.
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed/
screen -S ${CALLING}
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarizedfixed.lr_ann.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd $O_PATH #run this code from the directory where the config is located.
java -Xmx16g -jar $S_PATH/snpEff.jar LYRU.23 -v -s $V_PATH/$CALLING/TCRP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.html -csvStats $V_PATH/$CALLING/TCRP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.csv -interval $C_PATH/data/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.bed $V_PATH/$CALLING/TCRP_polarizedfixed/${CALLING}_polarizedfixed.vcf > $V_PATH/$CALLING/TCRP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.vcf #run this code from the directory where the config is located.

cd $V_PATH/$CALLING/TCRP_polarizedfixed
grep -v '#' "${CALLING}_polarizedfixed.lr_ann.vcf" | wc -l 
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671526
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov (XL nr filtered) 5783764
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov (XL nr filtered) 5839239
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov (XL nr filtered) 6312383

```

##4: Filter the annotated VCF. 
###Subset the VCF files in order to keep only good quality biallelic SNP variants.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_filtered_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
#The following short loop defines the OTHER variable as the opposite of the TYPE variable (SNP or INDEL)
if [ $TYPE = "SNP" ]
  then
  OTHER=(INDEL)
elif [ $TYPE = "INDEL" ]
  then
  OTHER=(SNP)
fi

if [ $TYPE != "SNP" ] && [ $TYPE != "INDEL" ] #Don't apply filters if $TYPE is invalid
  then
  echo "Invalid value for variable TYPE"
  echo "Filtering aborted"
  else #Apply filters if $TYPE is valid
  echo "Initializing filtering for $TYPE variants"
  
  if [ -f ${CALLING}"_polarized_filtered1.lr_ann.vcf" ] #Since filter 1 is common for both types of variants, skip it if it's been performed before
    then
    echo "Repetitive and low mappability regions already filtered out"
    echo "Skipping this step"
    else
    #Filter 1: Remove repetitive regions and those with low mappability:
    echo "Filtering out repetitive and low mappability regions"
    bedtools subtract -a ${CALLING}_polarizedfixed.lr_ann.vcf -b /GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/repeats_and_lowcomp_no_redundant_mappability.k75_lessthan90.bed -header | uniq > ${CALLING}_polarized_filtered1.lr_ann.vcf
    
    grep -v '#' ${CALLING}"_polarized_filtered1.lr_ann.vcf" | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671908
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 5783764
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 5839239
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 6312383
    #If the file has more than the unfiltered one it's due to some weird behaviour of bedtools subtract with some INDELs that become duplicated. These will be removed in the subsequent step.

  fi
  #Filter 2: During this step, all multiallelic variants as well as all variants from the other type (SNPs/INDELs) will be dropped from the respective VCFs.
  echo "Filtering out multiallelic variants and $OTHER variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -selectType ${TYPE} \
  -restrictAllelesTo BIALLELIC \
  -R $REF \
  -V ${CALLING}"_polarized_filtered1.lr_ann.vcf" \
  -o ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4782660
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4865867
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4907765
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5237095
  
  #Filter 3: Remove polarized fixed variants (AF=0 or AF=1) or those that weren't polarizable (AA different from either REF or ALT):
  echo "Filtering out non-polarizable and fixed variants"
  $BCF view -e '(INFO/AA!=REF & INFO/AA!=ALT) | INFO/AF=0.00 | INFO/AF=1.00' ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf" > ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4676648
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4758637
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4798043
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5103863
  
  #Filter 4: Apply GATK's recommended hard-filters, and then some.
  echo "Filtering out low quality and unreliable variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -select "QUAL >= 30 && QD >= 2.0 && FS <= 60.0 && MQ >= 40.0 && MQRankSum >= -12.5 && ReadPosRankSum >= -8.0" \
  -R $REF \
  -V ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf" \
  -o ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4548968
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4555453
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4565640
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4710686
  
  #Filter 5: For each species exclude those positions that have more than 15% missing genotypes (i.e. that have low depth in any dataset).
  echo "Filtering out high missingness variants"
  $BCF filter -e "F_MISSING > 0.15" -Ov -o ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf" ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4332653
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4420467
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4439054
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4617432
  
  #Filter 6: Finally, exclude sites that have low depth globally.
  echo "Filtering out low depth variants"
  $BCF filter -e "DP < 200" -Ov -o ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4241437
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4391212
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4412177
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4602025
fi

```

###Separate variants and substitutions.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_separate_variants_substitutions_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)

if [[ $CALLING == "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3"* ]] #the double brackets turns the test into a regex
  then
    for s in ${SPECIES[@]}
      do
      echo "retrieving 1 and 0 positions from ${s}"
      bcftools query -l "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf | cut -c1-12 | sort | uniq | grep "${s}" > "${s}"_samples.txt
      N_SAMPLES=$(cat "${s}"_samples.txt | wc -l)
      #AF_THRES=$(echo "scale=4; ($N_SAMPLES*2-2)/($N_SAMPLES*2)" | bc)
      bcftools view -S "${s}"_samples.txt "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf | bcftools view -i "AC/AN = 0 | AC/AN = 1" -Ov -o "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf #grab only those positions that have AF=0 or AF~1 (more exactly, AF>(num_alleles-2)/num_alleles, i.e. at most one ancestral allele). Use AC/AN instead of AF since the latter isn't recalculated for the subset of samples
      grep -v '#' "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf | cut -f1,2 | awk '{printf ("%s\t%s\t%s\n", $1, $2-1, $2)}' >  "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".bed
      echo "${s} 1 and 0 positions retrieved"
      done
    bedtools intersect -a *c_lp_1_and_0_positions_"$TYPE".bed -b *c_ll_1_and_0_positions_"$TYPE".bed > "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed #inner join (retrieves only positions that have AF=0 or AF=1 in both species simultaneously, dropping from both species those that are variable within any)
    bedtools intersect -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_substitutions_"$TYPE".lr_ann.vcf
    echo "substitutions retrieved"
    bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_variants_"$TYPE".lr_ann.vcf
    echo "variants retrieved"
    grep -v '#' "${CALLING}"_polarized_substitutions_"$TYPE".lr_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 1382501
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 1421816
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 1420110
    grep -v '#' "${CALLING}"_polarized_variants_"$TYPE".lr_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 2858936
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 2969396
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 2992067
    #bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header | grep -v '#' | wc -l #sanity check that counts the number of discarded variants. This number should equal the difference between _filtered6 (not anymore, now filtered6 is a different thing) and _substitutions. It is for both treatments:
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 70598
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 65219
    else
    echo "the code for this calling hasn't been written yet"
  fi

```

##5: Obtain per dataset VCFs.
###For varssubs, variants and substitutions. All of these should be filtered next.
```{r Obtain per dataset VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perdataset_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

#Define input variant:
if [ $VAR == "varssubs" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf")
elif [ $VAR == "variants" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_variants_"${TYPE}".lr_ann.vcf")
elif [ $VAR == "substitutions" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_substitutions_"${TYPE}".lr_ann.vcf")
else
  INPUT_FILE=()
fi
echo $INPUT_FILE

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRP_polarizedfixed
for j in ${DATASETS[@]}
  do
  echo "${j}"
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${j}"_samples
  mkdir -p "${j}"_"${NM_COV}"_perdataset
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V $INPUT_FILE \
  -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" \
  -env \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  grep -v '#' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" | wc -l #
  done

```

##6: Depth range calculus. Obtain depth range for each species in order to filter high depth positions as part of the next section's many filterings.
###A: write ANGSD depth calculus and store it as .sh
```{r Depth range calculus, eval=FALSE, engine='bash'}

#I'll modify Maria's code to calculate depth. Since these populations are big, we'll be using Elena's captured intergenic fraction of the genome. Save it as .sh and upload it to the server.

CALLING=$(pwd | rev | cut -d'/' -f1 | cut -d'_' -f2- | rev)
POP=$(echo ${STY#*.} | cut -d'.' -f1)
DATASET=$(echo ${STY#*.} | cut -d'_' -f1,2,3)
COVERAGE=$(echo ${STY#*.} | cut -d'_' -f4)
REF="/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa"
THREADS=10
REGIONFILE="/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf"

awk -F ":|-" '{printf ("%s\n", $3-$2)}' /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf | paste -sd+ | bc

rm "$POP".bamlist
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
SAMPLES=$(cat "$DATASET"_samples)
for var in $SAMPLES; do if [ ${var} = "h_ll_pv_0223" ]; then realpath ${var}_sorted_indelrealigner_marked_sorted.nm*.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; elif [ $COVERAGE = "origcov" ] && [ -e ${var}_recal_round-1_25x.nm3.bam ]; then realpath ${var}_recal_round-1_25x.nm3.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; else realpath ${var}_recal_round-1.nm*.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; fi; done
cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist
BAMLIST="$POP".bamlist

cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
OUT_NAME=/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/$POP.qc
NUMBER_IND=$(printf "%03d" `wc -l $BAMLIST | cut -f1 -d " "`)
MAXDEPTH=$(expr $NUMBER_IND \* 1000)

#Sanity checks: 
ls $BAMLIST
echo $OUT_NAME
echo $NUMBER_IND
echo $MAXDEPTH

angsd \
-P $THREADS \
-b $BAMLIST \
-ref $REF \
-out $OUT_NAME \
-uniqueOnly 1 \
-remove_bads 1 \
-only_proper_pairs 1 \
-rf $REGIONFILE \
-baq 1 \
-C 50 \
-doQsDist 1 \
-doDepth 1 \
-doCounts 1 \
-maxDepth $MAXDEPTH

#Save it in a text editor as depth_calculus.sh, upload it to the server, and chmod +x it:
mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed

scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/depth_calculus_polarizedfixed.sh dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/depth_calculus_polarizedfixed.sh

```

###B: define sample sets and run depth calculus 
```{r Depth range calculus, eval=FALSE, engine='bash'}

#Change calling variable
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)

mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NL=$'\n'
for i in ${DATASETS[@]}
  do
    N_SIZE0=$(cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${i}_samples" | wc -l)
    N_SIZE=$(printf "%03d" $N_SIZE0)
    cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
    screen -dmS "${i}_${COVERAGE}_n${N_SIZE}.log"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "script ${i}_${COVERAGE}_n${N_SIZE}.log$NL"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "./depth_calculus_polarizedfixed.sh; exec bash$NL"
    #screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "exit$NL"
    done

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
mkdir -p /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_polarizedfixed
scp dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/*depthGlobal /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_polarizedfixed

```

###C: compile statistics and draw graphs
```{r Depth range calculus}

calling <- "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed"

#Now we use R to plot the depth distribution and to obtain a summary table:

library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)

##Functions:
get_mean <- function(dat) { with(dat, sum(as.numeric(freq)*value)/sum(as.numeric(freq))) }
get_sd <- function(dat) { mu <- get_mean (dat) 
with (dat, sqrt(sum(as.numeric(freq)*(value-mu)^2)/(sum(as.numeric(freq))-1))) } 

#*******************************************************************************************

my_files_depthGlobal = list.files(path = paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling),pattern="*.depthGlobal$") #"5x|GP|MG|LD"

for (i in 1:length(my_files_depthGlobal)) {
  assign(my_files_depthGlobal[i], (scan(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""), sep = " ", dec = ".")) %>% .[!is.na(.)])
  }
mean_folds = 0.95
depth_per_sample <- data.frame()

#Compute globaldepth for all populations found
#*******************************************************************************************

for (i in 1:length(my_files_depthGlobal)) {
  DF = read.table(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""),head=F, stringsAsFactors=F, check.names=FALSE)
  freq_table_DF <- data.frame (value = 1:length (DF), freq = t(DF))
  freq_table_truncated_DF <- filter(freq_table_DF, value < (nrow(freq_table_DF)))
  #Mean depth:
  my_mean_DF <-  get_mean (freq_table_DF)
  my_mean_truncated_DF <- get_mean (freq_table_truncated_DF)
  my_sd_DF <-  get_sd (freq_table_DF)
  my_sd_truncated_DF <- get_sd (freq_table_truncated_DF)
  #Max and min depth:
  maxDepth_DF = my_mean_DF + (mean_folds * my_mean_DF)
  minDepth_DF  = my_mean_DF - (mean_folds * my_mean_DF)
  #maxDepth_truncated_DF = my_mean_truncated_DF + (mean_folds * my_sd_truncated_DF)
  maxDepth_truncated_DF = my_mean_truncated_DF + (3 * my_sd_truncated_DF)
  #minDepth_truncated_DF  = my_mean_truncated_DF - (mean_folds * my_sd_truncated_DF)
  minDepth_truncated_DF = my_mean_truncated_DF - (1 * my_sd_truncated_DF)
  #Para una o más poblaciones:
  population=unlist(strsplit(my_files_depthGlobal[i],"[.]"))[1]
  depth_per_sample <- rbind(depth_per_sample, 
                            data.frame(pop = population,
                                       mean = my_mean_DF,
                                       sd = my_sd_DF, 
                                       mean_truncated = my_mean_truncated_DF,
                                       sd_truncated = my_sd_truncated_DF,
                                       maxDepth = maxDepth_DF, 
                                       minDepth = minDepth_DF,
                                       maxDepth_truncated = maxDepth_truncated_DF,
                                       minDepth_truncated = minDepth_truncated_DF)) 
  #Plotting:
  ggplot(freq_table_truncated_DF, aes(x = value, y = freq)) + 
    geom_bar(stat = "identity", color = "black") +
    scale_x_continuous(breaks = 0:250*10, limits = c(0, maxDepth_truncated_DF*1.5)) +
    scale_y_continuous(expand=c(0,0)) +
    ggtitle (paste(my_files_depthGlobal[i],"_", mean_folds, "_",maxDepth_truncated_DF, "_",maxDepth_DF) ) +
    geom_vline(xintercept=maxDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=maxDepth_truncated_DF, colour ="grey",linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_truncated_DF,colour ="grey",linetype="dashed", size=0.5) + 
    theme_classic() + 
    theme(text = element_text(size=10))
  plot_name=paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],"_",mean_folds,".pdf",sep="")
  ggsave(filename = plot_name)
}

#When finished write the table

#Results for all datasets within a calling are stored in one single dataframe:
write.table(x = depth_per_sample,file = paste("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",calling,"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_",mean_folds,".csv", sep= ""),quote=FALSE, col.names = FALSE, row.names = FALSE, sep= " ")

```

###D: separate for each sample set
```{r Depth range calculus, eval=FALSE, engine='bash'}

#From outside the server, first upload the summary table to the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed)
scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/$CALLING

#In the server, separate in populations:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed)
cd /home/dkleinman/datos/nm_depth_calculus/$CALLING
POPS=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $1}')
for POP in ${POPS[@]}
  do
  echo $POP
  grep "${POP}" /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv > "$POP"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv
  done

```

##7: Perform high-depth filtering. Obtain list of sites with very high depth within each dataset, join them, and remove those sites.
###At the dataset level:
```{r Perform depth filtering, eval=FALSE, engine='bash'}

#For each dataset obtain the list of positions that have lower (higher) depth than the minimum (maximum) within 0.95 of the distribution, as calculated in the previous section, and join them to later remove all of them from all datasets:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_datasets_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRP_polarizedfixed
for j in ${DATASETS[@]}
  do
  echo "${j}"
  #MIN_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $9}') #Obtained in section 10
  MAX_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $8}') #Obtained in section 10
  #echo $MIN_DP
  echo $MAX_DP
  $BCF filter -i "DP > ${MAX_DP}" -Ov -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".lr_ann.vcf" ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf"
  sed -e 's/chr//' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".lr_ann.vcf" | awk '{OFS="\t"; if (!/^#/){print $1,$2-1,$2}}' > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #convert from VCF to BED
  done
cat *"_"${NM_COV}"_perdataset/"*"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" | bedtools sort | uniq > ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #join all BEDs
for j in ${DATASETS[@]}
  do
  echo "${j}"
  bedtools subtract -a ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf"
  done
  
```

###At the global level (run the dataset level code first):
```{r Perform depth filtering, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_global_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

if [ $VAR == "varssubs" ]
  then
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".lr_ann.vcf"
  else
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_"${VAR}"_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".lr_ann.vcf"
fi

```

##8: Obtain per population VCFs.
```{r Obtain per population VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perpop_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRP_polarizedfixed
for i in ${DATASETS[@]}
  do
  echo "${i}"
  declare POP=$(bcftools query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" | cut -c1-7 | sort | uniq)
  for j in ${POP[@]}
    do
    echo "${j}"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    $BCF query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" | grep "${j}" > ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    cat ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    mkdir -p "${j}"_"${NM_COV}"_perpop
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" \
    -o ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" \
    -env \
    --sample_file ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    grep -v '#' ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" | wc -l #
    done
  done

```

##9: Split the population VCFs into per individual VCFs. Generate a VCF for each individual.
###Whole-genome.
```{r Split the population VCFs into per individual VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "individual_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRP_polarizedfixed
declare POP=$(bcftools query -l ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" | cut -c1-7 | sort | uniq)
for i in ${POP[@]}
  do
  echo "${i}"
  mkdir -p "${i}"_"${NM_COV}"_individuals
  VCF_LIST=$(ls ${i}"_"${NM_COV}"_perpop/"*"_"${i}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf")
  for j in ${VCF_LIST[@]}
    do 
    INDIVIDUALS=$(bcftools query -l "${j}" | sort | uniq)
    for k in ${INDIVIDUALS[@]}
      do
      echo "${k}"
      ID=$(echo "${k}")
      java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
      -T SelectVariants \
      -R $REF \
      -V "${j}" \
      -o ${i}"_"${NM_COV}"_individuals/"${k}"_"${NM_COV}"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" \
      -env \
      -sn $ID
      done
    done
  done

```

##10: Get counts (of variants, substitutions or vars+subs).
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
  done
rm ${VAR}_*.temp.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_polarizedfixed_${VAR}_${TYPE}.lr_ann.txt

```

##11: Calculate population averages.
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed

#First, generate some headers and info files.
head -n1 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | head -n1) | cut -f-27 > ind_headers.txt #Retrieve headers for files with individuals
cut -f2,5- ind_headers.txt > pop_headers.txt #Retrieve headers for files with populations
tail -n+2 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | head -n1) | cut -f-4 > ids.txt #Retrieve first 4 columns with individual data

#Next, obtain the population average for the empirical data (5x only!!):
cat pop_headers.txt <(gawk '$3=="5x" {N[$2]++; for (i=5;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | cut -f-27)) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt

cut -f1 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | tail -n+2 > pops.txt #Retrieve column with population data

#In order to relativise by the Kirov population average, divide the population average by the Kirov empirical population averages:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | cut -f2-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRP_polarizedfixed/${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_5xpopulation_average_TCRP_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt

```

##12. Plot counts.
###Relative to Kirov, definitive version.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
variants_and_subst_wg <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_polarizedfixed_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) 

variants_and_subst_wg$dataset <- as.factor(variants_and_subst_wg$dataset)
variants_and_subst_wg$dataset = factor(variants_and_subst_wg$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
variants_and_subst_wg$population = factor(variants_and_subst_wg$population,levels=c("ki","no","po","sm","do"))
print.data.frame(variants_and_subst_wg)

variants_and_subst_wg_alleleR <- variants_and_subst_wg %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
variants_and_subst_wg_alleleR

r_average_vector <- c()
for (r in unique(variants_and_subst_wg_alleleR$ratio)) {
  print(r)
  r_average <- filter(variants_and_subst_wg_alleleR,r==ratio & population=="ki") %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(variants_and_subst_wg_alleleR,r==ratio))))
}
print(r_average_vector)

relativised_variants_and_subst_wg_alleleR <- mutate(variants_and_subst_wg_alleleR, ki_relative_value=value/r_average_vector)

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_variants_and_subst_wg_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_ki_relative_value"=character(0),"se_ki_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_variants_and_subst_wg_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(relativised_variants_and_subst_wg_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_ki_relative_value","se_ki_relative_value")
    average_relativised_variants_and_subst_wg_alleleR <- rbind(average_relativised_variants_and_subst_wg_alleleR,row_data,stringsAsFactors=F)
  }
}
average_relativised_variants_and_subst_wg_alleleR$population = factor(average_relativised_variants_and_subst_wg_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_relativised_variants_and_subst_wg_alleleR$population)[levels(average_relativised_variants_and_subst_wg_alleleR$population)=="sm"] <- "an"
average_relativised_variants_and_subst_wg_alleleR$ratio = factor(average_relativised_variants_and_subst_wg_alleleR$ratio,levels=c("total","intergenic","intronic","synonymous","syn_pref","syn_unpref","missense","missense_tol","missense_del","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high"))
levels(average_relativised_variants_and_subst_wg_alleleR$ratio) <- c("total","intergenic","introns","synonymous","synonymous_pref","synonymous_unpref","missense","missense_tolerated","missense_deleterious","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high")
average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR
#(average_relativised_variants_and_subst_wg_alleleR,paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/",type,"_derived_allele_allele_ratio_relative2introns_mean.csv"))

#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.60,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

average_relativised_derived_allele_allele_ratio_up <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('total|intergenic|introns|\\<synonymous\\>',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_up

average_relativised_derived_allele_allele_ratio_middle <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('\\<missense\\>|nonsense|^UCNE$',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_middle

average_relativised_derived_allele_allele_ratio_down <- ggplot(filter(average_relativised_variants_and_subst_wg_alleleR,grepl('_tolerated|_deleterious|_mid|_high',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  #ylab("Average genetic load relative to ki") +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_down


average_relativised_derived_allele_allele_ratio_combined <- grid.arrange(set_panel_size(average_relativised_derived_allele_allele_ratio_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_middle,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_down,width=unit(4.5,"cm"),height=unit(10,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))

ggsave(paste0(type,"_polarizedfixed_genetic_load_relative2Kirov_definitive.pdf"), width=26, height=38, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",average_relativised_derived_allele_allele_ratio_combined)

```

###Derived allele counts 5xonly manuscript version.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
averages <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_5xpopulation_average_TCRP_",type,"_SNP.empirmean_ki_rel.lr_ann.txt")) %>% select(.,population,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) %>% mutate(species=ifelse(population=="ki" | population=="po" | population=="no","ll","lp"),size=ifelse(population=="ki" | population=="sm","large","small"))
averages$population = factor(averages$population,levels=c("ki","no","po","sm","do"))
averages$species = factor(averages$species,levels=c("ll","lp"))
averages$size = factor(averages$size,levels=c("large","small"))
print.data.frame(averages)

averages_tidy <- averages %>% gather(ratio,value,-population,-species,-size,factor_key=T)
averages_tidy

colnames(averages_tidy) <- c("population","species","size","ratio","mean")
averages_tidy$ratio <- gsub('intronic', 'introns', averages_tidy$ratio)
averages_tidy$ratio <- gsub('coding', 'CDS', averages_tidy$ratio)
averages_tidy$ratio <- gsub('synonymous', 'syn.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_tol', 'm. tol.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_del', 'm. del.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('nonsense', 'LoF', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_low', 'UCNE low', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_mid', 'UCNE mod.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_high', 'UCNE high', averages_tidy$ratio)
averages_tidy$population = factor(averages_tidy$population,levels=c("ki","po","no","sm","do"))
levels(averages_tidy$population) <- c("KIR","POL","NOR","AND","DON")
#levels(averages_tidy$population)[levels(averages_tidy$population)=="sm"] <- "an"
averages_tidy$ratio = factor(averages_tidy$ratio,levels=c("total","intergenic","introns","CDS","syn.","syn_pref","syn_unpref","missense","m. tol.","m. del.","LoF","UCNE","UCNE low","UCNE mod.","UCNE high")) 


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.6,0.6,0.5,0.5),"max"=c(1.2,1.5,2,4),"breaks"=c(0.1,0.1,0.2,0.5))

ggplot_up <- ggplot(data=filter(averages_tidy,grepl('total|intergenic|introns|syn\\.',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_up

ggplot_middle <- ggplot(data=filter(averages_tidy,grepl('\\<missense\\>|LoF|^UCNE$',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_middle

ggplot_down <- ggplot(data=filter(averages_tidy,grepl('tol|del|mod|high',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_down

#New:
if(type=="varssubs") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_middle,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_down,width=unit(1.65,"cm"),height=unit(4,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=10,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))
} else if (type=="fixed") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(ggplot_down,width=unit(4.5,"cm"),height=unit(10,"cm")),set_panel_size(ggplot_other,width=unit(4.5,"cm"),height=unit(10,"cm")),widths=c(4,2.3,0.2),layout_matrix=rbind(c(1,1,NA),c(2,NA,3)),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Derived fixation rate relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))
}

#New:
ggsave(paste0(type,"_TCRP_genetic_load_5xrelative2Kirov_manuscriptlike.pdf"), width=8.2, height=17, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_combined)

```

#Tiger-cat-rufus-lynx-pardinus with wrong parsimony:
##1. Infer ancestral state by parsimony:
###Solve small parsimony problem:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/

#Considering a tree with the following nodes: #1 tiger (T), #2 cat (C), #3 bobcat (R), #4 Eurasian lynx (L), #5 Iberian lynx (P), #6 LxP, #7 (LxP)xR, #8 ((LxP)xR)xC, #9 (((LxP)xR)xC)xT:
ALLELE_LIST=("TTTTA" "TTATA" "TATTA" "ATTTA" "NTTTA" "NTATA" "NATTA")
echo -e "TREE\tPARSIMONY_COST\tANCESTRAL_ROOT\tANCESTRAL_OUTGROUP" > ${CALLING}_parsimony_solutions.txt
for ALLELES in "${ALLELE_LIST[@]}"
  do
  echo $ALLELES
  #FITCH ALGORITHM (ROOT-FOCUSED):
  ##Phase 1 (N variables contain the possible alleles in the node; L variables contain the parsimony cost of the node; C variables compare the child nodes):
  N1=$(echo $ALLELES | cut -c1)
  L1=$((${#N1} - 1))
  N2=$(echo $ALLELES | cut -c2)
  L2=$((${#N2} - 1))
  N3=$(echo $ALLELES | cut -c3)
  L3=$((${#N3} - 1))
  N4=$(echo $ALLELES | cut -c4)
  L4=$((${#N4} - 1))
  N5=$(echo $ALLELES | cut -c5)
  L5=$((${#N5} - 1))
  C6=$(comm -12 <(fold -w1 <<< $N4 | sort -u) <(fold -w1 <<< $N5 | sort -u) | tr -d '\n')
  N6=$(if [ -z $C6 ]; then echo $N4$N5; else echo $C6; fi)
  L6=$(($L4 + $L5 + ${#N6} - 1))
  C7=$(comm -12 <(fold -w1 <<< $N3 | sort -u) <(fold -w1 <<< $N6 | sort -u) | tr -d '\n')
  N7=$(if [ -z $C7 ]; then echo $N3$N6; else echo $C7; fi)
  L7=$(($L3 + $L6 + ${#N7} - 1))
  C8=$(comm -12 <(fold -w1 <<< $N2 | sort -u) <(fold -w1 <<< $N7 | sort -u) | tr -d '\n')
  N8=$(if [ -z $C8 ]; then echo $N2$N7; else echo $C8; fi)
  L8=$(($L2 + $L7 + ${#N8} - 1))
  C9=$(comm -12 <(fold -w1 <<< $N1 | sort -u) <(fold -w1 <<< $N8 | sort -u) | tr -d '\n')
  N9=$(if [ -z $C9 ]; then echo $N1$N8; else echo $C9; fi)
  L9=$(($L1 + $L8 + ${#N9} - 1))
  ##Phase 2 (Z variables compare with the parent node; A variables contain the ancestral assignment for the node):
  A9=$(if [ ${#N9} -ge 2 ]; then echo "N"; else echo $N9; fi)
  Z8=$(comm -12 <(fold -w1 <<< $N8 | sort -u) <(fold -w1 <<< $N9 | sort -u) | tr -d '\n')
  A8=$(if [ -z $Z8 ]; then echo "N"; elif [ ${#Z8} -ge 2 ]; then echo "N"; else echo $Z8; fi)
  Z7=$(comm -12 <(fold -w1 <<< $N7 | sort -u) <(fold -w1 <<< $N8 | sort -u) | tr -d '\n')
  A7=$(if [ -z $Z7 ]; then echo "N"; else echo $Z7; fi)
  Z6=$(comm -12 <(fold -w1 <<< $N6 | sort -u) <(fold -w1 <<< $N7 | sort -u) | tr -d '\n')
  A6=$(if [ -z $Z6 ]; then echo "N"; else echo $Z6; fi)
  if [ $N1 == "N" ]; then echo "parsimony cost of the tree is" $L8; else echo "parsimony cost of the tree is" $L9; fi
  if [ $N1 == "N" ]; then echo "most parsimonious root is" $A8 ; else echo "most parsimonious root is" $A9 "then" $A8; fi

  #OUTGROUP ALGORITHM (OUTGROUP-FOCUSED):
  ##Phase 1 (N variables contain the possible alleles in the node; L variables contain the parsimony cost of the node; C variables compare the child nodes):
  N1=$(echo $ALLELES | cut -c1)
  N2=$(echo $ALLELES | cut -c2)
  N3=$(echo $ALLELES | cut -c3)
  N4=$(echo $ALLELES | cut -c4)
  N5=$(echo $ALLELES | cut -c5)
  C6=$(comm -12 <(fold -w1 <<< $N4 | sort -u) <(fold -w1 <<< $N5 | sort -u) | tr -d '\n')
  N6=$(if [ -z $C6 ]; then echo $N4$N5; else echo $C6; fi)
  C8=$(comm -12 <(fold -w1 <<< $N1 | sort -u) <(fold -w1 <<< $N2 | sort -u) | tr -d '\n')
  N8=$(if [ -z $C8 ]; then echo $N1$N2; else echo $C8; fi)
  C7=$(comm -12 <(fold -w1 <<< $N3 | sort -u) <(fold -w1 <<< $N8 | sort -u) | tr -d '\n')
  N7=$(if [ -z $C7 ]; then echo $N3$N8; else echo $C7; fi)
  ##Phase 2 (Z variables compare with the parent node; A variables contain the ancestral assignment for the node):
  Z6=$(comm -12 <(fold -w1 <<< $N6 | sort -u) <(fold -w1 <<< $N7 | sort -u) | tr -d '\n')
  A6=$(if [ ${#N6} -ge 2 ]; then echo "N"; elif [ -z $C7 ]; then echo $N6; else echo $N6; fi)
  A7=$(if [ ${#N7} -ge 2 ]; then echo "N"; else echo $N7; fi)
  echo "most parsimonious outer group is" $A7
  if [ $N1 == "N" ]
    then echo -e "$ALLELES\t$L8\t$A8\t$A7" >> ${CALLING}_parsimony_solutions.txt
    else echo -e "$ALLELES\t$L9\t$A9\t$A7" >> ${CALLING}_parsimony_solutions.txt
  fi
  done

```

###Apply the solution to my dataset:
```{bash}

cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani

#First, retrieve only informative sites (i.e. variants in my VCF). Don't run this if it was run before.
bedtools intersect -a ../lynx2cat_wTiger.sorted.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf > lynx2cat_wTiger.sorted.dani_variants.bed

#Next, extract the Lynx lynx state (from the Lynx lynx "reference genome"):
bedtools getfasta -fi /GRUPOS/grupolince/reference_genomes/lynx_lynx_genome/LynxLynx_SNVsOnly.fa -bed lynx2cat_wTiger.sorted.dani_variants.bed -tab -fo lynxlynx_reference.sorted.dani_variants.txt

awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' lynxlynx_reference.sorted.dani_variants.txt > lynxlynx_reference.sorted.dani_variants.bed

#Next, add the Lynx lynx state to the file with the other species.
bedtools intersect -a lynx2cat_wTiger_wRufusstep1.sorted.dani_variants.bed -b lynxlynx_reference.sorted.dani_variants.bed -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8)}' > lynx2cat_wTiger_wRufus_wLynxstep0.sorted.dani_variants.bed

#Next, integrate the Lynx lynx state together with the others in a single column. Rename TCRP (tiger, cat, rufus, pardinus) as TCRLP (tiger, cat, rufus, lynx, pardinus).
awk -F"\t|=|:" '{printf ("%s\t%s\t%s\t%s=%s%s%s:%s:%s\n", $1,$2,$3,"TCRLP",substr($5,1,3),$8,substr($5,4,4),$6,$7)}' lynx2cat_wTiger_wRufus_wLynxstep0.sorted.dani_variants.bed > lynx2cat_wTiger_wRufus_wLynxstep1.sorted.dani_variants.bed

#Next, apply parsimony criteria to infer the ancestral state, and print the scaffold, position, new ancestral state and previous ancestral state (i.e. the Lynx rufus base).
awk '{                                       
split($0,a,":");
split(a[1],b,"=");
split(b[2],c,"");
if (c[1]==c[2] && c[1]==c[3] && c[1]==c[4] && c[1]==c[5]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #TCRLP* all equal
else if (c[1]==c[2] && c[1]==c[3] && c[1]==c[4] && c[1]!=c[5]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]); #TCRL* vs P
else if (c[1]==c[2] && c[1]==c[3] && c[1]==c[5] && c[1]!=c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #TCRP* vs L
else if (c[1]==c[2] && c[1]==c[4] && c[1]==c[5] && c[1]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #TCLP* vs R
else if (c[1]==c[3] && c[1]==c[4] && c[1]==c[5] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #TRLP* vs C
else if (c[2]==c[3] && c[2]==c[4] && c[2]==c[5] && c[2]!=c[1]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #CRLP* vs T

else if (c[1]==c[2] && c[1]==c[3] && c[4]==c[5] && c[1]!=c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]); #TCR* vs LP
else if (c[1]==c[2] && c[1]==c[4] && c[3]==c[5] && c[1]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]); #TCL* vs RP
else if (c[1]==c[2] && c[1]==c[5] && c[3]==c[4] && c[1]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #TCP* vs RL

else if (c[1]==c[3] && c[1]==c[4] && c[2]==c[5] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]); #TRL* vs CP
else if (c[1]==c[3] && c[1]==c[5] && c[2]==c[4] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #TRP* vs CL
else if (c[1]==c[4] && c[1]==c[5] && c[2]==c[3] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #TLP* vs CR
else if (c[2]==c[3] && c[2]==c[4] && c[1]==c[5] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]); #CRL* vs TP
else if (c[2]==c[3] && c[2]==c[5] && c[1]==c[4] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #CRP* vs TL
else if (c[2]==c[4] && c[2]==c[5] && c[1]==c[3] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #CLP* vs TR

else if (c[3]==c[4] && c[3]==c[5] && c[1]==c[2] && c[1]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[2],c[3]); #TC* vs RLP

else if ((c[1]=="?" || c[1]=="-") && c[2]==c[3] && c[2]==c[4] && c[2]!=c[5]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[4],c[3]); #CRL* vs P
else if ((c[1]=="?" || c[1]=="-") && c[2]==c[3] && c[2]==c[5] && c[2]!=c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #CRP* vs L
else if ((c[1]=="?" || c[1]=="-") && c[2]==c[4] && c[2]==c[5] && c[2]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[5],c[3]); #CLP* vs R

else if ((c[1]=="?" || c[1]=="-") && c[2]==c[3] && c[4]==c[5] && c[2]!=c[4]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]); #CR* vs LP
else if ((c[1]=="?" || c[1]=="-") && c[2]==c[4] && c[3]==c[5] && c[2]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,"N",c[3]); #CL vs RP null
else if ((c[1]=="?" || c[1]=="-") && c[2]==c[5] && c[3]==c[4] && c[2]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,"N",c[3]); #CP vs RL null

else printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,"N",c[3]); #others null
}' lynx2cat_wTiger_wRufus_wLynxstep1.sorted.dani_variants.bed > /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_polarizedfixed/ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_polarizedfixed/

#Generate file with consistent sites (sites where the polarisation doesn't change).
awk '$5==$6 {print $0}' ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed > consistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed

#Generate file with inconsistent sites (wrongly polarised or unpolarisable).
awk '$5!=$6 {print $0}' ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed > inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed

#Global checks:
##Check number of sites with a polarisation change between TCP and TCLRP:
awk '$5!=$6 {print $0}' ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | wc -l #189802
##Check number of sites with a polarisation change between TCRP and TCLRP:
paste /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRP_polarizedfixed/ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | awk '$5!=$11 {print $0}' | wc -l #73101

##Number of variants in my vcf:
grep -v '#' /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf | wc -l #4388391
##Number of syntenic variants in the TCRLP file:
wc -l < ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed #3899717 (88.9% of all variants)
##Of which inconsistent:
wc -l < inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed #189802 (4.87% of the syntenic variants)
###Of which wrongly polarised:
awk '$5!="N" {print $0}' inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | wc -l #130437 (3.34% of the syntenic variants)
###And unsolvable:
awk '$5=="N" {print $0}' inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | wc -l #59365 (1.52% of the syntenic variants)

#Misdel checks:
##Number of misdel variants in my vcf:
bedtools intersect -a /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #9193
##Number of syntenic misdel variants in the TCRLP file:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #8532 (92.8% of all variants)
##Of which inconsistent:
bedtools intersect -a inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #57 (0.62% of all variants and 0.67% of the syntenic variants)

```

##2: Adjust polarisation.
###Replace inconsistent AA.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#First make two subset VCFs: one with the inconsistent sites, and one with the rest (which includes all consistent sites as well as all those such as INDELs or triallelic that were eventually filtered out).
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
REF=//GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed

bedtools subtract -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_consistent_and_filteredout_sites.vcf

bedtools intersect -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites.vcf

#Discard INDELs from the inconsistent sites VCF in order to avoid duplicate rows, which can mess up the subsequent re-polarisation loop.
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_inconsistent_sites.vcf \
-o ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

grep -v '#' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf > ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf
mv ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

#Discard INDELs from the consistent sites VCF to be able to later paste it with the inconsistent one (because the AA column shifts place when the file is parsed by GATK).
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_consistent_and_filteredout_sites.vcf \
-o ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf

#Next, fix the AA annotation for the inconsistent sites.
screen -S "${CALLING}-aafilled_fixed.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script "${CALLING}-aafilled_fixed.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)

#For sites with an inconsistent polarisation between the old and the new parsimony (as inferred above), replace the previously inferred AA ("old") with the newly inferred one ("new").
rm c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites_SNP_fixed.vcf
TOTAL=$(wc -l < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed)
COUNTER=0
while read -r row
  do
  ((COUNTER++))
  #PATTERN=$(echo "$row" | awk -F"\t" '{printf ("%s\t%s\n", $1,$3)}')
  #SCAFFOLD=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $1)}')
  #POSITION=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $3)}')
  OLD_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$6)}')
  NEW_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$5)}')
  #sed -n '/^'"$PATTERN"'/{s/'"$OLD_AA"'/'"$NEW_AA"'/;p;q}' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf >> ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf
  sed "${COUNTER}q;d" ${CALLING}_aafilled_inconsistent_sites_SNP.vcf | sed 's/'"$OLD_AA"'/'"$NEW_AA"'/' >> ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "fixed polarization of $COUNTER sites out of $TOTAL"
  fi
  done < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed

---

bedtools sort -i <(cat ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf) -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_fixed_SNP.vcf

```

###Use VcfFilterJdk to polarize the AA-filled VCF.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#Polarize the AA-filled VCF based on the new INFO/AA column. Alleles will be switched whenever the ancestral allele matches the alternative one, and genotypes will be properly recoded as well. The following code was originally provided by Pierre Lindenbaum and modified by José Luis Castro.

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/
screen -S ${CALLING}-polarizedfixed.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarizedfixed.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


java -jar /opt/jvarkit/dist/vcffilterjdk.jar -e 'if(variant.getNAlleles()!=2 || !variant.hasAttribute("AA")) return true; 
final String aa = variant.getAttributeAsString("AA",""); 
if(!variant.getAlleles().get(1).getDisplayString().equalsIgnoreCase(aa)) return true; 
VariantContextBuilder vb=new VariantContextBuilder(variant); 

Allele oldalt = variant.getAlleles().get(1);
Allele oldref = variant.getAlleles().get(0); 
Allele ref= Allele.create(oldalt.getDisplayString(),true); 
Allele alt= Allele.create(oldref.getDisplayString(),false);

vb.alleles(Arrays.asList(ref,alt)); 

List genotypes= new ArrayList<>(); 
for(Genotype g: variant.getGenotypes()) 
  { 
  if(!g.isCalled()) 
  { genotypes.add(g); continue;} 
  GenotypeBuilder gb = new GenotypeBuilder(g); 
  List alleles = new ArrayList<>(); 
  for(Allele a:g.getAlleles()) { 
    if(a.equals(oldalt)) { a=ref;} 
    else if(a.equals(oldref)) { a=alt;} 
    alleles.add(a); 
    } 
  if(g.hasPL()) { 
    int pl[] = g.getPL(); 
    int pl2[] = new int[pl.length]; 
    for(int i=0;i< pl.length;i++) pl2[i]=pl[(pl.length-1)-i]; 
    gb.PL(pl2); 
    } 
  if(g.hasAD()) 
    { int ad[] = g.getAD(); 
    int ad2[] = new int[ad.length]; 
    for(int i=0;i< ad.length;i++) ad2[i]=ad[(ad.length-1)-i];
    gb.AD(ad2); 
  } 
  genotypes.add(gb.alleles(alleles).make()); 
  }

vb.attribute("AF",1.0d - Double.parseDouble(variant.getAttributeAsString("AF",""))); vb.attribute("AC",variant.getGenotypes().stream().flatMap(G->G.getAlleles().stream()).filter(A->A.equals(oldref)).count()); 
vb.genotypes(genotypes); 
return vb.make();' -o ${CALLING}_polarizedfixed.vcf ${CALLING}_aafilled_fixed_SNP.vcf

```

###Generate ancestral state fasta reference.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/

#Transform fasta to tab (not really tab separated, only the last column) format to ease the editing.
seqkit fx2tab /home/datos_usuarios/dkleinman/snpEff/data/genomes/LYRU.23.fa > LYRU.23.tab

#Next, edit the Rufus fasta in order to generate the Ancestral fasta:
screen -S fixing_fasta
script fixing_fasta.log
rm ANCESTRAL.23.tab
#First copy all the scaffolds that will remain unchanged:
grep -v -f <(cut -f1 /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | sort | uniq) LYRU.23.tab | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > ANCESTRAL.23.tab
#Next loop over the inconsistent variants (those for which the polarisation is the reverse or are now deemed unpolarisable), grep the scaffold which they belong to, edit the base, and use that file as the input for the next variant in the same scaffold
COUNTER=0
PREV_SCAFFOLD=("lp23.s00000")
OLD_SCAFFOLD=$(head -n1 LYRU.23.tab | awk '{printf ("%s\n",$1)}')
TOTAL=$(wc -l < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed)
while read -r SCAFFOLD START STOP SYNTENY ANCESTRAL RUFUS; do
  #If this is the first variant in the scaffold, grep the Rufus sequence from that scaffold to use as input.
  if [[ "$SCAFFOLD" != "$PREV_SCAFFOLD" ]]
    then
    grep "$SCAFFOLD" LYRU.23.tab > $SCAFFOLD.LYRU.23.tab
    echo "generating input file for scaffold" $SCAFFOLD
  fi
  PREV_SCAFFOLD=$SCAFFOLD
  #Print the sequence replacing only the current variant, and replace the previous input with this output:
  awk -v stop=$STOP -v ancestral=$ANCESTRAL '{printf ("%s\t%s\t%s\t%s%s%s\n", $1,$2,$3,substr($4,1,stop-1),ancestral,substr($4,stop+1))}' $SCAFFOLD.LYRU.23.tab > $SCAFFOLD.tmp && mv $SCAFFOLD.tmp $SCAFFOLD.LYRU.23.tab
  #If there is a change in scaffold, the editing of the previous scaffold is now complete and can be appended to the new ancestral file.
  if [[ "$SCAFFOLD" != "$OLD_SCAFFOLD" ]]
    then
    cat $OLD_SCAFFOLD.LYRU.23.tab >> ANCESTRAL.23.tab
    echo "advancing to scaffold" $SCAFFOLD
    rm $OLD_SCAFFOLD.LYRU.23.tab
  fi
  OLD_SCAFFOLD=$SCAFFOLD
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER sites out of $TOTAL"
  fi
 done < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed
#The editing of the last scaffold is now complete and can be appended to the new ancestral file.
SCAFFOLD=$(tail -n1 /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | awk '{printf ("%s\n",$1)}')
cat $SCAFFOLD.LYRU.23.tab >> ANCESTRAL.23.tab
rm $SCAFFOLD.LYRU.23.tab


#Sort the ancestral file so that scaffolds regain their order, and place the field separators used by seqkit (two white spaces, one white space, and one tab, respectively), in order to convert it back to fasta format:
sort -k1,1 ANCESTRAL.23.tab | awk '{printf ("%s  %s %s\t%s\n", $1,$2,$3,$4)}' > ANCESTRAL_sorted.23.tab
seqkit tab2fx ANCESTRAL_sorted.23.tab > ANCESTRAL.23.fa

#Chech if it worked fine:
rm kaka.borrar
while read -r SCAFFOLD START STOP SYNTENY ANCESTRAL RUFUS; do
  OLD=$(grep "$SCAFFOLD" LYRU.23.tab | awk '{printf ("%s\n", $4)}' | cut -c$STOP)
  NEW=$(grep "$SCAFFOLD" ANCESTRAL.23.tab | awk '{printf ("%s\n", $4)}' | cut -c$STOP)
  echo -e "$SCAFFOLD\t$STOP\t$RUFUS\t$OLD\t$ANCESTRAL\t$NEW" >> kaka.borrar
 done < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed
#Seems like all key positions have changed correctly, while random ones are still the same.

```

###Add ancestral state reference to the SnpEff database. Annotating against the Ancestral genome is the correct option if the VCF has been polarized based on that genome.
####Add entry to the config file
```{r Set up SnpEff, eval=FALSE, engine='bash'}

#Originally the config was just in the software folder and I didn't have writing permission. If this is the only config file available, writing permission is required, and when annotating later on, the file should be called using the -c command followed by the path to the file.
#However, in my case I believe the tech group created a copy of the file in my folder after I sent them an e-mail, and this is the one that I was able to edit.

cd /home/dkleinman/datos/snpEff
#mv /home/dkleinman/snpEff.config ./ #I move the config file that appeared in my folder to a subfolder that I created for snpEff
vi snpEff.config  #initiate the editing process

#Following the manual, I added the following two lines (use :o to start editing -watch out for the current line- and :wq to save and exit):

# Ancestral lynx genome (parsimony criteria)
LYANCESTRAL.23.genome : Ancestral lynx (parsimony) #from now on, LYANCESTRAL.23 is the snpEff code for the ancestral lynx (parsimony criteria) genome, whose original route is: /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_polarizedfixed/ANCESTRAL.23.fa

```

####Create directory and move files
```{r Set up SnpEff, eval=FALSE, engine='bash'}

#First for the regular annotation:
mkdir /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23 #create a directory inside the software's dependencies whose name matches the code
cd /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23

scp /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23/ #copy the annotation file (can be gff or gtf) to the newly created directory. This gff file includes CDS, introns, exons and genes, so it's very basic. A more complex version that Maria created which includes lncRNAs, etc., will be considered as custom annotation.
mv LYPA23C.all.fix.nr.gff3 genes.gff #rename the file as the tutorial indicates

mkdir -p /home/dkleinman/datos/snpEff/data/genomes #create a directory inside the software's dependencies called genomes
cd /home/dkleinman/datos/snpEff/data/genomes
scp /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_polarizedfixed/ANCESTRAL.23.fa /home/dkleinman/datos/snpEff/data/genomes/LYANCESTRAL.23.fa #copy the reference genome fasta to the new genomes directory

```

####Build the Ancestral genome database
```{r Set up SnpEff, eval=FALSE, engine='bash'}

cd /home/dkleinman/datos/snpEff
screen -S build_LYANCESTRAL_snpEff_db #open a dettachable screen in case the database building takes too long
script build_LYANCESTRAL_snpEff_db.txt #initiate the log file

cd /opt/snpEff
java -jar snpEff.jar build -gff3 -v LYANCESTRAL.23 -c /home/dkleinman/datos/snpEff/snpEff.config -dataDir /home/dkleinman/datos/snpEff/data #build the database. Use the -gff3 command for gff files and -gtf22 for gtf files. Use -v for verbose (expanded information on the processes and the warnings/errors that may appear). Use -c to indicate the path to my own config file. Then use -dataDir to override the data directory from the config file (by default the software thinks that the data folder with the genome and the genes files is located where config is, so it's necessary to give it the correct path).

ctrl + D #terminate the script
ctrl + D #terminate the screen

```

##3: Annotate the VCF.
```{r Annotate using SnpEff, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/
screen -S ${CALLING}
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarizedfixed.lr_ann.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd $O_PATH #run this code from the directory where the config is located.
java -Xmx16g -jar $S_PATH/snpEff.jar LYANCESTRAL.23 -v -s $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.html -csvStats $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.csv -interval $C_PATH/data/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.bed $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.vcf > $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.vcf #run this code from the directory where the config is located.

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
grep -v '#' "${CALLING}_polarizedfixed.lr_ann.vcf" | wc -l 
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671526
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov (XL nr filtered) 5783764
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov (XL nr filtered) 5839239
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov (XL nr filtered) 6312383

```

##4: Filter the annotated VCF. 
###Subset the VCF files in order to keep only good quality biallelic SNP variants.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_filtered_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
#The following short loop defines the OTHER variable as the opposite of the TYPE variable (SNP or INDEL)
if [ $TYPE = "SNP" ]
  then
  OTHER=(INDEL)
elif [ $TYPE = "INDEL" ]
  then
  OTHER=(SNP)
fi

if [ $TYPE != "SNP" ] && [ $TYPE != "INDEL" ] #Don't apply filters if $TYPE is invalid
  then
  echo "Invalid value for variable TYPE"
  echo "Filtering aborted"
  else #Apply filters if $TYPE is valid
  echo "Initializing filtering for $TYPE variants"
  
  if [ -f ${CALLING}"_polarized_filtered1.lr_ann.vcf" ] #Since filter 1 is common for both types of variants, skip it if it's been performed before
    then
    echo "Repetitive and low mappability regions already filtered out"
    echo "Skipping this step"
    else
    #Filter 1: Remove repetitive regions and those with low mappability:
    echo "Filtering out repetitive and low mappability regions"
    bedtools subtract -a ${CALLING}_polarizedfixed.lr_ann.vcf -b /GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/repeats_and_lowcomp_no_redundant_mappability.k75_lessthan90.bed -header | uniq > ${CALLING}_polarized_filtered1.lr_ann.vcf
    
    grep -v '#' ${CALLING}"_polarized_filtered1.lr_ann.vcf" | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671908
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 5783764
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 5839239
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 6312383
    #If the file has more than the unfiltered one it's due to some weird behaviour of bedtools subtract with some INDELs that become duplicated. These will be removed in the subsequent step.

  fi
  #Filter 2: During this step, all multiallelic variants as well as all variants from the other type (SNPs/INDELs) will be dropped from the respective VCFs.
  echo "Filtering out multiallelic variants and $OTHER variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -selectType ${TYPE} \
  -restrictAllelesTo BIALLELIC \
  -R $REF \
  -V ${CALLING}"_polarized_filtered1.lr_ann.vcf" \
  -o ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4782660
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4865867
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4907765
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5237095
  
  #Filter 3: Remove polarized fixed variants (AF=0 or AF=1) or those that weren't polarizable (AA different from either REF or ALT):
  echo "Filtering out non-polarizable and fixed variants"
  $BCF view -e '(INFO/AA!=REF & INFO/AA!=ALT) | INFO/AF=0.00 | INFO/AF=1.00' ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf" > ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4676648
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4758637
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4798043
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5103863
  
  #Filter 4: Apply GATK's recommended hard-filters, and then some.
  echo "Filtering out low quality and unreliable variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -select "QUAL >= 30 && QD >= 2.0 && FS <= 60.0 && MQ >= 40.0 && MQRankSum >= -12.5 && ReadPosRankSum >= -8.0" \
  -R $REF \
  -V ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf" \
  -o ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4548968
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4555453
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4565640
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4710686
  
  #Filter 5: For each species exclude those positions that have more than 15% missing genotypes (i.e. that have low depth in any dataset).
  echo "Filtering out high missingness variants"
  $BCF filter -e "F_MISSING > 0.15" -Ov -o ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf" ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4332653
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4420467
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4439054
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4617432
  
  #Filter 6: Finally, exclude sites that have low depth globally.
  echo "Filtering out low depth variants"
  $BCF filter -e "DP < 200" -Ov -o ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4241437
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4391212
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4412177
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4602025
fi

```

###Separate variants and substitutions.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_separate_variants_substitutions_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)

if [[ $CALLING == "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3"* ]] #the double brackets turns the test into a regex
  then
    for s in ${SPECIES[@]}
      do
      echo "retrieving 1 and 0 positions from ${s}"
      bcftools query -l "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf | cut -c1-12 | sort | uniq | grep "${s}" > "${s}"_samples.txt
      N_SAMPLES=$(cat "${s}"_samples.txt | wc -l)
      #AF_THRES=$(echo "scale=4; ($N_SAMPLES*2-2)/($N_SAMPLES*2)" | bc)
      bcftools view -S "${s}"_samples.txt "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf | bcftools view -i "AC/AN = 0 | AC/AN = 1" -Ov -o "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf #grab only those positions that have AF=0 or AF~1 (more exactly, AF>(num_alleles-2)/num_alleles, i.e. at most one ancestral allele). Use AC/AN instead of AF since the latter isn't recalculated for the subset of samples
      grep -v '#' "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf | cut -f1,2 | awk '{printf ("%s\t%s\t%s\n", $1, $2-1, $2)}' >  "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".bed
      echo "${s} 1 and 0 positions retrieved"
      done
    bedtools intersect -a *c_lp_1_and_0_positions_"$TYPE".bed -b *c_ll_1_and_0_positions_"$TYPE".bed > "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed #inner join (retrieves only positions that have AF=0 or AF=1 in both species simultaneously, dropping from both species those that are variable within any)
    bedtools intersect -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_substitutions_"$TYPE".lr_ann.vcf
    echo "substitutions retrieved"
    bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_variants_"$TYPE".lr_ann.vcf
    echo "variants retrieved"
    grep -v '#' "${CALLING}"_polarized_substitutions_"$TYPE".lr_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 1382501
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 1421816
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 1420110
    grep -v '#' "${CALLING}"_polarized_variants_"$TYPE".lr_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 2858936
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 2969396
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 2992067
    #bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header | grep -v '#' | wc -l #sanity check that counts the number of discarded variants. This number should equal the difference between _filtered6 (not anymore, now filtered6 is a different thing) and _substitutions. It is for both treatments:
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 70598
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 65219
    else
    echo "the code for this calling hasn't been written yet"
  fi

```

###Separate segregating and fixed sites. These are defined at the species level.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_separate_segregating_fixed_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
POPS=$(echo $CALLING | fold -w8 | cut -c1-7 | head -n$N_POPS | sort | uniq)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
FILE=$(echo ${CALLING}_polarized_filteredall_varssubs_${TYPE}.lr_ann.vcf) #This file was generated in section 11 after applying the per dataset depth filtering to the varssubs file.
echo "input file is" $FILE

if [[ $CALLING == "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3"* ]] #the double brackets turns the test into a regex
  then
  for s in ${SPECIES[@]}
    do
    bcftools query -l $FILE | cut -c1-12 | sort | uniq | grep ${s} > ${s}_samples.txt
    echo "retrieving derived varssubs positions for species" $s
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V $FILE \
    -o ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf \
    -env \
    --sample_file ${s}_samples.txt
    VARSSUBS_N=$(grep -v '#' ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf | wc -l) #
    echo "varssubs total is" $VARSSUBS_N
    echo "retrieving derived segregating positions for species" $s
    bcftools view -i "AC/AN > 0 & AC/AN < 1" ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf -Ov -o ${s}_${NM_COV}_persp_segregating_${TYPE}.lr_ann.vcf
    SEGR_N=$(grep -v '#' ${s}_${NM_COV}_persp_segregating_${TYPE}.lr_ann.vcf | wc -l) #
    echo "segregating total is" $SEGR_N
    echo "retrieving derived fixed positions for species" $s
    bcftools view -i "AC/AN = 1" ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf -Ov -o ${s}_${NM_COV}_persp_fixed_${TYPE}.lr_ann.vcf
    FIXED_N=$(grep -v '#' ${s}_${NM_COV}_persp_fixed_${TYPE}.lr_ann.vcf | wc -l) #
    echo "fixed total is" $FIXED_N
    done
  else
  echo "the code for this calling hasn't been written yet"
fi

```

##5: Obtain per dataset VCFs.
###For varssubs, variants and substitutions. All of these should be filtered next.
```{r Obtain per dataset VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perdataset_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

#Define input variant:
if [ $VAR == "varssubs" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf")
elif [ $VAR == "variants" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_variants_"${TYPE}".lr_ann.vcf")
elif [ $VAR == "substitutions" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_substitutions_"${TYPE}".lr_ann.vcf")
else
  INPUT_FILE=()
fi
echo $INPUT_FILE

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
for j in ${DATASETS[@]}
  do
  echo "${j}"
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${j}"_samples
  mkdir -p "${j}"_"${NM_COV}"_perdataset
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V $INPUT_FILE \
  -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" \
  -env \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  grep -v '#' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" | wc -l #
  done

```

###For segregating and fixed (true variants and substitutions). These come from the already filtered varssubs, so steps 6 and 7 should be skipped. Go straight to step 8 after this.
```{r Obtain per dataset VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perdataset_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed

for j in ${DATASETS[@]}
  do
  echo ${j}
  SPECIES=$(echo ${j} | cut -c1-4)
  INPUT_FILE=$(echo ${SPECIES}_${NM_COV}_persp_${VAR}_${TYPE}.lr_ann.vcf)
  echo $INPUT_FILE
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  mkdir -p ${j}_${NM_COV}_perdataset
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V $INPUT_FILE \
  -o ${j}_${NM_COV}_perdataset/${j}_${NM_COV}_perdataset_filtered_${VAR}_${TYPE}.lr_ann.vcf \
  -env \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  grep -v '#' ${j}_${NM_COV}_perdataset/${j}_${NM_COV}_perdataset_filtered_${VAR}_${TYPE}.lr_ann.vcf | wc -l #
  done

```

##6: Depth range calculus. Obtain depth range for each species in order to filter high depth positions as part of the next section's many filterings.
###A: write ANGSD depth calculus and store it as .sh
```{r Depth range calculus, eval=FALSE, engine='bash'}

#I'll modify Maria's code to calculate depth. Since these populations are big, we'll be using Elena's captured intergenic fraction of the genome. Save it as .sh and upload it to the server.

CALLING=$(pwd | rev | cut -d'/' -f1 | cut -d'_' -f2- | rev)
POP=$(echo ${STY#*.} | cut -d'.' -f1)
DATASET=$(echo ${STY#*.} | cut -d'_' -f1,2,3)
COVERAGE=$(echo ${STY#*.} | cut -d'_' -f4)
REF="/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa"
THREADS=10
REGIONFILE="/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf"

awk -F ":|-" '{printf ("%s\n", $3-$2)}' /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf | paste -sd+ | bc

rm "$POP".bamlist
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
SAMPLES=$(cat "$DATASET"_samples)
for var in $SAMPLES; do if [ ${var} = "h_ll_pv_0223" ]; then realpath ${var}_sorted_indelrealigner_marked_sorted.nm*.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; elif [ $COVERAGE = "origcov" ] && [ -e ${var}_recal_round-1_25x.nm3.bam ]; then realpath ${var}_recal_round-1_25x.nm3.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; else realpath ${var}_recal_round-1.nm*.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; fi; done
cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist
BAMLIST="$POP".bamlist

cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
OUT_NAME=/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/$POP.qc
NUMBER_IND=$(printf "%03d" `wc -l $BAMLIST | cut -f1 -d " "`)
MAXDEPTH=$(expr $NUMBER_IND \* 1000)

#Sanity checks: 
ls $BAMLIST
echo $OUT_NAME
echo $NUMBER_IND
echo $MAXDEPTH

angsd \
-P $THREADS \
-b $BAMLIST \
-ref $REF \
-out $OUT_NAME \
-uniqueOnly 1 \
-remove_bads 1 \
-only_proper_pairs 1 \
-rf $REGIONFILE \
-baq 1 \
-C 50 \
-doQsDist 1 \
-doDepth 1 \
-doCounts 1 \
-maxDepth $MAXDEPTH

#Save it in a text editor as depth_calculus_polarizedfixed.sh, upload it to the server, and chmod +x it:
mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed

scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/depth_calculus_polarizedfixed.sh dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/depth_calculus_polarizedfixed.sh

```

###B: define sample sets and run depth calculus 
```{r Depth range calculus, eval=FALSE, engine='bash'}

#Change calling variable
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)

mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NL=$'\n'
for i in ${DATASETS[@]}
  do
    N_SIZE0=$(cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${i}_samples" | wc -l)
    N_SIZE=$(printf "%03d" $N_SIZE0)
    cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
    screen -dmS "${i}_${COVERAGE}_n${N_SIZE}.log"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "script ${i}_${COVERAGE}_n${N_SIZE}.log$NL"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "./depth_calculus_polarizedfixed.sh; exec bash$NL"
    #screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "exit$NL"
    done

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
mkdir -p /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_polarizedfixed
scp dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/*depthGlobal /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_polarizedfixed

```

###C: compile statistics and draw graphs
```{r Depth range calculus}

calling <- "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed"

#Now we use R to plot the depth distribution and to obtain a summary table:

library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)

##Functions:
get_mean <- function(dat) { with(dat, sum(as.numeric(freq)*value)/sum(as.numeric(freq))) }
get_sd <- function(dat) { mu <- get_mean (dat) 
with (dat, sqrt(sum(as.numeric(freq)*(value-mu)^2)/(sum(as.numeric(freq))-1))) } 

#*******************************************************************************************

my_files_depthGlobal = list.files(path = paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling),pattern="*.depthGlobal$") #"5x|GP|MG|LD"

for (i in 1:length(my_files_depthGlobal)) {
  assign(my_files_depthGlobal[i], (scan(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""), sep = " ", dec = ".")) %>% .[!is.na(.)])
  }
mean_folds = 0.95
depth_per_sample <- data.frame()

#Compute globaldepth for all populations found
#*******************************************************************************************

for (i in 1:length(my_files_depthGlobal)) {
  DF = read.table(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""),head=F, stringsAsFactors=F, check.names=FALSE)
  freq_table_DF <- data.frame (value = 1:length (DF), freq = t(DF))
  freq_table_truncated_DF <- filter(freq_table_DF, value < (nrow(freq_table_DF)))
  #Mean depth:
  my_mean_DF <-  get_mean (freq_table_DF)
  my_mean_truncated_DF <- get_mean (freq_table_truncated_DF)
  my_sd_DF <-  get_sd (freq_table_DF)
  my_sd_truncated_DF <- get_sd (freq_table_truncated_DF)
  #Max and min depth:
  maxDepth_DF = my_mean_DF + (mean_folds * my_mean_DF)
  minDepth_DF  = my_mean_DF - (mean_folds * my_mean_DF)
  #maxDepth_truncated_DF = my_mean_truncated_DF + (mean_folds * my_sd_truncated_DF)
  maxDepth_truncated_DF = my_mean_truncated_DF + (3 * my_sd_truncated_DF)
  #minDepth_truncated_DF  = my_mean_truncated_DF - (mean_folds * my_sd_truncated_DF)
  minDepth_truncated_DF = my_mean_truncated_DF - (1 * my_sd_truncated_DF)
  #Para una o más poblaciones:
  population=unlist(strsplit(my_files_depthGlobal[i],"[.]"))[1]
  depth_per_sample <- rbind(depth_per_sample, 
                            data.frame(pop = population,
                                       mean = my_mean_DF,
                                       sd = my_sd_DF, 
                                       mean_truncated = my_mean_truncated_DF,
                                       sd_truncated = my_sd_truncated_DF,
                                       maxDepth = maxDepth_DF, 
                                       minDepth = minDepth_DF,
                                       maxDepth_truncated = maxDepth_truncated_DF,
                                       minDepth_truncated = minDepth_truncated_DF)) 
  #Plotting:
  ggplot(freq_table_truncated_DF, aes(x = value, y = freq)) + 
    geom_bar(stat = "identity", color = "black") +
    scale_x_continuous(breaks = 0:250*10, limits = c(0, maxDepth_truncated_DF*1.5)) +
    scale_y_continuous(expand=c(0,0)) +
    ggtitle (paste(my_files_depthGlobal[i],"_", mean_folds, "_",maxDepth_truncated_DF, "_",maxDepth_DF) ) +
    geom_vline(xintercept=maxDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=maxDepth_truncated_DF, colour ="grey",linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_truncated_DF,colour ="grey",linetype="dashed", size=0.5) + 
    theme_classic() + 
    theme(text = element_text(size=10))
  plot_name=paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],"_",mean_folds,".pdf",sep="")
  ggsave(filename = plot_name)
}

#When finished write the table

#Results for all datasets within a calling are stored in one single dataframe:
write.table(x = depth_per_sample,file = paste("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",calling,"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_",mean_folds,".csv", sep= ""),quote=FALSE, col.names = FALSE, row.names = FALSE, sep= " ")

```

###D: separate for each sample set
```{r Depth range calculus, eval=FALSE, engine='bash'}

#From outside the server, first upload the summary table to the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed)
scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/$CALLING

#In the server, separate in populations:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed)
cd /home/dkleinman/datos/nm_depth_calculus/$CALLING
POPS=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $1}')
for POP in ${POPS[@]}
  do
  echo $POP
  grep "${POP}" /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv > "$POP"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv
  done

```

##7: Perform high-depth filtering. Obtain list of sites with very high depth within each dataset, join them, and remove those sites.
###At the dataset level:
```{r Perform depth filtering, eval=FALSE, engine='bash'}

#For each dataset obtain the list of positions that have lower (higher) depth than the minimum (maximum) within 0.95 of the distribution, as calculated in the previous section, and join them to later remove all of them from all datasets:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_datasets_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
for j in ${DATASETS[@]}
  do
  echo "${j}"
  #MIN_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $9}') #Obtained in section 10
  MAX_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $8}') #Obtained in section 10
  #echo $MIN_DP
  echo $MAX_DP
  $BCF filter -i "DP > ${MAX_DP}" -Ov -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".lr_ann.vcf" ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf"
  sed -e 's/chr//' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".lr_ann.vcf" | awk '{OFS="\t"; if (!/^#/){print $1,$2-1,$2}}' > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #convert from VCF to BED
  done
cat *"_"${NM_COV}"_perdataset/"*"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" | bedtools sort | uniq > ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #join all BEDs
for j in ${DATASETS[@]}
  do
  echo "${j}"
  bedtools subtract -a ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf"
  done
  
```

###At the global level (run the dataset level code first):
```{r Perform depth filtering, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_global_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

if [ $VAR == "varssubs" ]
  then
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".lr_ann.vcf"
  else
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_"${VAR}"_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".lr_ann.vcf"
fi

```

##8: Obtain per population VCFs.
```{r Obtain per population VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perpop_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}_*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
for i in ${DATASETS[@]}
  do
  echo "${i}"
  declare POP=$(bcftools query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" | cut -c1-7 | sort | uniq)
  for j in ${POP[@]}
    do
    echo "${j}"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    $BCF query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" | grep "${j}" > ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    cat ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    mkdir -p "${j}"_"${NM_COV}"_perpop
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" \
    -o ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" \
    -env \
    --sample_file ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    grep -v '#' ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" | wc -l #
    done
  done

```

##9: Split the population VCFs into per individual VCFs. Generate a VCF for each individual.
###Whole-genome.
```{r Split the population VCFs into per individual VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "individual_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
declare POP=$(bcftools query -l ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" | cut -c1-7 | sort | uniq)
for i in ${POP[@]}
  do
  echo "${i}"
  mkdir -p "${i}"_"${NM_COV}"_individuals
  VCF_LIST=$(ls ${i}"_"${NM_COV}"_perpop/"*"_"${i}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf")
  for j in ${VCF_LIST[@]}
    do 
    INDIVIDUALS=$(bcftools query -l "${j}" | sort | uniq)
    for k in ${INDIVIDUALS[@]}
      do
      echo "${k}"
      ID=$(echo "${k}")
      java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
      -T SelectVariants \
      -R $REF \
      -V "${j}" \
      -o ${i}"_"${NM_COV}"_individuals/"${k}"_"${NM_COV}"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" \
      -env \
      -sn $ID
      done
    done
  done

```

##10: Get counts (of variants, substitutions or vars+subs).
###All sites:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/TCRLP_polarizedfixed/provean/parsimonypolar_missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/TCRLP_polarizedfixed/provean/parsimonypolar_missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
  done
rm ${VAR}_*.temp.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.lr_ann.txt

```

###No ref_warnings:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.norefwarn.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".norefwarn.lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".norefwarn.lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for n in "${INDLIST[@]}"
  do
  echo "${n}"
  ind=$(echo "${n}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  grep -v 'WARNING_REF_DOES_NOT_MATCH_GENOME' ${n} > norefwarn.temporary.vcf
  i=norefwarn.temporary.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b !!! /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.norefwarn.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.norefwarn.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b !!! /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.norefwarn.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.norefwarn.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.norefwarn.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.norefwarn.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.norefwarn.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.norefwarn.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".norefwarn.lr_ann.txt"
  done
rm ${VAR}_*.norefwarn.temp.borrar
rm norefwarn.temporary.vcf

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.norefwarn.lr_ann.txt

```

###No warnings:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.nowarn.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for n in "${INDLIST[@]}"
  do
  echo "${n}"
  ind=$(echo "${n}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  grep -v 'WARNING' ${n} > nowarn.temporary.vcf
  i=nowarn.temporary.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b !!! /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.nowarn.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.nowarn.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b !!! /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.nowarn.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.nowarn.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.nowarn.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.nowarn.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.nowarn.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.nowarn.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.lr_ann.txt"
  done
rm ${VAR}_*.nowarn.temp.borrar
rm nowarn.temporary.vcf

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.nowarn.lr_ann.txt

```

##11: Calculate population averages.
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed

#First, generate some headers and info files.
head -n1 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | head -n1) | cut -f-27 > ind_headers.txt #Retrieve headers for files with individuals
cut -f2,5- ind_headers.txt > pop_headers.txt #Retrieve headers for files with populations
tail -n+2 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | head -n1) | cut -f-4 > ids.txt #Retrieve first 4 columns with individual data

#Next, obtain the population average for the empirical data (5x only!!):
cat pop_headers.txt <(gawk '$3=="5x" {N[$2]++; for (i=5;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | cut -f-27)) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt

cut -f1 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | tail -n+2 > pops.txt #Retrieve column with population data

#In order to relativise by the Kirov population average, divide the population average by the Kirov empirical population averages:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | cut -f2-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_5xpopulation_average_TCRLP_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt

```

##12. Plot counts.
###Derived allele counts relative to Kirov.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
variants_and_subst_wg <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_TCRLP_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) 

variants_and_subst_wg$dataset <- as.factor(variants_and_subst_wg$dataset)
variants_and_subst_wg$dataset = factor(variants_and_subst_wg$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
variants_and_subst_wg$population = factor(variants_and_subst_wg$population,levels=c("ki","no","po","sm","do"))
print.data.frame(variants_and_subst_wg)

variants_and_subst_wg_alleleR <- variants_and_subst_wg %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
variants_and_subst_wg_alleleR

r_average_vector <- c()
for (r in unique(variants_and_subst_wg_alleleR$ratio)) {
  print(r)
  r_average <- filter(variants_and_subst_wg_alleleR,r==ratio & population=="ki") %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(variants_and_subst_wg_alleleR,r==ratio))))
}
print(r_average_vector)

relativised_variants_and_subst_wg_alleleR <- mutate(variants_and_subst_wg_alleleR, ki_relative_value=value/r_average_vector)

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_variants_and_subst_wg_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_ki_relative_value"=character(0),"se_ki_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_variants_and_subst_wg_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(relativised_variants_and_subst_wg_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_ki_relative_value","se_ki_relative_value")
    average_relativised_variants_and_subst_wg_alleleR <- rbind(average_relativised_variants_and_subst_wg_alleleR,row_data,stringsAsFactors=F)
  }
}
average_relativised_variants_and_subst_wg_alleleR$population = factor(average_relativised_variants_and_subst_wg_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_relativised_variants_and_subst_wg_alleleR$population)[levels(average_relativised_variants_and_subst_wg_alleleR$population)=="sm"] <- "an"
average_relativised_variants_and_subst_wg_alleleR$ratio = factor(average_relativised_variants_and_subst_wg_alleleR$ratio,levels=c("total","intergenic","intronic","synonymous","syn_pref","syn_unpref","missense","missense_tol","missense_del","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high"))
levels(average_relativised_variants_and_subst_wg_alleleR$ratio) <- c("total","intergenic","introns","synonymous","synonymous_pref","synonymous_unpref","missense","missense_tolerated","missense_deleterious","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high")
average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR
#(average_relativised_variants_and_subst_wg_alleleR,paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/",type,"_derived_allele_allele_ratio_relative2introns_mean.csv"))

#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.60,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

average_relativised_derived_allele_allele_ratio_up <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('total|intergenic|introns|\\<synonymous\\>',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_up

average_relativised_derived_allele_allele_ratio_middle <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('\\<missense\\>|nonsense|^UCNE$',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_middle

average_relativised_derived_allele_allele_ratio_down <- ggplot(filter(average_relativised_variants_and_subst_wg_alleleR,grepl('_tolerated|_deleterious|_mid|_high',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  #ylab("Average genetic load relative to ki") +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_down


average_relativised_derived_allele_allele_ratio_combined <- grid.arrange(set_panel_size(average_relativised_derived_allele_allele_ratio_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_middle,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_down,width=unit(4.5,"cm"),height=unit(10,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))

ggsave(paste0(type,"_TCRLP_genetic_load_relative2Kirov_definitive.pdf"), width=26, height=38, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",average_relativised_derived_allele_allele_ratio_combined)

```

###Derived allele counts 5xonly manuscript version.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
averages <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_5xpopulation_average_TCRLP_",type,"_SNP.empirmean_ki_rel.lr_ann.txt")) %>% select(.,population,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) %>% mutate(species=ifelse(population=="ki" | population=="po" | population=="no","ll","lp"),size=ifelse(population=="ki" | population=="sm","large","small"))
averages$population = factor(averages$population,levels=c("ki","no","po","sm","do"))
averages$species = factor(averages$species,levels=c("ll","lp"))
averages$size = factor(averages$size,levels=c("large","small"))
print.data.frame(averages)

averages_tidy <- averages %>% gather(ratio,value,-population,-species,-size,factor_key=T)
averages_tidy

colnames(averages_tidy) <- c("population","species","size","ratio","mean")
averages_tidy$ratio <- gsub('intronic', 'introns', averages_tidy$ratio)
averages_tidy$ratio <- gsub('coding', 'CDS', averages_tidy$ratio)
averages_tidy$ratio <- gsub('synonymous', 'syn.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_tol', 'm. tol.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_del', 'm. del.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('nonsense', 'LoF', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_low', 'UCNE low', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_mid', 'UCNE mod.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_high', 'UCNE high', averages_tidy$ratio)
averages_tidy$population = factor(averages_tidy$population,levels=c("ki","po","no","sm","do"))
levels(averages_tidy$population) <- c("KIR","POL","NOR","AND","DON")
#levels(averages_tidy$population)[levels(averages_tidy$population)=="sm"] <- "an"
averages_tidy$ratio = factor(averages_tidy$ratio,levels=c("total","intergenic","introns","CDS","syn.","syn_pref","syn_unpref","missense","m. tol.","m. del.","LoF","UCNE","UCNE low","UCNE mod.","UCNE high")) 


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.6,0.6,0.5,0.5),"max"=c(1.2,1.5,2,4),"breaks"=c(0.1,0.1,0.2,0.5))

ggplot_up <- ggplot(data=filter(averages_tidy,grepl('total|intergenic|introns|syn\\.',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_up

ggplot_middle <- ggplot(data=filter(averages_tidy,grepl('\\<missense\\>|LoF|^UCNE$',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_middle

ggplot_down <- ggplot(data=filter(averages_tidy,grepl('tol|del|mod|high',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_down

#New:
if(type=="varssubs") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_middle,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_down,width=unit(1.65,"cm"),height=unit(4,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=10,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))
} else if (type=="fixed") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(ggplot_down,width=unit(4.5,"cm"),height=unit(10,"cm")),set_panel_size(ggplot_other,width=unit(4.5,"cm"),height=unit(10,"cm")),widths=c(4,2.3,0.2),layout_matrix=rbind(c(1,1,NA),c(2,NA,3)),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Derived fixation rate relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))
}

#New:
ggsave(paste0(type,"_TCRLP_genetic_load_5xrelative2Kirov_manuscriptlike.pdf"), width=8.2, height=17, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_combined)

```

##13: Derived allele count spectrum.
###Combine per population and feature allele count files:
####All sites, and consistent sites
```{r Calculate derived allele frequency ratio, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_derived_counts_spectrum_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
 
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
mkdir -p derived_allele_counts_spectrum
scp /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt 
GREP=$(cat derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f1)
POP_VCFS=($(ls `find . -path *"_perpop/c_*5x*_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
rm ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
for p in ${POP_VCFS[@]}
  do
  SP_DATASET=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f1-3)
  SHORT_POP=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f4-6)
  echo "working with pop" $SHORT_POP "and vcf" $p
  echo "extracting derived allele counts from" $SHORT_POP
  for g in ${GREP[@]}
    do
    #echo "grepping: ${g}"
    FEATURE=$(grep "${g}" derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f2)
    echo "extracting from feature:" $FEATURE
    grep "${g}" "${p}" | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$11)}' > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}
    echo "joining frequency files"
    awk -v pop="$SHORT_POP" -v feat="$FEATURE" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
    if [ $FEATURE == "NSYN" ]
      then
      FEATURE2=(NTOL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/provean/parsimonypolar_missense_variants_provean_scores_tolerated.txt > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE2}_${TYPE}.lr_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE2"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
      FEATURE2=(NDEL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/provean/parsimonypolar_missense_variants_provean_scores_deleterious.txt > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE2}_${TYPE}.lr_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE2"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
    fi
    done
  done

#Generate version with consistent polarised sites only.
bedtools intersect -a <(awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $3,$4,$5,$6,$1,$2)}' ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac") -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/consistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $5,$6,$1,$2,$3,$4)}' > ${CALLING}"_5x_perpop_ALL_features_consistent_"${VAR}"_"${TYPE}".lr_ann.ac"


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/*5x_perpop_ALL_features_${VAR}_${TYPE}.lr_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/*5x_perpop_ALL_features_consistent_${VAR}_${TYPE}.lr_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/

```

####Perfect-coverage sites only:
```{r Calculate derived allele frequency ratio, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_derived_counts_spectrum_perfectcov_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
 
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
#mkdir -p derived_allele_counts_spectrum
#scp -p /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt 
GREP=$(cat derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f1)
POP_VCFS=($(ls `find . -path *"_perpop/c_*5x*_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
rm ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".lr_ann.ac"
for p in ${POP_VCFS[@]}
  do
  SP_DATASET=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f1-3)
  SHORT_POP=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f4-6)
  echo "working with pop" $SHORT_POP "and vcf" $p
  echo "extracting derived allele counts from" $SHORT_POP
  N_MAX=$((2 * $(bcftools query -l ${p} | wc -l)))
  for g in ${GREP[@]}
    do
    #echo "grepping: ${g}"
    FEATURE=$(grep "${g}" derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f2)
    echo "extracting from feature:" $FEATURE
    grep "${g}" "${p}" | grep ";AN=${N_MAX}" | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$11)}' > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}
    echo "joining frequency files"
    awk -v pop="$SHORT_POP" -v feat="$FEATURE" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_perfectcov_"$VAR"_"$FEATURE"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".lr_ann.ac"
    if [ $FEATURE == "NSYN" ]
      then
      FEATURE2=(NTOL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/provean/parsimonypolar_missense_variants_provean_scores_tolerated.txt > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE2}_${TYPE}.lr_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_perfectcov_"$VAR"_"$FEATURE2"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".lr_ann.ac"
      FEATURE2=(NDEL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/provean/parsimonypolar_missense_variants_provean_scores_deleterious.txt > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE2}_${TYPE}.lr_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_perfectcov_"$VAR"_"$FEATURE2"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".lr_ann.ac"
    fi
    done
  done

#Generate version with consistent polarised sites only.
bedtools intersect -a <(awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $3,$4,$5,$6,$1,$2)}' ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".lr_ann.ac") -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/consistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $5,$6,$1,$2,$3,$4)}' > ${CALLING}"_5x_perpop_ALL_features_perfectcov_consistent_"${VAR}"_"${TYPE}".lr_ann.ac"


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/*5x_perpop_ALL_features_perfectcov_${VAR}_${TYPE}.lr_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/*5x_perpop_ALL_features_perfectcov_consistent_${VAR}_${TYPE}.lr_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/

```

###Plot spectra:
####Whole dataset.
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP", pattern="*ALL_features*"),pattern='consistent', invert=T, value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- data_frame("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")
  }
}

```

####Consistent polarisation only:
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP", pattern="*ALL_features*"),pattern='consistent', value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- tibble("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_consistent_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_consistent_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_consistent_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_consistent_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
  }
}

```

####Perfect-coverage only:
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP", pattern="*ALL_features*"),pattern='perfectcov', value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- tibble("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_perfectcov_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_perfectcov_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_perfectcov_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_perfectcov_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
  }
}

```

#Tiger-cat-rufus-lynx-pardinus with outgroup parsimony:
##1. Infer ancestral state by parsimony:
###Solve small parsimony problem:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/

#Considering a tree with the following nodes: #1 tiger (T), #2 cat (C), #3 bobcat (R), #4 Eurasian lynx (L), #5 Iberian lynx (P), #6 LxP, #7 (LxP)xR, #8 ((LxP)xR)xC, #9 (((LxP)xR)xC)xT:
ALLELE_LIST=("TTTTA" "TTATA" "TATTA" "ATTTA" "NTTTA" "NTATA" "NATTA")
echo -e "TREE\tPARSIMONY_COST\tANCESTRAL_ROOT\tANCESTRAL_OUTGROUP" > ${CALLING}_parsimony_solutions.txt
for ALLELES in "${ALLELE_LIST[@]}"
  do
  echo $ALLELES
  #FITCH ALGORITHM (ROOT-FOCUSED):
  ##Phase 1 (N variables contain the possible alleles in the node; L variables contain the parsimony cost of the node; C variables compare the child nodes):
  N1=$(echo $ALLELES | cut -c1)
  L1=$((${#N1} - 1))
  N2=$(echo $ALLELES | cut -c2)
  L2=$((${#N2} - 1))
  N3=$(echo $ALLELES | cut -c3)
  L3=$((${#N3} - 1))
  N4=$(echo $ALLELES | cut -c4)
  L4=$((${#N4} - 1))
  N5=$(echo $ALLELES | cut -c5)
  L5=$((${#N5} - 1))
  C6=$(comm -12 <(fold -w1 <<< $N4 | sort -u) <(fold -w1 <<< $N5 | sort -u) | tr -d '\n')
  N6=$(if [ -z $C6 ]; then echo $N4$N5; else echo $C6; fi)
  L6=$(($L4 + $L5 + ${#N6} - 1))
  C7=$(comm -12 <(fold -w1 <<< $N3 | sort -u) <(fold -w1 <<< $N6 | sort -u) | tr -d '\n')
  N7=$(if [ -z $C7 ]; then echo $N3$N6; else echo $C7; fi)
  L7=$(($L3 + $L6 + ${#N7} - 1))
  C8=$(comm -12 <(fold -w1 <<< $N2 | sort -u) <(fold -w1 <<< $N7 | sort -u) | tr -d '\n')
  N8=$(if [ -z $C8 ]; then echo $N2$N7; else echo $C8; fi)
  L8=$(($L2 + $L7 + ${#N8} - 1))
  C9=$(comm -12 <(fold -w1 <<< $N1 | sort -u) <(fold -w1 <<< $N8 | sort -u) | tr -d '\n')
  N9=$(if [ -z $C9 ]; then echo $N1$N8; else echo $C9; fi)
  L9=$(($L1 + $L8 + ${#N9} - 1))
  ##Phase 2 (Z variables compare with the parent node; A variables contain the ancestral assignment for the node):
  A9=$(if [ ${#N9} -ge 2 ]; then echo "N"; else echo $N9; fi)
  Z8=$(comm -12 <(fold -w1 <<< $N8 | sort -u) <(fold -w1 <<< $N9 | sort -u) | tr -d '\n')
  A8=$(if [ -z $Z8 ]; then echo "N"; elif [ ${#Z8} -ge 2 ]; then echo "N"; else echo $Z8; fi)
  Z7=$(comm -12 <(fold -w1 <<< $N7 | sort -u) <(fold -w1 <<< $N8 | sort -u) | tr -d '\n')
  A7=$(if [ -z $Z7 ]; then echo "N"; else echo $Z7; fi)
  Z6=$(comm -12 <(fold -w1 <<< $N6 | sort -u) <(fold -w1 <<< $N7 | sort -u) | tr -d '\n')
  A6=$(if [ -z $Z6 ]; then echo "N"; else echo $Z6; fi)
  if [ $N1 == "N" ]; then echo "parsimony cost of the tree is" $L8; else echo "parsimony cost of the tree is" $L9; fi
  if [ $N1 == "N" ]; then echo "most parsimonious root is" $A8 ; else echo "most parsimonious root is" $A9 "then" $A8; fi

  #OUTGROUP ALGORITHM (OUTGROUP-FOCUSED):
  ##Phase 1 (N variables contain the possible alleles in the node; L variables contain the parsimony cost of the node; C variables compare the child nodes):
  N1=$(echo $ALLELES | cut -c1)
  N2=$(echo $ALLELES | cut -c2)
  N3=$(echo $ALLELES | cut -c3)
  N4=$(echo $ALLELES | cut -c4)
  N5=$(echo $ALLELES | cut -c5)
  C6=$(comm -12 <(fold -w1 <<< $N4 | sort -u) <(fold -w1 <<< $N5 | sort -u) | tr -d '\n')
  N6=$(if [ -z $C6 ]; then echo $N4$N5; else echo $C6; fi)
  C8=$(comm -12 <(fold -w1 <<< $N1 | sort -u) <(fold -w1 <<< $N2 | sort -u) | tr -d '\n')
  N8=$(if [ -z $C8 ]; then echo $N1$N2; else echo $C8; fi)
  C7=$(comm -12 <(fold -w1 <<< $N3 | sort -u) <(fold -w1 <<< $N8 | sort -u) | tr -d '\n')
  N7=$(if [ -z $C7 ]; then echo $N3$N8; else echo $C7; fi)
  ##Phase 2 (Z variables compare with the parent node; A variables contain the ancestral assignment for the node):
  Z6=$(comm -12 <(fold -w1 <<< $N6 | sort -u) <(fold -w1 <<< $N7 | sort -u) | tr -d '\n')
  A6=$(if [ ${#N6} -ge 2 ]; then echo "N"; elif [ -z $C7 ]; then echo $N6; else echo $N6; fi)
  A7=$(if [ ${#N7} -ge 2 ]; then echo "N"; else echo $N7; fi)
  echo "most parsimonious outer group is" $A7
  if [ $N1 == "N" ]
    then echo -e "$ALLELES\t$L8\t$A8\t$A7" >> ${CALLING}_parsimony_solutions.txt
    else echo -e "$ALLELES\t$L9\t$A9\t$A7" >> ${CALLING}_parsimony_solutions.txt
  fi
  done

```

###Apply the solution to my dataset:
```{bash}

cd /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani

#First, retrieve only informative sites (i.e. variants in my VCF). Don't run this if it was run before.
bedtools intersect -a ../lynx2cat_wTiger.sorted.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf > lynx2cat_wTiger.sorted.dani_variants.bed

#Next, extract the Lynx lynx state (from the Lynx lynx "reference genome"):
bedtools getfasta -fi /GRUPOS/grupolince/reference_genomes/lynx_lynx_genome/LynxLynx_SNVsOnly.fa -bed lynx2cat_wTiger.sorted.dani_variants.bed -tab -fo lynxlynx_reference.sorted.dani_variants.txt

awk -F"\t|:|-" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' lynxlynx_reference.sorted.dani_variants.txt > lynxlynx_reference.sorted.dani_variants.bed

#Next, add the Lynx lynx state to the file with the other species, which was generated in chunk 0 of the TCRP section.
bedtools intersect -a lynx2cat_wTiger_wRufusstep1.sorted.dani_variants.bed -b lynxlynx_reference.sorted.dani_variants.bed -wb | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8)}' > lynx2cat_wTiger_wRufus_wLynxstep0.sorted.dani_variants.bed

#Next, integrate the Lynx lynx state together with the others in a single column. Rename TCRP (tiger, cat, rufus, pardinus) as TCRLP (tiger, cat, rufus, lynx, pardinus).
awk -F"\t|=|:" '{printf ("%s\t%s\t%s\t%s=%s%s%s:%s:%s\n", $1,$2,$3,"TCRLP",substr($5,1,3),$8,substr($5,4,4),$6,$7)}' lynx2cat_wTiger_wRufus_wLynxstep0.sorted.dani_variants.bed > lynx2cat_wTiger_wRufus_wLynxstep1.sorted.dani_variants.bed

#Next, apply parsimony criteria to infer the ancestral state, and print the scaffold, position, new ancestral state and previous ancestral state (i.e. the Lynx rufus base). The logic behind this code is extracted from the results for the previous section. The Iberian and Eurasian lynx base is ignored here (because all sites in my VCF are polymorphic in one or both species, or alternative substitutions).
awk '{                                       
split($0,a,":");
split(a[1],b,"=");
split(b[2],c,"");
if (c[1]==c[2] && c[1]==c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]); #TCR* all equal
else if (c[1]==c[2] && c[1]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,"N",c[3]); #TC vs R null
else if (c[1]==c[3] && c[1]!=c[2]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]); #TR* vs C
else if (c[2]==c[3] && c[1]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]); #CR* vs T

else if ((c[1]=="?" || c[1]=="-") && c[2]==c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,c[3],c[3]); #CR* all equal
else if ((c[1]=="?" || c[1]=="-") && c[2]!=c[3]) printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,"N",c[3]); #C vs R null

else printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,"N",c[3]); #others null
}' lynx2cat_wTiger_wRufus_wLynxstep1.sorted.dani_variants.bed > /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/

#Generate file with consistent sites (sites where the polarisation doesn't change).
awk '$5==$6 {print $0}' ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed > consistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed

#Generate file with inconsistent sites (wrongly polarised or unpolarisable).
awk '$5!=$6 {print $0}' ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed > inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed

#Global checks:
##Check number of sites with a polarisation change between TCP and TCLRP:
awk '$5!=$6 {print $0}' ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | wc -l #142650
##Check number of sites with a polarisation change between TCRP and TCLRP:
paste /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRP_polarizedfixed/ancestral_state_tiger_cat_rufus_pardinus.sorted.dani_variants.bed ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | awk '$5!=$11 {print $0}' | wc -l #192640
##Check number of sites with a polarisation change between TCRLP and wrong TCLRP:
paste /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_polarizedfixed/ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | awk '$5!=$11 {print $0}' | wc -l #164443

##Number of variants in my vcf:
grep -v '#' /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf | wc -l #4388391
##Number of syntenic variants in the TCRLP file:
wc -l < ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed #3899717 (88.9% of all variants)
##Of which inconsistent:
wc -l < inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed #142650 (3.66% of the syntenic variants)
###Of which wrongly polarised:
awk '$5!="N" {print $0}' inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | wc -l #0
###And unsolvable:
awk '$5=="N" {print $0}' inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | wc -l #142650 (3.66% of the syntenic variants)

#Misdel checks:
##Number of misdel variants in my vcf:
bedtools intersect -a /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #9193
##Number of syntenic misdel variants in the TCRLP file:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #8532 (92.8% of all variants)
##Of which inconsistent:
bedtools intersect -a inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt | wc -l #25 (0.27% of all misdel variants and 0.29% of the syntenic variants)

```

##2: Adjust polarisation.
###Replace inconsistent AA.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#First make two subset VCFs: one with the inconsistent sites, and one with the rest (which includes all consistent sites as well as all those such as INDELs or triallelic that were eventually filtered out).
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony

bedtools subtract -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_consistent_and_filteredout_sites.vcf

bedtools intersect -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites.vcf

#Discard INDELs from the inconsistent sites VCF in order to avoid duplicate rows, which can mess up the subsequent re-polarisation loop.
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_inconsistent_sites.vcf \
-o ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

grep -v '#' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf > ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf
mv ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

#Discard INDELs from the consistent sites VCF to be able to later paste it with the inconsistent one (because the AA column shifts place when the file is parsed by GATK).
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_consistent_and_filteredout_sites.vcf \
-o ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf

#Next, fix the AA annotation for the inconsistent sites.
screen -S "${CALLING}-aafilled_pars"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script "${CALLING}-aafilled_outerparsimony.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)

#For sites with an inconsistent polarisation between the old and the new parsimony (as inferred above), replace the previously inferred AA ("old") with the newly inferred one ("new").
rm c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites_SNP_outerparsimony.vcf
TOTAL=$(wc -l < inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed)
COUNTER=0
while read -r row
  do
  ((COUNTER++))
  #PATTERN=$(echo "$row" | awk -F"\t" '{printf ("%s\t%s\n", $1,$3)}')
  #SCAFFOLD=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $1)}')
  #POSITION=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $3)}')
  OLD_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$6)}')
  NEW_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$5)}')
  #sed -n '/^'"$PATTERN"'/{s/'"$OLD_AA"'/'"$NEW_AA"'/;p;q}' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf >> ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf
  sed "${COUNTER}q;d" ${CALLING}_aafilled_inconsistent_sites_SNP.vcf | sed 's/'"$OLD_AA"'/'"$NEW_AA"'/' >> ${CALLING}_aafilled_inconsistent_sites_SNP_outerparsimony.vcf
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "fixed polarization of $COUNTER sites out of $TOTAL"
  fi
  done < inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed

---

bedtools sort -i <(cat ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf ${CALLING}_aafilled_inconsistent_sites_SNP_outerparsimony.vcf) -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_outerparsimony_SNP.vcf

```

###Use VcfFilterJdk to polarize the AA-filled VCF.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#Polarize the AA-filled VCF based on the new INFO/AA column. Alleles will be switched whenever the ancestral allele matches the alternative one, and genotypes will be properly recoded as well. The following code was originally provided by Pierre Lindenbaum and modified by José Luis Castro.

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/
screen -S ${CALLING}-polarized_outerpars
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarized_outerparsimony.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


java -jar /opt/jvarkit/dist/vcffilterjdk.jar -e 'if(variant.getNAlleles()!=2 || !variant.hasAttribute("AA")) return true; 
final String aa = variant.getAttributeAsString("AA",""); 
if(!variant.getAlleles().get(1).getDisplayString().equalsIgnoreCase(aa)) return true; 
VariantContextBuilder vb=new VariantContextBuilder(variant); 

Allele oldalt = variant.getAlleles().get(1);
Allele oldref = variant.getAlleles().get(0); 
Allele ref= Allele.create(oldalt.getDisplayString(),true); 
Allele alt= Allele.create(oldref.getDisplayString(),false);

vb.alleles(Arrays.asList(ref,alt)); 

List genotypes= new ArrayList<>(); 
for(Genotype g: variant.getGenotypes()) 
  { 
  if(!g.isCalled()) 
  { genotypes.add(g); continue;} 
  GenotypeBuilder gb = new GenotypeBuilder(g); 
  List alleles = new ArrayList<>(); 
  for(Allele a:g.getAlleles()) { 
    if(a.equals(oldalt)) { a=ref;} 
    else if(a.equals(oldref)) { a=alt;} 
    alleles.add(a); 
    } 
  if(g.hasPL()) { 
    int pl[] = g.getPL(); 
    int pl2[] = new int[pl.length]; 
    for(int i=0;i< pl.length;i++) pl2[i]=pl[(pl.length-1)-i]; 
    gb.PL(pl2); 
    } 
  if(g.hasAD()) 
    { int ad[] = g.getAD(); 
    int ad2[] = new int[ad.length]; 
    for(int i=0;i< ad.length;i++) ad2[i]=ad[(ad.length-1)-i];
    gb.AD(ad2); 
  } 
  genotypes.add(gb.alleles(alleles).make()); 
  }

vb.attribute("AF",1.0d - Double.parseDouble(variant.getAttributeAsString("AF",""))); vb.attribute("AC",variant.getGenotypes().stream().flatMap(G->G.getAlleles().stream()).filter(A->A.equals(oldref)).count()); 
vb.genotypes(genotypes); 
return vb.make();' -o ${CALLING}_polarized_outerparsimony.vcf ${CALLING}_aafilled_outerparsimony_SNP.vcf

```

###Generate ancestral state fasta reference.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/

#Transform fasta to tab (not really tab separated, only the last column) format to ease the editing.
seqkit fx2tab /home/datos_usuarios/dkleinman/snpEff/data/genomes/LYRU.23.fa > LYRU.23.tab

#Next, edit the Rufus fasta in order to generate the Ancestral fasta:
screen -S generating_ancestral_fasta
script generating_ancestral_fasta.log
rm ANCESTRAL.23.tab
#First copy all the scaffolds that will remain unchanged:
grep -v -f <(cut -f1 inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | sort | uniq) LYRU.23.tab | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > ANCESTRAL.23.tab
#Next loop over the inconsistent variants (those for which the polarisation is the reverse or are now deemed unpolarisable), grep the scaffold which they belong to, edit the base, and use that file as the input for the next variant in the same scaffold
COUNTER=0
PREV_SCAFFOLD=("lp23.s00000")
OLD_SCAFFOLD=$(head -n1 LYRU.23.tab | awk '{printf ("%s\n",$1)}')
TOTAL=$(wc -l < inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed)
while read -r SCAFFOLD START STOP SYNTENY ANCESTRAL RUFUS; do
  #If this is the first variant in the scaffold, grep the Rufus sequence from that scaffold to use as input.
  if [[ "$SCAFFOLD" != "$PREV_SCAFFOLD" ]]
    then
    grep "$SCAFFOLD" LYRU.23.tab > $SCAFFOLD.LYRU.23.tab
    echo "generating input file for scaffold" $SCAFFOLD
  fi
  PREV_SCAFFOLD=$SCAFFOLD
  #Print the sequence replacing only the current variant, and replace the previous input with this output:
  awk -v stop=$STOP -v ancestral=$ANCESTRAL '{printf ("%s\t%s\t%s\t%s%s%s\n", $1,$2,$3,substr($4,1,stop-1),ancestral,substr($4,stop+1))}' $SCAFFOLD.LYRU.23.tab > $SCAFFOLD.tmp && mv $SCAFFOLD.tmp $SCAFFOLD.LYRU.23.tab
  #If there is a change in scaffold, the editing of the previous scaffold is now complete and can be appended to the new ancestral file.
  if [[ "$SCAFFOLD" != "$OLD_SCAFFOLD" ]]
    then
    cat $OLD_SCAFFOLD.LYRU.23.tab >> ANCESTRAL.23.tab
    echo "advancing to scaffold" $SCAFFOLD
    rm $OLD_SCAFFOLD.LYRU.23.tab
  fi
  OLD_SCAFFOLD=$SCAFFOLD
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER sites out of $TOTAL"
  fi
 done < inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed
#The editing of the last scaffold is now complete and can be appended to the new ancestral file.
SCAFFOLD=$(tail -n1 inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | awk '{printf ("%s\n",$1)}')
cat $SCAFFOLD.LYRU.23.tab >> ANCESTRAL.23.tab
rm $SCAFFOLD.LYRU.23.tab

--------->

#Sort the ancestral file so that scaffolds regain their order, and place the field separators used by seqkit (two white spaces, one white space, and one tab, respectively), in order to convert it back to fasta format:
sort -k1,1 ANCESTRAL.23.tab | awk '{printf ("%s  %s %s\t%s\n", $1,$2,$3,$4)}' > ANCESTRAL_sorted.23.tab
seqkit tab2fx ANCESTRAL_sorted.23.tab > ANCESTRAL.23.fa

#Chech if it worked fine:
rm kaka.borrar
while read -r SCAFFOLD START STOP SYNTENY ANCESTRAL RUFUS; do
  OLD=$(grep "$SCAFFOLD" LYRU.23.tab | awk '{printf ("%s\n", $4)}' | cut -c$STOP)
  NEW=$(grep "$SCAFFOLD" ANCESTRAL.23.tab | awk '{printf ("%s\n", $4)}' | cut -c$STOP)
  echo -e "$SCAFFOLD\t$STOP\t$RUFUS\t$OLD\t$ANCESTRAL\t$NEW" >> kaka.borrar
 done < inconsistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed
#Seems like all key positions have changed correctly, while random ones are still the same.

```

###Add ancestral state reference to the SnpEff database. Annotating against the Ancestral genome is the correct option if the VCF has been polarized based on that genome.
####Add entry to the config file
```{r Set up SnpEff, eval=FALSE, engine='bash'}

#Originally the config was just in the software folder and I didn't have writing permission. If this is the only config file available, writing permission is required, and when annotating later on, the file should be called using the -c command followed by the path to the file.
#However, in my case I believe the tech group created a copy of the file in my folder after I sent them an e-mail, and this is the one that I was able to edit.

cd /home/dkleinman/datos/snpEff
#mv /home/dkleinman/snpEff.config ./ #I move the config file that appeared in my folder to a subfolder that I created for snpEff
vi snpEff.config  #initiate the editing process

#Following the manual, I added the following two lines (use :o to start editing -watch out for the current line- and :wq to save and exit):

# Ancestral lynx genome (parsimony criteria)
LYANCESTRAL.23.genome : Ancestral lynx (parsimony) #from now on, LYANCESTRAL.23 is the snpEff code for the ancestral lynx (parsimony criteria) genome, whose original route is: /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/ANCESTRAL.23.fa

```

####Create directory and move files
```{r Set up SnpEff, eval=FALSE, engine='bash'}

#First for the regular annotation:
mkdir -p /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23 #create a directory inside the software's dependencies whose name matches the code
cd /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23

scp /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23/ #copy the annotation file (can be gff or gtf) to the newly created directory. This gff file includes CDS, introns, exons and genes, so it's very basic. A more complex version that Maria created which includes lncRNAs, etc., will be considered as custom annotation.
mv LYPA23C.all.fix.nr.gff3 genes.gff #rename the file as the tutorial indicates

mkdir -p /home/dkleinman/datos/snpEff/data/genomes #create a directory inside the software's dependencies called genomes
cd /home/dkleinman/datos/snpEff/data/genomes
scp /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/ANCESTRAL.23.fa /home/dkleinman/datos/snpEff/data/genomes/LYANCESTRAL.23.fa #copy the reference genome fasta to the new genomes directory

```

####Build the Ancestral genome database
```{r Set up SnpEff, eval=FALSE, engine='bash'}

cd /home/dkleinman/datos/snpEff
screen -S build_LYANCESTRAL_snpEff_db #open a dettachable screen in case the database building takes too long
script build_LYANCESTRAL_snpEff_db.txt #initiate the log file

cd /opt/snpEff
java -jar snpEff.jar build -gff3 -v LYANCESTRAL.23 -c /home/dkleinman/datos/snpEff/snpEff.config -dataDir /home/dkleinman/datos/snpEff/data #build the database. Use the -gff3 command for gff files and -gtf22 for gtf files. Use -v for verbose (expanded information on the processes and the warnings/errors that may appear). Use -c to indicate the path to my own config file. Then use -dataDir to override the data directory from the config file (by default the software thinks that the data folder with the genome and the genes files is located where config is, so it's necessary to give it the correct path).

ctrl + D #terminate the script
ctrl + D #terminate the screen

```

##3: Annotate the VCF.
```{r Annotate using SnpEff, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/
screen -S ${CALLING}
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarized_outerparsimony.anc_ann.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd $O_PATH #run this code from the directory where the config is located.
java -Xmx16g -jar $S_PATH/snpEff.jar LYANCESTRAL.23 -v -s $V_PATH/$CALLING/TCRLP_outerparsimony/${CALLING}_polarized_outerparsimony.anc_ann.html -csvStats $V_PATH/$CALLING/TCRLP_outerparsimony/${CALLING}_polarized_outerparsimony.anc_ann.csv -interval $C_PATH/data/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.bed $V_PATH/$CALLING/TCRLP_outerparsimony/${CALLING}_polarized_outerparsimony.vcf > $V_PATH/$CALLING/TCRLP_outerparsimony/${CALLING}_polarized_outerparsimony.anc_ann.vcf #run this code from the directory where the config is located.

cd $V_PATH/$CALLING/TCRLP_outerparsimony
grep -v '#' ${CALLING}_polarized_outerparsimony.anc_ann.vcf | wc -l 
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671526
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov (XL nr filtered) 5783764
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov (XL nr filtered) 5839239
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov (XL nr filtered) 6312383

```

##4: Filter the annotated VCF. 
###Subset the VCF files in order to keep only good quality biallelic SNP variants.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_filtered_${TYPE}.anc_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
#The following short loop defines the OTHER variable as the opposite of the TYPE variable (SNP or INDEL)
if [ $TYPE = "SNP" ]
  then
  OTHER=(INDEL)
elif [ $TYPE = "INDEL" ]
  then
  OTHER=(SNP)
fi

if [ $TYPE != "SNP" ] && [ $TYPE != "INDEL" ] #Don't apply filters if $TYPE is invalid
  then
  echo "Invalid value for variable TYPE"
  echo "Filtering aborted"
  else #Apply filters if $TYPE is valid
  echo "Initializing filtering for $TYPE variants"
  
  if [ -f ${CALLING}"_polarized_filtered1.anc_ann.vcf" ] #Since filter 1 is common for both types of variants, skip it if it's been performed before
    then
    echo "Repetitive and low mappability regions already filtered out"
    echo "Skipping this step"
    else
    #Filter 1: Remove repetitive regions and those with low mappability:
    echo "Filtering out repetitive and low mappability regions"
    bedtools subtract -a ${CALLING}_polarized_outerparsimony.anc_ann.vcf -b /GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/repeats_and_lowcomp_no_redundant_mappability.k75_lessthan90.bed -header | uniq > ${CALLING}_polarized_filtered1.anc_ann.vcf
    
    grep -v '#' ${CALLING}"_polarized_filtered1.anc_ann.vcf" | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671908
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 5783764
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 5839239
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 6312383
    #If the file has more than the unfiltered one it's due to some weird behaviour of bedtools subtract with some INDELs that become duplicated. These will be removed in the subsequent step.

  fi
  #Filter 2: During this step, all multiallelic variants as well as all variants from the other type (SNPs/INDELs) will be dropped from the respective VCFs.
  echo "Filtering out multiallelic variants and $OTHER variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -selectType ${TYPE} \
  -restrictAllelesTo BIALLELIC \
  -R $REF \
  -V ${CALLING}"_polarized_filtered1.anc_ann.vcf" \
  -o ${CALLING}"_polarized_filtered2_"${TYPE}".anc_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered2_"${TYPE}".anc_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4782660
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4865867
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4907765
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5237095
  
  #Filter 3: Remove polarized fixed variants (AF=0 or AF=1) or those that weren't polarizable (AA different from either REF or ALT):
  echo "Filtering out non-polarizable and fixed variants"
  $BCF view -e '(INFO/AA!=REF & INFO/AA!=ALT) | INFO/AF=0.00 | INFO/AF=1.00' ${CALLING}"_polarized_filtered2_"${TYPE}".anc_ann.vcf" > ${CALLING}"_polarized_filtered3_"${TYPE}".anc_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered3_"${TYPE}".anc_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4676648
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4758637
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4798043
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5103863
  
  #Filter 4: Apply GATK's recommended hard-filters, and then some.
  echo "Filtering out low quality and unreliable variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -select "QUAL >= 30 && QD >= 2.0 && FS <= 60.0 && MQ >= 40.0 && MQRankSum >= -12.5 && ReadPosRankSum >= -8.0" \
  -R $REF \
  -V ${CALLING}"_polarized_filtered3_"${TYPE}".anc_ann.vcf" \
  -o ${CALLING}"_polarized_filtered4_"${TYPE}".anc_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered4_"${TYPE}".anc_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4548968
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4555453
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4565640
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4710686
  
  #Filter 5: For each species exclude those positions that have more than 15% missing genotypes (i.e. that have low depth in any dataset).
  echo "Filtering out high missingness variants"
  $BCF filter -e "F_MISSING > 0.15" -Ov -o ${CALLING}"_polarized_filtered5_"${TYPE}".anc_ann.vcf" ${CALLING}"_polarized_filtered4_"${TYPE}".anc_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered5_"${TYPE}".anc_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4332653
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4420467
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4439054
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4617432
  
  #Filter 6: Finally, exclude sites that have low depth globally.
  echo "Filtering out low depth variants"
  $BCF filter -e "DP < 200" -Ov -o ${CALLING}"_polarized_filtered6_"${TYPE}".anc_ann.vcf" ${CALLING}"_polarized_filtered5_"${TYPE}".anc_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered6_"${TYPE}".anc_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4241437
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4391212
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4412177
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4602025
fi

```

###Separate variants and substitutions.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_separate_variants_substitutions_${TYPE}.anc_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)

if [[ $CALLING == "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3"* ]] #the double brackets turns the test into a regex
  then
    for s in ${SPECIES[@]}
      do
      echo "retrieving 1 and 0 positions from ${s}"
      bcftools query -l "${CALLING}"_polarized_filtered6_"$TYPE".anc_ann.vcf | cut -c1-12 | sort | uniq | grep "${s}" > "${s}"_samples.txt
      N_SAMPLES=$(cat "${s}"_samples.txt | wc -l)
      #AF_THRES=$(echo "scale=4; ($N_SAMPLES*2-2)/($N_SAMPLES*2)" | bc)
      bcftools view -S "${s}"_samples.txt "${CALLING}"_polarized_filtered6_"$TYPE".anc_ann.vcf | bcftools view -i "AC/AN = 0 | AC/AN = 1" -Ov -o "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf #grab only those positions that have AF=0 or AF~1 (more exactly, AF>(num_alleles-2)/num_alleles, i.e. at most one ancestral allele). Use AC/AN instead of AF since the latter isn't recalculated for the subset of samples
      grep -v '#' "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf | cut -f1,2 | awk '{printf ("%s\t%s\t%s\n", $1, $2-1, $2)}' >  "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".bed
      echo "${s} 1 and 0 positions retrieved"
      done
    bedtools intersect -a *c_lp_1_and_0_positions_"$TYPE".bed -b *c_ll_1_and_0_positions_"$TYPE".bed > "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed #inner join (retrieves only positions that have AF=0 or AF=1 in both species simultaneously, dropping from both species those that are variable within any)
    bedtools intersect -a "${CALLING}"_polarized_filtered6_"$TYPE".anc_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_substitutions_"$TYPE".anc_ann.vcf
    echo "substitutions retrieved"
    bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".anc_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_variants_"$TYPE".anc_ann.vcf
    echo "variants retrieved"
    grep -v '#' "${CALLING}"_polarized_substitutions_"$TYPE".anc_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 1382501
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 1421816
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 1420110
    grep -v '#' "${CALLING}"_polarized_variants_"$TYPE".anc_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 2858936
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 2969396
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 2992067
    #bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".anc_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header | grep -v '#' | wc -l #sanity check that counts the number of discarded variants. This number should equal the difference between _filtered6 (not anymore, now filtered6 is a different thing) and _substitutions. It is for both treatments:
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 70598
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 65219
    else
    echo "the code for this calling hasn't been written yet"
  fi

```

###Separate segregating and fixed sites. These are defined at the species level.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_separate_segregating_fixed_${TYPE}.anc_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
POPS=$(echo $CALLING | fold -w8 | cut -c1-7 | head -n$N_POPS | sort | uniq)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
FILE=$(echo ${CALLING}_polarized_filteredall_varssubs_${TYPE}.anc_ann.vcf) #This file was generated in section 11 after applying the per dataset depth filtering to the varssubs file.
echo "input file is" $FILE

if [[ $CALLING == "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3"* ]] #the double brackets turns the test into a regex
  then
  for s in ${SPECIES[@]}
    do
    bcftools query -l $FILE | cut -c1-12 | sort | uniq | grep ${s} > ${s}_samples.txt
    echo "retrieving derived varssubs positions for species" $s
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V $FILE \
    -o ${s}_${NM_COV}_persp_varssubs_${TYPE}.anc_ann.vcf \
    -env \
    --sample_file ${s}_samples.txt
    VARSSUBS_N=$(grep -v '#' ${s}_${NM_COV}_persp_varssubs_${TYPE}.anc_ann.vcf | wc -l) #
    echo "varssubs total is" $VARSSUBS_N
    echo "retrieving derived segregating positions for species" $s
    bcftools view -i "AC/AN > 0 & AC/AN < 1" ${s}_${NM_COV}_persp_varssubs_${TYPE}.anc_ann.vcf -Ov -o ${s}_${NM_COV}_persp_segregating_${TYPE}.anc_ann.vcf
    SEGR_N=$(grep -v '#' ${s}_${NM_COV}_persp_segregating_${TYPE}.anc_ann.vcf | wc -l) #
    echo "segregating total is" $SEGR_N
    echo "retrieving derived fixed positions for species" $s
    bcftools view -i "AC/AN = 1" ${s}_${NM_COV}_persp_varssubs_${TYPE}.anc_ann.vcf -Ov -o ${s}_${NM_COV}_persp_fixed_${TYPE}.anc_ann.vcf
    FIXED_N=$(grep -v '#' ${s}_${NM_COV}_persp_fixed_${TYPE}.anc_ann.vcf | wc -l) #
    echo "fixed total is" $FIXED_N
    done
  else
  echo "the code for this calling hasn't been written yet"
fi

```

##5: Obtain per dataset VCFs.
###For varssubs, variants and substitutions. All of these should be filtered next.
```{r Obtain per dataset VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perdataset_${VAR}_${CALLING}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

#Define input variant:
if [ $VAR == "varssubs" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_filtered6_"${TYPE}".anc_ann.vcf")
elif [ $VAR == "variants" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_variants_"${TYPE}".anc_ann.vcf")
elif [ $VAR == "substitutions" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_substitutions_"${TYPE}".anc_ann.vcf")
else
  INPUT_FILE=()
fi
echo $INPUT_FILE

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_outerparsimony
for j in ${DATASETS[@]}
  do
  echo "${j}"
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${j}"_samples
  mkdir -p "${j}"_"${NM_COV}"_perdataset
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V $INPUT_FILE \
  -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".anc_ann.vcf" \
  -env \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  grep -v '#' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".anc_ann.vcf" | wc -l #
  done

```

###For segregating and fixed (true variants and substitutions). These come from the already filtered varssubs, so steps 6 and 7 should be skipped. Go straight to step 8 after this.
```{r Obtain per dataset VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(fixed) #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perdataset_${VAR}_${CALLING}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_outerparsimony

for j in ${DATASETS[@]}
  do
  echo ${j}
  SPECIES=$(echo ${j} | cut -c1-4)
  INPUT_FILE=$(echo ${SPECIES}_${NM_COV}_persp_${VAR}_${TYPE}.anc_ann.vcf)
  echo $INPUT_FILE
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  mkdir -p ${j}_${NM_COV}_perdataset
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V $INPUT_FILE \
  -o ${j}_${NM_COV}_perdataset/${j}_${NM_COV}_perdataset_filtered_${VAR}_${TYPE}.anc_ann.vcf \
  -env \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  grep -v '#' ${j}_${NM_COV}_perdataset/${j}_${NM_COV}_perdataset_filtered_${VAR}_${TYPE}.anc_ann.vcf | wc -l #
  done

```

##6: Depth range calculus. Obtain depth range for each species in order to filter high depth positions as part of the next section's many filterings.
###A: write ANGSD depth calculus and store it as .sh
```{r Depth range calculus, eval=FALSE, engine='bash'}

#I'll modify Maria's code to calculate depth. Since these populations are big, we'll be using Elena's captured intergenic fraction of the genome. Save it as .sh and upload it to the server.

CALLING=$(pwd | rev | cut -d'/' -f1 | cut -d'_' -f2- | rev)
POP=$(echo ${STY#*.} | cut -d'.' -f1)
SPECIES=$(echo $POP | cut -c-4)
if [ $SPECIES = "c_ll" ]
  then NM_COV=$(echo $CALLING | rev | cut -d'_' -f2 | cut -c-3 | rev)
elif [ $SPECIES = "h_ll" ]
  then NM_COV=$(echo $CALLING | rev | cut -d'_' -f2 | cut -c-3 | rev)
else NM_COV=$(echo $CALLING | rev | cut -d'_' -f2 | cut -c4- | rev)
fi
DATASET=$(echo ${STY#*.} | cut -d'_' -f1,2,3)
COVERAGE=$(echo ${STY#*.} | cut -d'_' -f4)
REF="/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa"
THREADS=10
REGIONFILE="/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf"

awk -F ":|-" '{printf ("%s\n", $3-$2)}' /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf | paste -sd+ | bc

rm "$POP".bamlist
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
SAMPLES=$(cat "$DATASET"_samples)
for var in $SAMPLES
  do 
  if [ ${var} = "h_ll_pv_0223" ]
    then realpath ${var}_sorted_indelrealigner_marked_sorted.$NM_COV.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/"$POP".bamlist
  elif [ $COVERAGE = "origcov" ] && [ -e ${var}_recal_round-1_25x.$NM_COV.bam ]
    then realpath ${var}_recal_round-1_25x.$NM_COV.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/"$POP".bamlist
  else realpath ${var}_recal_round-1.$NM_COV.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/"$POP".bamlist
  fi
done
cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/"$POP".bamlist
BAMLIST="$POP".bamlist

cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony
OUT_NAME=/home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/$POP.qc
NUMBER_IND=$(printf "%03d" `wc -l $BAMLIST | cut -f1 -d " "`)
MAXDEPTH=$(expr $NUMBER_IND \* 1000)

#Sanity checks: 
ls $BAMLIST
echo $OUT_NAME
echo $NUMBER_IND
echo $MAXDEPTH

angsd \
-P $THREADS \
-b $BAMLIST \
-ref $REF \
-out $OUT_NAME \
-uniqueOnly 1 \
-remove_bads 1 \
-only_proper_pairs 1 \
-rf $REGIONFILE \
-baq 1 \
-C 50 \
-doQsDist 1 \
-doDepth 1 \
-doCounts 1 \
-maxDepth $MAXDEPTH

#Save it in a text editor as depth_calculus_outerparsimony.sh, upload it to the server, and chmod +x it:
mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/depth_calculus_outerparsimony.sh dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/depth_calculus_outerparsimony.sh

```

###B: define sample sets and run depth calculus 
```{r Depth range calculus, eval=FALSE, engine='bash'}

#Change calling variable
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)

mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NL=$'\n'
for i in ${DATASETS[@]}
  do
    N_SIZE0=$(cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${i}_samples" | wc -l)
    N_SIZE=$(printf "%03d" $N_SIZE0)
    cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony
    screen -dmS "${i}_${COVERAGE}_n${N_SIZE}.log"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "script ${i}_${COVERAGE}_n${N_SIZE}.log$NL"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "./depth_calculus_outerparsimony.sh; exec bash$NL"
    #screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "exit$NL"
    done

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
mkdir -p /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_outerparsimony
scp dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/*depthGlobal /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_outerparsimony

```

###C: compile statistics and draw graphs
```{r Depth range calculus}

calling <- "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_outerparsimony"

#Now we use R to plot the depth distribution and to obtain a summary table:

library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)

##Functions:
get_mean <- function(dat) { with(dat, sum(as.numeric(freq)*value)/sum(as.numeric(freq))) }
get_sd <- function(dat) { mu <- get_mean (dat) 
with (dat, sqrt(sum(as.numeric(freq)*(value-mu)^2)/(sum(as.numeric(freq))-1))) } 

#*******************************************************************************************

my_files_depthGlobal = list.files(path = paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling),pattern="*.depthGlobal$") #"5x|GP|MG|LD"

for (i in 1:length(my_files_depthGlobal)) {
  assign(my_files_depthGlobal[i], (scan(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""), sep = " ", dec = ".")) %>% .[!is.na(.)])
  }
mean_folds = 0.95
depth_per_sample <- data.frame()

#Compute globaldepth for all populations found
#*******************************************************************************************

for (i in 1:length(my_files_depthGlobal)) {
  DF = read.table(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""),head=F, stringsAsFactors=F, check.names=FALSE)
  freq_table_DF <- data.frame (value = 1:length (DF), freq = t(DF))
  freq_table_truncated_DF <- filter(freq_table_DF, value < (nrow(freq_table_DF)))
  #Mean depth:
  my_mean_DF <-  get_mean (freq_table_DF)
  my_mean_truncated_DF <- get_mean (freq_table_truncated_DF)
  my_sd_DF <-  get_sd (freq_table_DF)
  my_sd_truncated_DF <- get_sd (freq_table_truncated_DF)
  #Max and min depth:
  maxDepth_DF = my_mean_DF + (mean_folds * my_mean_DF)
  minDepth_DF  = my_mean_DF - (mean_folds * my_mean_DF)
  #maxDepth_truncated_DF = my_mean_truncated_DF + (mean_folds * my_sd_truncated_DF)
  maxDepth_truncated_DF = my_mean_truncated_DF + (3 * my_sd_truncated_DF)
  #minDepth_truncated_DF  = my_mean_truncated_DF - (mean_folds * my_sd_truncated_DF)
  minDepth_truncated_DF = my_mean_truncated_DF - (1 * my_sd_truncated_DF)
  #Para una o más poblaciones:
  population=unlist(strsplit(my_files_depthGlobal[i],"[.]"))[1]
  depth_per_sample <- rbind(depth_per_sample, 
                            data.frame(pop = population,
                                       mean = my_mean_DF,
                                       sd = my_sd_DF, 
                                       mean_truncated = my_mean_truncated_DF,
                                       sd_truncated = my_sd_truncated_DF,
                                       maxDepth = maxDepth_DF, 
                                       minDepth = minDepth_DF,
                                       maxDepth_truncated = maxDepth_truncated_DF,
                                       minDepth_truncated = minDepth_truncated_DF)) 
  #Plotting:
  ggplot(freq_table_truncated_DF, aes(x = value, y = freq)) + 
    geom_bar(stat = "identity", color = "black") +
    scale_x_continuous(breaks = 0:250*10, limits = c(0, maxDepth_truncated_DF*1.5)) +
    scale_y_continuous(expand=c(0,0)) +
    ggtitle (paste(my_files_depthGlobal[i],"_", mean_folds, "_",maxDepth_truncated_DF, "_",maxDepth_DF) ) +
    geom_vline(xintercept=maxDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=maxDepth_truncated_DF, colour ="grey",linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_truncated_DF,colour ="grey",linetype="dashed", size=0.5) + 
    theme_classic() + 
    theme(text = element_text(size=10))
  plot_name=paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],"_",mean_folds,".pdf",sep="")
  ggsave(filename = plot_name)
}

#When finished write the table

#Results for all datasets within a calling are stored in one single dataframe:
write.table(x = depth_per_sample,file = paste("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",calling,"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_",mean_folds,".csv", sep= ""),quote=FALSE, col.names = FALSE, row.names = FALSE, sep= " ")

```

###D: separate for each sample set
```{r Depth range calculus, eval=FALSE, engine='bash'}

#From outside the server, first upload the summary table to the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_outerparsimony)
scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/$CALLING

#In the server, separate in populations:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_outerparsimony)
cd /home/dkleinman/datos/nm_depth_calculus/$CALLING
POPS=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $1}')
for POP in ${POPS[@]}
  do
  echo $POP
  grep "${POP}" /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv > "$POP"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv
  done

```

##7: Perform high-depth filtering. Obtain list of sites with very high depth within each dataset, join them, and remove those sites.
###At the dataset level:
```{r Perform depth filtering, eval=FALSE, engine='bash'}

#For each dataset obtain the list of positions that have lower (higher) depth than the minimum (maximum) within 0.95 of the distribution, as calculated in the previous section, and join them to later remove all of them from all datasets:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_datasets_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_outerparsimony
for j in ${DATASETS[@]}
  do
  echo "${j}"
  #MIN_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $9}') #Obtained in section 10
  MAX_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_outerparsimony/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $8}') #Obtained in section 10
  #echo $MIN_DP
  echo $MAX_DP
  $BCF filter -i "DP > ${MAX_DP}" -Ov -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".anc_ann.vcf" ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".anc_ann.vcf"
  sed -e 's/chr//' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".anc_ann.vcf" | awk '{OFS="\t"; if (!/^#/){print $1,$2-1,$2}}' > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #convert from VCF to BED
  done
cat *"_"${NM_COV}"_perdataset/"*"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" | bedtools sort | uniq > ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #join all BEDs
for j in ${DATASETS[@]}
  do
  echo "${j}"
  bedtools subtract -a ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".anc_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".anc_ann.vcf"
  done
  
```

###At the global level (run the dataset level code first):
```{r Perform depth filtering, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_global_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

if [ $VAR == "varssubs" ]
  then
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_filtered6_"${TYPE}".anc_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".anc_ann.vcf"
  else
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_"${VAR}"_"${TYPE}".anc_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".anc_ann.vcf"
fi

```

##8: Obtain per population VCFs.
```{r Obtain per population VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perpop_${VAR}_${CALLING}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}_*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_outerparsimony
for i in ${DATASETS[@]}
  do
  echo "${i}"
  declare POP=$(bcftools query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".anc_ann.vcf" | cut -c1-7 | sort | uniq)
  for j in ${POP[@]}
    do
    echo "${j}"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    $BCF query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".anc_ann.vcf" | grep "${j}" > ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    cat ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    mkdir -p "${j}"_"${NM_COV}"_perpop
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".anc_ann.vcf" \
    -o ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".anc_ann.vcf" \
    -env \
    --sample_file ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    grep -v '#' ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".anc_ann.vcf" | wc -l #
    done
  done

```

##9: Split the population VCFs into per individual VCFs. Generate a VCF for each individual.
###Whole-genome.
```{r Split the population VCFs into per individual VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "individual_${VAR}_${CALLING}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_outerparsimony
declare POP=$(bcftools query -l ${CALLING}"_polarized_filtered6_"${TYPE}".anc_ann.vcf" | cut -c1-7 | sort | uniq)
for i in ${POP[@]}
  do
  echo "${i}"
  mkdir -p "${i}"_"${NM_COV}"_individuals
  VCF_LIST=$(ls ${i}"_"${NM_COV}"_perpop/"*"_"${i}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".anc_ann.vcf")
  for j in ${VCF_LIST[@]}
    do 
    INDIVIDUALS=$(bcftools query -l "${j}" | sort | uniq)
    for k in ${INDIVIDUALS[@]}
      do
      echo "${k}"
      ID=$(echo "${k}")
      java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
      -T SelectVariants \
      -R $REF \
      -V "${j}" \
      -o ${i}"_"${NM_COV}"_individuals/"${k}"_"${NM_COV}"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" \
      -env \
      -sn $ID
      done
    done
  done

```

##10: Get counts (of variants, substitutions or vars+subs).
###All sites:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_outerparsimony
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".anc_ann.txt"
  done
rm ${VAR}_*.temp.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.anc_ann.txt

```

###No warnings:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.nowarn.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
for n in "${INDLIST[@]}"
  do
  echo "${n}"
  ind=$(echo "${n}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  grep -v 'WARNING' ${n} > nowarn.temporary.vcf
  i=nowarn.temporary.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b !!! /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.nowarn.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.nowarn.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b !!! /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.nowarn.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.nowarn.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.nowarn.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.nowarn.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.nowarn.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.nowarn.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.anc_ann.txt"
  done
rm ${VAR}_*.nowarn.temp.borrar
rm nowarn.temporary.vcf

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.nowarn.anc_ann.txt

```

###Heterozygous counts:
```{r Get heterozygous counts, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_heterozygous_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_outerparsimony
rm ${CALLING}"_ann_individual_summary_heterozygous_"${VAR}"_"${TYPE}".anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_H\tintergenic_H\tintronic_H\tcoding_H\tsynonymous_H\tmissense_H\tmistol_H\tmisdel_H\tnonsense_H\tUCNE_H\tUCNE_mid_H\tUCNE_high_H" > ${CALLING}"_ann_individual_summary_heterozygous_"${VAR}"_"${TYPE}".anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  TOTAL_H=$(grep -v '#' ${i} | grep ';AF=0.500;' | wc -l)
  INTERGENIC_H=$(grep 'intergenic' ${i} | grep ';AF=0.500;' | wc -l)
  INTRONIC_H=$(grep 'intron_variant' ${i} | grep ';AF=0.500;' | wc -l)
  CODING_H=$(grep 'CDS' ${i} | grep ';AF=0.500;' | wc -l)
  SYNONYMOUS_H=$(grep 'synonymous_variant' ${i} | grep ';AF=0.500;' | wc -l)
  MISSENSE_H=$(grep 'missense_variant' ${i} | grep ';AF=0.500;' | wc -l)
  MISTOL_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt | grep ';AF=0.500;' | wc -l)
  MISDEL_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt | grep ';AF=0.500;' | wc -l)
  NONSENSE_H=$(grep '|HIGH|' ${i} | grep ';AF=0.500;' | wc -l)
  UCNE_H=$(grep 'UCNE' ${i} | grep ';AF=0.500;' | wc -l)
  UCNE_MID_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed | grep ';AF=0.500;' | wc -l)
  UCNE_HIGH_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed | grep ';AF=0.500;' | wc -l)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_H\t$INTERGENIC_H\t$INTRONIC_H\t$CODING_H\t$SYNONYMOUS_H\t$MISSENSE_H\t$MISTOL_H\t$MISDEL_H\t$NONSENSE_H\t$UCNE_H\t$UCNE_MID_H\t$UCNE_HIGH_H" >> ${CALLING}"_ann_individual_summary_heterozygous_"${VAR}"_"${TYPE}".anc_ann.txt"
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_individual_summary_heterozygous_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

###Homozygous counts:
```{r Get heterozygous counts, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_homozygous_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_outerparsimony
rm ${CALLING}"_ann_individual_summary_homozygous_"${VAR}"_"${TYPE}".anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_H\tintergenic_H\tintronic_H\tcoding_H\tsynonymous_H\tmissense_H\tmistol_H\tmisdel_H\tnonsense_H\tUCNE_H\tUCNE_mid_H\tUCNE_high_H" > ${CALLING}"_ann_individual_summary_homozygous_"${VAR}"_"${TYPE}".anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  TOTAL_H=$(grep -v '#' ${i} | grep ';AF=1.00;' | wc -l)
  INTERGENIC_H=$(grep 'intergenic' ${i} | grep ';AF=1.00;' | wc -l)
  INTRONIC_H=$(grep 'intron_variant' ${i} | grep ';AF=1.00;' | wc -l)
  CODING_H=$(grep 'CDS' ${i} | grep ';AF=1.00;' | wc -l)
  SYNONYMOUS_H=$(grep 'synonymous_variant' ${i} | grep ';AF=1.00;' | wc -l)
  MISSENSE_H=$(grep 'missense_variant' ${i} | grep ';AF=1.00;' | wc -l)
  MISTOL_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt | grep ';AF=1.00;' | wc -l)
  MISDEL_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt | grep ';AF=1.00;' | wc -l)
  NONSENSE_H=$(grep '|HIGH|' ${i} | grep ';AF=1.00;' | wc -l)
  UCNE_H=$(grep 'UCNE' ${i} | grep ';AF=1.00;' | wc -l)
  UCNE_MID_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed | grep ';AF=1.00;' | wc -l)
  UCNE_HIGH_H=$(bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed | grep ';AF=1.00;' | wc -l)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_H\t$INTERGENIC_H\t$INTRONIC_H\t$CODING_H\t$SYNONYMOUS_H\t$MISSENSE_H\t$MISTOL_H\t$MISDEL_H\t$NONSENSE_H\t$UCNE_H\t$UCNE_MID_H\t$UCNE_HIGH_H" >> ${CALLING}"_ann_individual_summary_homozygous_"${VAR}"_"${TYPE}".anc_ann.txt"
  done

#From outside the server:
export SSHPASS=$(cat /Users/dani/Documents/genomics_pass.txt)
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
sshpass -e scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_individual_summary_homozygous_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/
unset SSHPASS

```

###Centromere sites:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_centr_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_outerparsimony
rm ${CALLING}"_ann_individual_summary_centr_"${VAR}"_"${TYPE}".anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_centr_"${VAR}"_"${TYPE}".anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/mlucena/telomers_centromers_definition/centr_regions_based_on_synteny_1000bp.bed -header > "ind_centr_"${VAR}"_"${TYPE}".temporary.vcf"
  j=("ind_centr_"${VAR}"_"${TYPE}".temporary.vcf")
  TOTAL_V=$(grep -v '#' ${j} | wc -l)
  TOTAL_A=$(grep -v '#' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${j} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${j} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${j} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${j} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${j} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_centr_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_centr_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_centr_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_centr_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_centr_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_centr_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${j} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${j} | wc -l)
  UCNE_A=$(grep 'UCNE' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_centr_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_centr_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_centr_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_centr_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_centr_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_centr_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_centr_"${VAR}"_"${TYPE}".anc_ann.txt"
  rm "ind_centr_"${VAR}"_"${TYPE}".temporary.vcf"
  done
rm ${VAR}_centr_*.temp.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.anc_ann.txt

```

###Telomere sites:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_tel_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_outerparsimony
rm ${CALLING}"_ann_individual_summary_tel_"${VAR}"_"${TYPE}".anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_tel_"${VAR}"_"${TYPE}".anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/mlucena/telomers_centromers_definition/tel0-10m_regions_based_on_synteny_1000bp.bed -header > "ind_tel_"${VAR}"_"${TYPE}".temporary.vcf"
  j=("ind_tel_"${VAR}"_"${TYPE}".temporary.vcf")
  TOTAL_V=$(grep -v '#' ${j} | wc -l)
  TOTAL_A=$(grep -v '#' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${j} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${j} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${j} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${j} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${j} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_tel_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_tel_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_tel_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_tel_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_tel_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_tel_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${j} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${j} | wc -l)
  UCNE_A=$(grep 'UCNE' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_tel_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_tel_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_tel_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_tel_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_tel_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_tel_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_tel_"${VAR}"_"${TYPE}".anc_ann.txt"
  rm "ind_tel_"${VAR}"_"${TYPE}".temporary.vcf"
  done
rm ${VAR}_tel_*.temp.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.anc_ann.txt

```

###XChr sites (bad; all individuals as DIPLOID):
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_Xchr_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_outerparsimony
rm ${CALLING}"_ann_individual_summary_XchrDIPLOID_"${VAR}"_"${TYPE}".anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tsex\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_XchrDIPLOID_"${VAR}"_"${TYPE}".anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  echo "generating Xchr VCF"
  SEX=$(grep ${ind} samples_sex.txt | cut -f2)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/lynx2cat_wTiger_Xchr_woutPAR.sorted.merged.bed -header > ${i/_individual_${VAR}_${TYPE}.anc_ann.vcf/_individual_${VAR}_Xchr_${TYPE}.anc_ann.vcf}
  j=(${i/_individual_${VAR}_${TYPE}.anc_ann.vcf/_individual_${VAR}_Xchr_${TYPE}.anc_ann.vcf})
  echo "counting Xchr variants"
  TOTAL_V=$(grep -v '#' ${j} | wc -l)
  TOTAL_A=$(grep -v '#' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${j} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${j} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${j} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${j} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${j} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_Xchr_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_Xchr_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_Xchr_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_Xchr_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_Xchr_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_Xchr_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${j} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${j} | wc -l)
  UCNE_A=$(grep 'UCNE' ${j} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_Xchr_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_Xchr_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_Xchr_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${j} -b $V_PATH/$CALLING/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_Xchr_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_Xchr_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_Xchr_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$SEX\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_XchrDIPLOID_"${VAR}"_"${TYPE}".anc_ann.txt"
  done
rm ${VAR}_Xchr_*.temp.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.anc_ann.txt

```

###XChr sites (good; only females as DIPLOID):
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_Xchr_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_outerparsimony
rm ${CALLING}"_ann_individual_summary_Xchr_"${VAR}"_"${TYPE}".anc_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\tsex\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_Xchr_"${VAR}"_"${TYPE}".anc_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_Xchr_"${TYPE}".anc_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  SEX=$(grep ${ind} samples_sex.txt | cut -f2)
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  TOTAL_C=$(echo $(echo "scale=2; (($TOTAL_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_C=$(echo $(echo "scale=2; (($INTERGENIC_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_C=$(echo $(echo "scale=2; (($INTRONIC_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  SYNONYMOUS_C=$(echo $(echo "scale=2; (($SYNONYMOUS_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_C=$(echo $(echo "scale=2; (($MISSENSE_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_Xchr_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_Xchr_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_Xchr_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_TOL_C=$(echo $(echo "scale=2; (($MISSENSE_TOL_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_Xchr_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_Xchr_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_Xchr_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_DEL_C=$(echo $(echo "scale=2; (($MISSENSE_DEL_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_C=$(echo $(echo "scale=2; (($NONSENSE_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_C=$(echo $(echo "scale=2; (($UCNE_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_Xchr_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_Xchr_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_Xchr_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_MID_C=$(echo $(echo "scale=2; (($UCNE_MID_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  bedtools intersect -a ${i} -b $V_PATH/$CALLING/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_Xchr_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_Xchr_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_Xchr_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_HIGH_C=$(echo $(echo "scale=2; (($UCNE_HIGH_A/2))" | bc) | awk '{printf("%d\n", $1 + 0.5)}')
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  MISSENSE_SYNONYMOUS_C=$(echo "scale=4; $MISSENSE_C/$SYNONYMOUS_C" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  if [ $SEX == "Female" ]
    then
    echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$SEX\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_Xchr_"${VAR}"_"${TYPE}".anc_ann.txt"
  elif [ $SEX == "Male" ]
    then
    echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$SEX\t$TOTAL_V\t$TOTAL_C\t$INTERGENIC_V\t$INTERGENIC_C\t$INTRONIC_V\t$INTRONIC_C\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_C\t$MISSENSE_V\t$MISSENSE_C\t$MISSENSE_TOL_V\t$MISSENSE_TOL_C\t$MISSENSE_DEL_V\t$MISSENSE_DEL_C\t$NONSENSE_V\t$NONSENSE_C\t$UCNE_V\t$UCNE_C\t$UCNE_MID_V\t$UCNE_MID_C\t$UCNE_HIGH_V\t$UCNE_HIGH_C\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_C\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_Xchr_"${VAR}"_"${TYPE}".anc_ann.txt"
  fi
  done
rm ${VAR}_Xchr_*.temp.borrar

#LATER AVERAGE EVERYTHING WITH COUNT/(*N_FEM*2 + N_MAL)

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.anc_ann.txt

```

##11: Calculate population averages.
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony

#First, generate some headers and info files.
head -n1 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt | head -n1) | cut -f-27 > ind_headers.txt #Retrieve headers for files with individuals
cut -f2,5- ind_headers.txt > pop_headers.txt #Retrieve headers for files with populations
tail -n+2 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt | head -n1) | cut -f-4 > ids.txt #Retrieve first 4 columns with individual data

#Next, obtain the population average for the empirical data (5x only!!):
cat pop_headers.txt <(gawk '$3=="5x" {N[$2]++; for (i=5;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.anc_ann.txt | cut -f-27)) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.anc_ann.txt

cut -f1 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.anc_ann.txt | tail -n+2 > pops.txt #Retrieve column with population data

#In order to relativise by the Kirov population average, divide the population average by the Kirov empirical population averages:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.anc_ann.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.anc_ann.txt | cut -f2-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.anc_ann.txt


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.anc_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_5xpopulation_average_TCRLP_outerparsimony_${VAR}_${TYPE}.empirmean_ki_rel.anc_ann.txt

```

##12. Plot counts.
###Derived allele counts relative to Kirov.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
variants_and_subst_wg <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_TCRLP_",type,"_SNP.anc_ann.txt")) %>% select(.,species,population,dataset,sample,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) 

variants_and_subst_wg$dataset <- as.factor(variants_and_subst_wg$dataset)
variants_and_subst_wg$dataset = factor(variants_and_subst_wg$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
variants_and_subst_wg$population = factor(variants_and_subst_wg$population,levels=c("ki","no","po","sm","do"))
print.data.frame(variants_and_subst_wg)

variants_and_subst_wg_alleleR <- variants_and_subst_wg %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
variants_and_subst_wg_alleleR

r_average_vector <- c()
for (r in unique(variants_and_subst_wg_alleleR$ratio)) {
  print(r)
  r_average <- filter(variants_and_subst_wg_alleleR,r==ratio & population=="ki") %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(variants_and_subst_wg_alleleR,r==ratio))))
}
print(r_average_vector)

relativised_variants_and_subst_wg_alleleR <- mutate(variants_and_subst_wg_alleleR, ki_relative_value=value/r_average_vector)

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_variants_and_subst_wg_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_ki_relative_value"=character(0),"se_ki_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_variants_and_subst_wg_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(relativised_variants_and_subst_wg_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_ki_relative_value","se_ki_relative_value")
    average_relativised_variants_and_subst_wg_alleleR <- rbind(average_relativised_variants_and_subst_wg_alleleR,row_data,stringsAsFactors=F)
  }
}
average_relativised_variants_and_subst_wg_alleleR$population = factor(average_relativised_variants_and_subst_wg_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_relativised_variants_and_subst_wg_alleleR$population)[levels(average_relativised_variants_and_subst_wg_alleleR$population)=="sm"] <- "an"
average_relativised_variants_and_subst_wg_alleleR$ratio = factor(average_relativised_variants_and_subst_wg_alleleR$ratio,levels=c("total","intergenic","intronic","synonymous","syn_pref","syn_unpref","missense","missense_tol","missense_del","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high"))
levels(average_relativised_variants_and_subst_wg_alleleR$ratio) <- c("total","intergenic","introns","synonymous","synonymous_pref","synonymous_unpref","missense","missense_tolerated","missense_deleterious","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high")
average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR
#(average_relativised_variants_and_subst_wg_alleleR,paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/",type,"_derived_allele_allele_ratio_relative2introns_mean.csv"))

#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.60,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

average_relativised_derived_allele_allele_ratio_up <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('total|intergenic|introns|\\<synonymous\\>',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_up

average_relativised_derived_allele_allele_ratio_middle <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('\\<missense\\>|nonsense|^UCNE$',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_middle

average_relativised_derived_allele_allele_ratio_down <- ggplot(filter(average_relativised_variants_and_subst_wg_alleleR,grepl('_tolerated|_deleterious|_mid|_high',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  #ylab("Average genetic load relative to ki") +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_down


average_relativised_derived_allele_allele_ratio_combined <- grid.arrange(set_panel_size(average_relativised_derived_allele_allele_ratio_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_middle,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_down,width=unit(4.5,"cm"),height=unit(10,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))

ggsave(paste0(type,"_TCRLP_genetic_load_relative2Kirov_definitive.pdf"), width=26, height=38, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",average_relativised_derived_allele_allele_ratio_combined)

```

###Derived allele counts 5xonly manuscript version.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
averages <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_5xpopulation_average_TCRLP_outerparsimony_",type,"_SNP.empirmean_ki_rel.anc_ann.txt")) %>% select(.,population,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) %>% mutate(species=ifelse(population=="ki" | population=="po" | population=="no","ll","lp"),size=ifelse(population=="ki" | population=="sm","large","small"))
averages$population = factor(averages$population,levels=c("ki","no","po","sm","do"))
averages$species = factor(averages$species,levels=c("ll","lp"))
averages$size = factor(averages$size,levels=c("large","small"))
print.data.frame(averages)

averages_tidy <- averages %>% gather(ratio,value,-population,-species,-size,factor_key=T)
averages_tidy

colnames(averages_tidy) <- c("population","species","size","ratio","mean")
averages_tidy$ratio <- gsub('intronic', 'introns', averages_tidy$ratio)
averages_tidy$ratio <- gsub('coding', 'CDS', averages_tidy$ratio)
averages_tidy$ratio <- gsub('synonymous', 'syn.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_tol', 'm. tol.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_del', 'm. del.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('nonsense', 'LoF', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_low', 'UCNE low', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_mid', 'UCNE mod.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_high', 'UCNE high', averages_tidy$ratio)
averages_tidy$population = factor(averages_tidy$population,levels=c("ki","po","no","sm","do"))
levels(averages_tidy$population) <- c("KIR","POL","NOR","AND","DON")
#levels(averages_tidy$population)[levels(averages_tidy$population)=="sm"] <- "an"
averages_tidy$ratio = factor(averages_tidy$ratio,levels=c("total","intergenic","introns","CDS","syn.","syn_pref","syn_unpref","missense","m. tol.","m. del.","LoF","UCNE","UCNE low","UCNE mod.","UCNE high")) 


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.6,0.6,0.5,0.5),"max"=c(1.2,1.5,2,4),"breaks"=c(0.1,0.1,0.2,0.5))

ggplot_up <- ggplot(data=filter(averages_tidy,grepl('total|intergenic|introns|syn\\.',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_up

ggplot_middle <- ggplot(data=filter(averages_tidy,grepl('\\<missense\\>|LoF|^UCNE$',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_middle

ggplot_down <- ggplot(data=filter(averages_tidy,grepl('tol|del|mod|high',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_down

#New:
if(type=="varssubs") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_middle,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_down,width=unit(1.65,"cm"),height=unit(4,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=10,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))
} else if (type=="fixed") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(ggplot_down,width=unit(4.5,"cm"),height=unit(10,"cm")),set_panel_size(ggplot_other,width=unit(4.5,"cm"),height=unit(10,"cm")),widths=c(4,2.3,0.2),layout_matrix=rbind(c(1,1,NA),c(2,NA,3)),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Derived fixation rate relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))
}

#New:
ggsave(paste0(type,"_TCRLP_outerparsimony_genetic_load_5xrelative2Kirov_manuscriptlike.pdf"), width=8.2, height=17, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_combined)

```

##13: Derived allele count spectrum.
###Combine per population and feature allele count files:
####All sites, and consistent sites
```{r Calculate derived allele frequency ratio, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_derived_counts_spectrum_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
 
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
mkdir -p derived_allele_counts_spectrum
scp /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt 
GREP=$(cat derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f1)
POP_VCFS=($(ls `find . -path *"_perpop/c_*5x*_perpop_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
rm ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".anc_ann.ac"
for p in ${POP_VCFS[@]}
  do
  SP_DATASET=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f1-3)
  SHORT_POP=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f4-6)
  echo "working with pop" $SHORT_POP "and vcf" $p
  echo "extracting derived allele counts from" $SHORT_POP
  for g in ${GREP[@]}
    do
    #echo "grepping: ${g}"
    FEATURE=$(grep "${g}" derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f2)
    echo "extracting from feature:" $FEATURE
    grep "${g}" "${p}" | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$11)}' > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.anc_ann.ac}
    echo "joining frequency files"
    awk -v pop="$SHORT_POP" -v feat="$FEATURE" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE"_"$TYPE".anc_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".anc_ann.ac"
    if [ $FEATURE == "NSYN" ]
      then
      FEATURE2=(NTOL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.anc_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_${VAR}_${FEATURE2}_${TYPE}.anc_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE2"_"$TYPE".anc_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".anc_ann.ac"
      FEATURE2=(NDEL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.anc_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_${VAR}_${FEATURE2}_${TYPE}.anc_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE2"_"$TYPE".anc_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".anc_ann.ac"
    fi
    done
  done

#Generate version with consistent polarised sites only.
bedtools intersect -a <(awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $3,$4,$5,$6,$1,$2)}' ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".anc_ann.ac") -b consistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $5,$6,$1,$2,$3,$4)}' > ${CALLING}"_5x_perpop_ALL_features_consistent_"${VAR}"_"${TYPE}".anc_ann.ac"


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/*5x_perpop_ALL_features_${VAR}_${TYPE}.anc_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/*5x_perpop_ALL_features_consistent_${VAR}_${TYPE}.anc_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/

```

####Perfect-coverage sites only:
```{r Calculate derived allele frequency ratio, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_derived_counts_spectrum_perfectcov_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
 
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
#mkdir -p derived_allele_counts_spectrum
#scp -p /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt 
GREP=$(cat derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f1)
POP_VCFS=($(ls `find . -path *"_perpop/c_*5x*_perpop_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
rm ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".anc_ann.ac"
for p in ${POP_VCFS[@]}
  do
  SP_DATASET=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f1-3)
  SHORT_POP=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f4-6)
  echo "working with pop" $SHORT_POP "and vcf" $p
  echo "extracting derived allele counts from" $SHORT_POP
  N_MAX=$((2 * $(bcftools query -l ${p} | wc -l)))
  for g in ${GREP[@]}
    do
    #echo "grepping: ${g}"
    FEATURE=$(grep "${g}" derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f2)
    echo "extracting from feature:" $FEATURE
    grep "${g}" "${p}" | grep ";AN=${N_MAX}" | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$11)}' > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE}_${TYPE}.anc_ann.ac}
    echo "joining frequency files"
    awk -v pop="$SHORT_POP" -v feat="$FEATURE" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_perfectcov_"$VAR"_"$FEATURE"_"$TYPE".anc_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".anc_ann.ac"
    if [ $FEATURE == "NSYN" ]
      then
      FEATURE2=(NTOL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE}_${TYPE}.anc_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE2}_${TYPE}.anc_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_perfectcov_"$VAR"_"$FEATURE2"_"$TYPE".anc_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".anc_ann.ac"
      FEATURE2=(NDEL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE}_${TYPE}.anc_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_perfectcov_${VAR}_${FEATURE2}_${TYPE}.anc_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_perfectcov_"$VAR"_"$FEATURE2"_"$TYPE".anc_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".anc_ann.ac"
    fi
    done
  done

#Generate version with consistent polarised sites only.
bedtools intersect -a <(awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $3,$4,$5,$6,$1,$2)}' ${CALLING}"_5x_perpop_ALL_features_perfectcov_"${VAR}"_"${TYPE}".anc_ann.ac") -b consistent_ancestral_state_tiger_cat_lynxrufus.sorted.dani_variants.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $5,$6,$1,$2,$3,$4)}' > ${CALLING}"_5x_perpop_ALL_features_perfectcov_consistent_"${VAR}"_"${TYPE}".anc_ann.ac"


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/*5x_perpop_ALL_features_perfectcov_${VAR}_${TYPE}.anc_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/*5x_perpop_ALL_features_perfectcov_consistent_${VAR}_${TYPE}.anc_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/

```

###Plot spectra:
####Whole dataset.
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP", pattern="*ALL_features*"),pattern='consistent', invert=T, value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- data_frame("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")
  }
}

```

####Consistent polarisation only:
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP", pattern="*ALL_features*"),pattern='consistent', value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- tibble("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_consistent_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_consistent_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_consistent_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_consistent_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
  }
}

```

####Perfect-coverage only:
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony", pattern="*ALL_features*"),pattern='perfectcov', value=T),pattern='consistent',value=T,invert=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- tibble("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_perfectcov_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_perfectcov_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_perfectcov_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_perfectcov_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")
  }
}

```

####Perfect-coverage consistent only:
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony", pattern="*ALL_features*"),pattern='perfectcov', value=T),pattern='consistent',value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- tibble("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_perfectcov_consistent_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_perfectcov_consistent_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_perfectcov_consistent_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_perfectcov_consistent_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP_outerparsimony/")
  }
}

```

###Combine per population and feature allele frequency files (only sites with no missingness):
```{r Calculate derived allele frequency ratio, eval=FALSE, engine='bash'}

#This is performed to calculate the average derived allele frequency of segregating sites.
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_derived_freq_spectrum_nomissing_${VAR}_${TYPE}.anc_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
GREP=$(cat derived_allele_freq_ratio/features_derived_allele_freq_ratio.txt | cut -f1)
POP_VCFS=($(ls `find . -path *"_perpop/c_*5x*_perpop_"${VAR}"_"${TYPE}".anc_ann.vcf" -print`))
rm ${CALLING}"_5x_perpop_ALL_features_nomissing_"${VAR}"_"${TYPE}".anc_ann.af"
for p in ${POP_VCFS[@]}
  do
  SP_DATASET=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f1-3)
  SHORT_POP=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f4-6)
  N_IND=$(($(bcftools query -l $p | wc -l) *2))
  echo "working with pop" $SHORT_POP "and vcf" $p
  echo "extracting derived allele frequencies from" $SHORT_POP
  for g in ${GREP[@]}
    do
    #echo "grepping: ${g}"
    FEATURE=$(grep "${g}" derived_allele_freq_ratio/features_derived_allele_freq_ratio.txt | cut -f2)
    echo "extracting from feature:" $FEATURE
    grep "${g}" "${p}" | grep ";AN=${N_IND};" | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$13)}' > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_nomissing_${VAR}_${FEATURE}_${TYPE}.anc_ann.af}
    echo "joining frequency files"
    awk -v pop="$SHORT_POP" -v feat="$FEATURE" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_nomissing_"$VAR"_"$FEATURE"_"$TYPE".anc_ann.af" >> ${CALLING}"_5x_perpop_ALL_features_nomissing_"${VAR}"_"${TYPE}".anc_ann.af"
    if [ $FEATURE == "NSYN" ]
      then
      FEATURE2=(NTOL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_nomissing_${VAR}_${FEATURE}_${TYPE}.anc_ann.af}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_tolerated.txt > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_nomissing_${VAR}_${FEATURE2}_${TYPE}.anc_ann.af}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_nomissing_"$VAR"_"$FEATURE2"_"$TYPE".anc_ann.af" >> ${CALLING}"_5x_perpop_ALL_features_nomissing_"${VAR}"_"${TYPE}".anc_ann.af"
      FEATURE2=(NDEL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_nomissing_${VAR}_${FEATURE}_${TYPE}.anc_ann.af}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony/provean/missense_variants_provean_scores_deleterious.txt > ${p/perpop_${VAR}_${TYPE}.anc_ann.vcf/perpop_nomissing_${VAR}_${FEATURE2}_${TYPE}.anc_ann.af}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_nomissing_"$VAR"_"$FEATURE2"_"$TYPE".anc_ann.af" >> ${CALLING}"_5x_perpop_ALL_features_nomissing_"${VAR}"_"${TYPE}".anc_ann.af"
    fi
    done
  done


#Calculate average derived allele frequency of segregating sites.
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_outerparsimony
rm ${CALLING}_5x_perpop_ALL_features_nomissing_${VAR}_${TYPE}.anc_ann.mean_af
POP=$(cut -f1 ${CALLING}_5x_perpop_ALL_features_nomissing_${VAR}_${TYPE}.anc_ann.af | sort -u)
CATEGORY=$(cut -f2 ${CALLING}_5x_perpop_ALL_features_nomissing_${VAR}_${TYPE}.anc_ann.af | sort -u)
for pop in ${POP[@]}
  do
  for cat in ${CATEGORY[@]}
    do
    grep "$pop" ${CALLING}_5x_perpop_ALL_features_nomissing_${VAR}_${TYPE}.anc_ann.af | grep "$cat" > grep.subset.af.borrar
    SUM=$(cut -f6 grep.subset.af.borrar | paste -sd+ | bc)
    N_SITES=$(wc -l < grep.subset.af.borrar)
    MEAN_AF=$(echo "scale=4; $SUM/$N_SITES" | bc)
    echo -e "$pop\t$cat\t$MEAN_AF"
    echo -e "$pop\t$cat\t$MEAN_AF" >> ${CALLING}_5x_perpop_ALL_features_nomissing_${VAR}_${TYPE}.anc_ann.mean_af
    done
  done
rm grep.subset.af.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/*5x_perpop_ALL_features_nomissing_${VAR}*.anc_ann.af /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_freq_spectrum/
#scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/*5x_perpop_ALL_features*.anc_ann.maf.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_freq_spectrum/

```


#Tiger-cat-rufus with est-sfs:
##1. Infer ancestral state by est-sfs:
###Lynx pardinus + Lynx lynx combined:
####Build input:
#####Whole-genome:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
mkdir -p /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#First, format the focal species (Iberian and Eurasian lynx) data:
grep -v '#' /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf | grep ';AN=120;' | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$15-$11,$5,$11,$9)}' > est_sfs_step1.sorted.dani_variants.focal.bed

awk '{                                       
if ($4=="A" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,$7,0,0,$8);
else if ($4=="A" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,$7,0,$8);
else if ($4=="A" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,0,$7,$8);
else if ($4=="C" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,$5,0,0,$8);
else if ($4=="C" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,$7,0,$8);
else if ($4=="C" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,0,$7,$8);
else if ($4=="G" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,$5,0,$8);
else if ($4=="G" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,$5,0,$8);
else if ($4=="G" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$5,$7,$8);
else if ($4=="T" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,0,$5,$8);
else if ($4=="T" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,0,$5,$8);
else if ($4=="T" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$7,$5,$8);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,0,$8);
}' est_sfs_step1.sorted.dani_variants.focal.bed > est_sfs_step2.sorted.dani_variants.focal.bed


#Second, format the outgroup species data:
##Tiger:
awk '{                                       
split($0,a,":");
split(a[1],b,"=");
split(b[2],c,"");
if (c[1]=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,1,0,0,0,$6);
else if (c[1]=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,1,0,0,$6);
else if (c[1]=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,1,0,$6);
else if (c[1]=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,1,$6);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,0,$6);
}' /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed > est_sfs_step1.sorted.dani_variants.tiger.bed

##Cat:
awk '{                                       
split($0,a,":");
split(a[1],b,"=");
split(b[2],c,"");
if (c[2]=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,1,0,0,0,$6);
else if (c[2]=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,1,0,0,$6);
else if (c[2]=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,1,0,$6);
else if (c[2]=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,1,$6);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,0,$6);
}' /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed > est_sfs_step1.sorted.dani_variants.cat.bed

##Bobcat:
awk '{                                       
split($0,a,":");
split(a[1],b,"=");
split(b[2],c,"");
if (c[3]=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,1,0,0,0,$6);
else if (c[3]=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,1,0,0,$6);
else if (c[3]=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,1,0,$6);
else if (c[3]=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,1,$6);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,0,$6);
}' /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed > est_sfs_step1.sorted.dani_variants.bobcat.bed

##Join these files:
bedtools intersect -a est_sfs_step1.sorted.dani_variants.bobcat.bed -b est_sfs_step1.sorted.dani_variants.cat.bed -wb | bedtools intersect -a "stdin" -b est_sfs_step1.sorted.dani_variants.tiger.bed -wb | awk '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$9,$14,$15)}' > est_sfs_step2.sorted.dani_variants.outgroup.bed


#Finally, generate the squared data for all species and format the final input data for the programme:
bedtools intersect -a est_sfs_step2.sorted.dani_variants.focal.bed -b est_sfs_step2.sorted.dani_variants.outgroup.bed -wb > est_sfs_step3.sorted.dani_variants.dataset.txt
awk '{printf ("%s\t%s\t%s\t%s\n", $4,$9,$10,$11)}' est_sfs_step3.sorted.dani_variants.dataset.txt > est_sfs_step4.sorted.dani_variants.input.txt

```

#####Except intergenic:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
mkdir -p /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#First, format the focal species (Iberian and Eurasian lynx) data with the old polarisation:
grep -Ev '#|intergenic' /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarized_filteredall_varssubs_SNP.lr_ann.vcf | grep ';AN=120;' | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$15-$11,$5,$11,$9)}' > est_sfs_step1.sorted.dani_wout_intergenic_variants.focal.bed

awk '{                                       
if ($4=="A" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,$7,0,0,$8);
else if ($4=="A" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,$7,0,$8);
else if ($4=="A" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,0,$7,$8);
else if ($4=="C" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,$5,0,0,$8);
else if ($4=="C" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,$7,0,$8);
else if ($4=="C" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,0,$7,$8);
else if ($4=="G" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,$5,0,$8);
else if ($4=="G" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,$5,0,$8);
else if ($4=="G" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$5,$7,$8);
else if ($4=="T" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,0,$5,$8);
else if ($4=="T" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,0,$5,$8);
else if ($4=="T" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$7,$5,$8);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,0,$8);
}' est_sfs_step1.sorted.dani_wout_intergenic_variants.focal.bed > est_sfs_step2.sorted.dani_wout_intergenic_variants.focal.bed


#For the outgroup species data we'll be using the whole-genome ones.


#Finally, format the final input data for the programme:
bedtools intersect -a est_sfs_step2.sorted.dani_wout_intergenic_variants.focal.bed -b est_sfs_step2.sorted.dani_variants.outgroup.bed -wb > est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset.txt
awk '{printf ("%s\t%s\t%s\t%s\n", $4,$9,$10,$11)}' est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset.txt > est_sfs_step4.sorted.dani_wout_intergenic_variants.input.txt

```

####Run the programme:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#Run the programme with rate6 model:
screen -S est_sfs_rate6_nrandom10.sorted.dani_variants
script est_sfs_rate6_nrandom10.sorted.dani_variants.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-rate6.txt ./est_sfs_step4.sorted.dani_variants.input.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_variants.uSFS_rate6.txt ./est_sfs_step5.sorted.dani_variants.pvalues_rate6.txt

#Run the programme with Kimura model:
screen -S est_sfs_kimura_nrandom10.sorted.dani_variants
script est_sfs_kimura_nrandom10.sorted.dani_variants.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-kimura.txt ./est_sfs_step4.sorted.dani_variants.input.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_variants.uSFS_kimura.txt ./est_sfs_step5.sorted.dani_variants.pvalues_kimura.txt


cd /home/dkleinman/datos/est-sfs_tests/
time est-sfs config-rate6.txt kaka_test.txt seedfile.txt kaka_test.uSFS.txt kaka_test.pvalues.txt

cd /home/dkleinman/datos/est-sfs_tests/
time est-sfs config-rate6.txt kaka_test2.txt seedfile.txt kaka_test2.uSFS.txt kaka_test2.pvalues.txt

cd /home/dkleinman/datos/est-sfs_tests/
time est-sfs config-rate6.txt kaka_test3.txt seedfile.txt kaka_test3.uSFS.txt kaka_test3.pvalues.txt


```

####Extract the ancestral information:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
CONFIG=(kimura) #rate6 #kimura

paste <(bedtools intersect -a est_sfs_step2.sorted.dani_wout_intergenic_variants.focal.bed -b est_sfs_step2.sorted.dani_variants.outgroup.bed -wb | awk '{printf ("%s\t%s\t%s\n", $1,$2,$3)}') <(awk '$1!=0 {printf ("%s\n", $3)}' est_sfs_step5.sorted.dani_wout_intergenic_variants.pvalues_$CONFIG.txt) > est_sfs_step6.sorted.dani_wout_intergenic_variants.ancestral_prob_$CONFIG.bed

bedtools intersect -a est_sfs_step6.sorted.dani_wout_intergenic_variants.ancestral_prob_$CONFIG.bed -b est_sfs_step1.sorted.dani_variants.focal.bed -wb | awk '{if ($9>$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12); 
else if ($9<$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="C" && $10!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="C" && $8!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="G" && $10=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="G" && $8=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
}' > est_sfs_step7.sorted.dani_wout_intergenic_variants.ancestral_vs_derived_$CONFIG.bed

awk '{if ($4==1.00000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$7);
else if ($4==0.00000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$6,$7)}' est_sfs_step7.sorted.dani_wout_intergenic_variants.ancestral_vs_derived_$CONFIG.bed > ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.bed

```

###Lynx pardinus and Lynx lynx separated:
####Build input:
#####Except intergenic:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL

mkdir -p /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#First, split the two species.
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perspecies_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation
for sp in ${SPECIES[@]}
  do
  echo ${sp}
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${sp}_*_samples > /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${sp}_codes
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V ${CALLING}_polarized_filteredall_${VAR}_${TYPE}.lr_ann.vcf \
  -o ${sp}_${NM_COV}_perspecies_${VAR}_${TYPE}.lr_ann.vcf \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${sp}_codes
  grep -v '#' ${sp}_${NM_COV}_perspecies_${VAR}_${TYPE}.lr_ann.vcf | wc -l #
  done

--->

#Next, format the focal species (Iberian and Eurasian lynx) data with the old polarisation:
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
for sp in ${SPECIES[@]}
  do
  echo ${sp}
  N_IND=$((2* $(bcftools query -l /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${sp}_${NM_COV}_perspecies_${VAR}_${TYPE}.lr_ann.vcf | wc -l)))
  grep -Ev '#|intergenic' /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${sp}_${NM_COV}_perspecies_${VAR}_${TYPE}.lr_ann.vcf | grep ";AN="$N_IND";" | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$15-$11,$5,$11,$9)}' > est_sfs_step1.sorted.dani_wout_intergenic_variants.focal_${sp}.bed
  awk '{                                       
if ($4=="A" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,$7,0,0,$8);
else if ($4=="A" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,$7,0,$8);
else if ($4=="A" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,0,$7,$8);
else if ($4=="C" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,$5,0,0,$8);
else if ($4=="C" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,$7,0,$8);
else if ($4=="C" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,0,$7,$8);
else if ($4=="G" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,$5,0,$8);
else if ($4=="G" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,$5,0,$8);
else if ($4=="G" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$5,$7,$8);
else if ($4=="T" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,0,$5,$8);
else if ($4=="T" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,0,$5,$8);
else if ($4=="T" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$7,$5,$8);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,0,$8);
}' est_sfs_step1.sorted.dani_wout_intergenic_variants.focal_${sp}.bed > est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_${sp}.bed
  done

bedtools intersect -a est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_c_ll.bed -b est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_c_lp.bed > est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_c_ll_squared.bed

bedtools intersect -a est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_c_lp.bed -b est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_c_ll.bed > est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_c_lp_squared.bed


#For the outgroup species data we'll be using the whole-genome ones.


#Finally, format the final input data for the programme:
for sp in ${SPECIES[@]}
  do
  echo ${sp}
  bedtools intersect -a est_sfs_step2.sorted.dani_wout_intergenic_variants.focal_${sp}_squared.bed -b est_sfs_step2.sorted.dani_variants.outgroup.bed -wb > est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_${sp}.txt
  awk '{printf ("%s\t%s\t%s\t%s\n", $4,$9,$10,$11)}' est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_${sp}.txt > est_sfs_step4.sorted.dani_wout_intergenic_variants.input_${sp}.txt
  done

```

#####Except intergenic, only polymorphic sites:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL

mkdir -p /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#First, split the two species (code in the previous section).

#Next, format the focal species (Iberian and Eurasian lynx) data with the old polarisation:
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
for sp in ${SPECIES[@]}
  do
  echo ${sp}
  N_IND=$((2* $(bcftools query -l /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${sp}_${NM_COV}_perspecies_${VAR}_${TYPE}.lr_ann.vcf | wc -l)))
  grep -Ev '#|intergenic' /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/${sp}_${NM_COV}_perspecies_${VAR}_${TYPE}.lr_ann.vcf | grep ";AN="$N_IND";" | awk -F"\t|;|="  '{printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2-1,$2,$4,$15-$11,$5,$11,$9)}' | awk -v n_ind=$N_IND '{if (!($5==n_ind || $7==n_ind)) print $0}' > est_sfs_step1.sorted.dani_wout_intergenic_polymorphic_variants.focal_${sp}.bed
  awk '{                                       
if ($4=="A" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,$7,0,0,$8);
else if ($4=="A" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,$7,0,$8);
else if ($4=="A" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$5,0,0,$7,$8);
else if ($4=="C" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,$5,0,0,$8);
else if ($4=="C" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,$7,0,$8);
else if ($4=="C" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$5,0,$7,$8);
else if ($4=="G" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,$5,0,$8);
else if ($4=="G" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,$5,0,$8);
else if ($4=="G" && $6=="T") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$5,$7,$8);
else if ($4=="T" && $6=="A") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,$7,0,0,$5,$8);
else if ($4=="T" && $6=="C") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,$7,0,$5,$8);
else if ($4=="T" && $6=="G") printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,$7,$5,$8);
else printf ("%s\t%s\t%s\t%s,%s,%s,%s\t%s\n", $1,$2,$3,0,0,0,0,$8);
}' est_sfs_step1.sorted.dani_wout_intergenic_polymorphic_variants.focal_${sp}.bed > est_sfs_step2.sorted.dani_wout_intergenic_polymorphic_variants.focal_${sp}.bed
  #For the outgroup species data we'll be using the whole-genome ones.
  #Finally, format the final input data for the programme:
  bedtools intersect -a est_sfs_step2.sorted.dani_wout_intergenic_polymorphic_variants.focal_${sp}.bed -b est_sfs_step2.sorted.dani_variants.outgroup.bed -wb > est_sfs_step3.sorted.dani_wout_intergenic_polymorphic_variants.dataset_${sp}.txt
  awk '{printf ("%s\t%s\t%s\t%s\n", $4,$9,$10,$11)}' est_sfs_step3.sorted.dani_wout_intergenic_polymorphic_variants.dataset_${sp}.txt > est_sfs_step4.sorted.dani_wout_intergenic_polymorphic_variants.input_${sp}.txt
  done

```

####Run the programme:
#####Except intergenic:
######Kimura config:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#Run the programme with Kimura model:
##Iberian lynx:
screen -S est_sfs_kimura_nrandom10.sorted.dani_wout_intergenic_variants_c_lp
script est_sfs_kimura_nrandom10.sorted.dani_wout_intergenic_variants_c_lp.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-kimura.txt ./est_sfs_step4.sorted.dani_wout_intergenic_variants.input_c_lp.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.uSFS_kimura_c_lp.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.pvalues_kimura_c_lp.txt

##Eurasian lynx:
screen -S est_sfs_kimura_nrandom10.sorted.dani_wout_intergenic_variants_c_ll
script est_sfs_kimura_nrandom10.sorted.dani_wout_intergenic_variants_c_ll.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-kimura.txt ./est_sfs_step4.sorted.dani_wout_intergenic_variants.input_c_ll.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.uSFS_kimura_c_ll.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.pvalues_kimura_c_ll.txt

```

######Rate6 config:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#Run the programme with rate6 model:
##Iberian lynx:
screen -S est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_variants_c_lp
script est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_variants_c_lp.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-rate6.txt ./est_sfs_step4.sorted.dani_wout_intergenic_variants.input_c_lp.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.uSFS_rate6_c_lp.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.pvalues_rate6_c_lp.txt


##Eurasian lynx:
screen -S est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_variants_c_ll
script est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_variants_c_ll.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-rate6.txt ./est_sfs_step4.sorted.dani_wout_intergenic_variants.input_c_ll.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.uSFS_rate6_c_ll.txt ./est_sfs_step5.sorted.dani_wout_intergenic_variants.pvalues_rate6_c_ll.txt

```

#####Except intergenic, only polymorphic sites:
######Kimura config:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#Run the programme with Kimura model:
##Iberian lynx:
screen -S est_sfs_kimura_nrandom10.wout_intergenic_polymorphic_c_lp
script est_sfs_kimura_nrandom10.wout_intergenic_polymorphic_c_lp.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-kimura.txt ./est_sfs_step4.sorted.dani_wout_intergenic_polymorphic_variants.input_c_lp.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.uSFS_kimura_c_lp.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.pvalues_kimura_c_lp.txt

##Eurasian lynx:
screen -S est_sfs_kimura_nrandom10.wout_intergenic_polymorphic_c_ll
script est_sfs_kimura_nrandom10.wout_intergenic_polymorphic_c_ll.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-kimura.txt ./est_sfs_step4.sorted.dani_wout_intergenic_polymorphic_variants.input_c_ll.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.uSFS_kimura_c_ll.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.pvalues_kimura_c_ll.txt

```

######Rate6 config:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs

#Run the programme with rate6 model:
##Iberian lynx:
screen -S est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_polymorphic_variants_c_lp
script est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_polymorphic_variants_c_lp.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-rate6.txt ./est_sfs_step4.sorted.dani_wout_intergenic_polymorphic_variants.input_c_lp.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.uSFS_rate6_c_lp.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.pvalues_rate6_c_lp.txt


##Eurasian lynx:
screen -S est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_polymorphic_variants_c_ll
script est_sfs_rate6_nrandom5.sorted.dani_wout_intergenic_polymorphic_variants_c_ll.log

time est-sfs /home/dkleinman/datos/est-sfs_tests/config-rate6.txt ./est_sfs_step4.sorted.dani_wout_intergenic_polymorphic_variants.input_c_ll.txt /home/dkleinman/datos/est-sfs_tests/seedfile.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.uSFS_rate6_c_ll.txt ./est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.pvalues_rate6_c_ll.txt

```

####Extract the ancestral information:
#####Except intergenic:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
CONFIG=(kimura) #rate6 #kimura

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

for sp in ${SPECIES[@]}
  do
  echo ${sp}
  paste <(awk '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_${sp}.txt) <(awk '$1!=0 {printf ("%s\n", $3)}' est_sfs_step5.sorted.dani_wout_intergenic_variants.pvalues_${CONFIG}_${sp}.txt) > est_sfs_step6.sorted.dani_wout_intergenic_variants.ancestral_prob_${CONFIG}_${sp}.bed
  
  bedtools intersect -a est_sfs_step6.sorted.dani_wout_intergenic_variants.ancestral_prob_${CONFIG}_${sp}.bed -b est_sfs_step1.sorted.dani_wout_intergenic_variants.focal_${sp}.bed -wb | awk '{if ($9>$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12); 
else if ($9<$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="C" && $10!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="C" && $8!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="G" && $10=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="G" && $8=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
}' > est_sfs_step7.sorted.dani_wout_intergenic_variants.ancestral_vs_derived_${CONFIG}_${sp}.bed
  done

for sp in ${SPECIES[@]}
  do
  echo ${sp}
  awk '{if ($4>=0.50000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$7);
else if ($4<0.50000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$6,$7)}' est_sfs_step7.sorted.dani_wout_intergenic_variants.ancestral_vs_derived_${CONFIG}_${sp}.bed > ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.${CONFIG}_${sp}.bed
  done

#Calculate the number of discordant inferred AA between the two species:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -wb | awk '$4!=$9 {print $0}' | wc -l #414694 vs 508878 where the AA is the same


#Focus only on the polymorphic sites.
##Lynx lynx:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b est_sfs_step3.sorted.dani_wout_intergenic_polymorphic_variants.dataset_c_ll.txt > ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_ll.bed
awk '$4!=$5 {print $0}' ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_ll.bed | wc -l #35328 sites where the AA is different from rufus

bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -b est_sfs_step3.sorted.dani_wout_intergenic_polymorphic_variants.dataset_c_lp.txt > ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_lp.bed
awk '$4!=$5 {print $0}' ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_lp.bed  | wc -l #19182 sites where the AA is different from rufus

bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_ll.bed -b ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_lp.bed -wb | awk '$4!=$9 {print $0}' | wc -l #6450 sites where the AA is different between Iberian and Eurasian

cat ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_l*.bed | awk '$4!=$5 {print $0}' | cut -f-3 | sort -k1,1 -k2,2n -u > discrepant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura.bed #54011 sites in total where the AA has changed from before

bedtools intersect -a <(awk '$4!=$5 {print $0}' ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_ll.bed) -b est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_c_ll.txt -wb | less -S

bedtools intersect -a <(awk '$4!=$5 {print $0}' ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.kimura_c_lp.bed) -b est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_c_lp.txt -wb | less -S

```

#####Test dataset for Keightley:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
CONFIG=(kimura) #rate6 #kimura

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)


#First, for Lynx lynx:
##Get the sites whose inferred AA are discordant between the two species:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -wb | awk '$4!=$9 {printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > discordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed

##Get the sites whose inferred AA are concordant between the two species:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -wb | awk '$4==$9 {printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > concordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed

##Generate a new est-sfs input with discordant sites on top:
cat <(bedtools intersect -a discordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_c_ll.txt -wb | awk '{printf ("%s\t%s\t%s\t%s\n", $8,$13,$14,$15)}') <(bedtools intersect -a concordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_c_ll.txt -wb | awk '{printf ("%s\t%s\t%s\t%s\n", $8,$13,$14,$15)}') > reordered.dani_wout_intergenic_variants.input_c_ll.bed

#Second, for Lynx pardinus:
##Get the sites whose inferred AA are discordant between the two species:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -b ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -wb | awk '$4!=$9 {printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > discordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed

##Get the sites whose inferred AA are concordant between the two species:
bedtools intersect -a ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -b ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -wb | awk '$4==$9 {printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > concordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed

##Generate a new est-sfs input with discordant sites on top:
cat <(bedtools intersect -a discordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -b est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_c_lp.txt -wb | awk '{printf ("%s\t%s\t%s\t%s\n", $8,$13,$14,$15)}') <(bedtools intersect -a concordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -b est_sfs_step3.sorted.dani_wout_intergenic_variants.dataset_c_lp.txt -wb | awk '{printf ("%s\t%s\t%s\t%s\n", $8,$13,$14,$15)}') > reordered.dani_wout_intergenic_variants.input_c_lp.bed

#Finally, generate a file with the inferred AA for ll (1st column) for lp (2nd column) and using parsimony (3rd column):
bedtools intersect -a <(cat <(bedtools intersect -a discordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b discordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -wb) <(bedtools intersect -a concordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_ll.bed -b concordant_ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_variants.kimura_c_lp.bed -wb)) -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed -wb | awk '{printf ("%s\t%s\t%s\n", $4,$8,$13)}' > reordered.dani_wout_intergenic_variants.AA_comparison.bed


#From outside the server:
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCR_est_sfs/est_sfs_step4.sorted.dani_variants.input.txt /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/est-sfs_tests

scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCR_est_sfs/reordered.dani_wout_intergenic_variants.input_c_ll.bed /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/est-sfs_tests

scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCR_est_sfs/reordered.dani_wout_intergenic_variants.input_c_lp.bed /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/est-sfs_tests

scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCR_est_sfs/reordered.dani_wout_intergenic_variants.AA_comparison.bed /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/est-sfs_tests

scp dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/est-sfs_tests/config-kimura.txt /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/est-sfs_tests

```

#####Except intergenic, only polymorphic sites:
```{bash}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCR_est_sfs
CONFIG=(kimura) #rate6 #kimura

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

for sp in ${SPECIES[@]}
  do
  echo ${sp}
  paste <(awk '{printf ("%s\t%s\t%s\n", $1,$2,$3)}' est_sfs_step3.sorted.dani_wout_intergenic_polymorphic_variants.dataset_${sp}.txt) <(awk '$1!=0 {printf ("%s\n", $3)}' est_sfs_step5.sorted.dani_wout_intergenic_polymorphic_variants.pvalues_${CONFIG}_${sp}.txt) > est_sfs_step6.sorted.dani_wout_intergenic_polymorphic_variants.ancestral_prob_${CONFIG}_${sp}.bed
  
  bedtools intersect -a est_sfs_step6.sorted.dani_wout_intergenic_polymorphic_variants.ancestral_prob_${CONFIG}_${sp}.bed -b est_sfs_step1.sorted.dani_wout_intergenic_polymorphic_variants.focal_${sp}.bed -wb | awk '{if ($9>$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12); 
else if ($9<$11) printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="C" && $10!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="C" && $8!="A") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
else if ($9==$11 && $8=="G" && $10=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$8,$10,$12);
else if ($9==$11 && $10=="G" && $8=="T") printf ("%s\t%s\t%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$4,$10,$8,$12);
}' > est_sfs_step7.sorted.dani_wout_intergenic_polymorphic_variants.ancestral_vs_derived_${CONFIG}_${sp}.bed
  done

for sp in ${SPECIES[@]}
  do
  echo ${sp}
  awk '{if ($4>=0.50000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$5,$7);
else if ($4<0.50000) printf ("%s\t%s\t%s\t%s\t%s\n", $1,$2,$3,$6,$7)}' est_sfs_step7.sorted.dani_wout_intergenic_polymorphic_variants.ancestral_vs_derived_${CONFIG}_${sp}.bed > ancestral_state_tiger_cat_lynxrufus_est_sfs.sorted.dani_wout_intergenic_polymorphic_variants.${CONFIG}_${sp}.bed
  done

```

##2: Adjust polarisation.
###Replace inconsistent AA.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#First make two subset VCFs: one with the inconsistent sites, and one with the rest (which includes all consistent sites as well as all those such as INDELs or triallelic that were eventually filtered out).
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed

bedtools subtract -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_consistent_and_filteredout_sites.vcf

bedtools intersect -a ../c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled.vcf -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites.vcf

#Discard INDELs from the inconsistent sites VCF in order to avoid duplicate rows, which can mess up the subsequent re-polarisation loop.
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_inconsistent_sites.vcf \
-o ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

grep -v '#' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf > ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf
mv ${CALLING}_aafilled_inconsistent_sites_SNP_bis.vcf ${CALLING}_aafilled_inconsistent_sites_SNP.vcf

#Discard INDELs from the consistent sites VCF to be able to later paste it with the inconsistent one (because the AA column shifts place when the file is parsed by GATK).
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
-T SelectVariants \
-selectType SNP \
-restrictAllelesTo BIALLELIC \
-R $REF \
-V ${CALLING}_aafilled_consistent_and_filteredout_sites.vcf \
-o ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf

#Next, fix the AA annotation for the inconsistent sites.
screen -S "${CALLING}-aafilled_fixed.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script "${CALLING}-aafilled_fixed.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)

#For sites with an inconsistent polarisation between the old and the new parsimony (as inferred above), replace the previously inferred AA ("old") with the newly inferred one ("new").
rm c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_inconsistent_sites_SNP_fixed.vcf
TOTAL=$(wc -l < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed)
COUNTER=0
while read -r row
  do
  ((COUNTER++))
  #PATTERN=$(echo "$row" | awk -F"\t" '{printf ("%s\t%s\n", $1,$3)}')
  #SCAFFOLD=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $1)}')
  #POSITION=$(echo "$row" | awk -F"\t" '{printf ("%s\n", $3)}')
  OLD_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$6)}')
  NEW_AA=$(echo "$row" | awk -F"\t" '{printf ("%s%s\n", "\tAA=",$5)}')
  #sed -n '/^'"$PATTERN"'/{s/'"$OLD_AA"'/'"$NEW_AA"'/;p;q}' ${CALLING}_aafilled_inconsistent_sites_SNP.vcf >> ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf
  sed "${COUNTER}q;d" ${CALLING}_aafilled_inconsistent_sites_SNP.vcf | sed 's/'"$OLD_AA"'/'"$NEW_AA"'/' >> ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf
  if [ $(( $COUNTER % 1000 )) == 0 ]
    then
    echo "fixed polarization of $COUNTER sites out of $TOTAL"
  fi
  done < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed

---

bedtools sort -i <(cat ${CALLING}_aafilled_consistent_and_filteredout_sites_SNP.vcf ${CALLING}_aafilled_inconsistent_sites_SNP_fixed.vcf) -header > c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_aafilled_fixed_SNP.vcf

```

###Use VcfFilterJdk to polarize the AA-filled VCF.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

#Polarize the AA-filled VCF based on the new INFO/AA column. Alleles will be switched whenever the ancestral allele matches the alternative one, and genotypes will be properly recoded as well. The following code was originally provided by Pierre Lindenbaum and modified by José Luis Castro.

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/
screen -S ${CALLING}-polarizedfixed.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarizedfixed.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


java -jar /opt/jvarkit/dist/vcffilterjdk.jar -e 'if(variant.getNAlleles()!=2 || !variant.hasAttribute("AA")) return true; 
final String aa = variant.getAttributeAsString("AA",""); 
if(!variant.getAlleles().get(1).getDisplayString().equalsIgnoreCase(aa)) return true; 
VariantContextBuilder vb=new VariantContextBuilder(variant); 

Allele oldalt = variant.getAlleles().get(1);
Allele oldref = variant.getAlleles().get(0); 
Allele ref= Allele.create(oldalt.getDisplayString(),true); 
Allele alt= Allele.create(oldref.getDisplayString(),false);

vb.alleles(Arrays.asList(ref,alt)); 

List genotypes= new ArrayList<>(); 
for(Genotype g: variant.getGenotypes()) 
  { 
  if(!g.isCalled()) 
  { genotypes.add(g); continue;} 
  GenotypeBuilder gb = new GenotypeBuilder(g); 
  List alleles = new ArrayList<>(); 
  for(Allele a:g.getAlleles()) { 
    if(a.equals(oldalt)) { a=ref;} 
    else if(a.equals(oldref)) { a=alt;} 
    alleles.add(a); 
    } 
  if(g.hasPL()) { 
    int pl[] = g.getPL(); 
    int pl2[] = new int[pl.length]; 
    for(int i=0;i< pl.length;i++) pl2[i]=pl[(pl.length-1)-i]; 
    gb.PL(pl2); 
    } 
  if(g.hasAD()) 
    { int ad[] = g.getAD(); 
    int ad2[] = new int[ad.length]; 
    for(int i=0;i< ad.length;i++) ad2[i]=ad[(ad.length-1)-i];
    gb.AD(ad2); 
  } 
  genotypes.add(gb.alleles(alleles).make()); 
  }

vb.attribute("AF",1.0d - Double.parseDouble(variant.getAttributeAsString("AF",""))); vb.attribute("AC",variant.getGenotypes().stream().flatMap(G->G.getAlleles().stream()).filter(A->A.equals(oldref)).count()); 
vb.genotypes(genotypes); 
return vb.make();' -o ${CALLING}_polarizedfixed.vcf ${CALLING}_aafilled_fixed_SNP.vcf

```

###Generate ancestral state fasta reference.
```{r Polarize contemporary VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/

#Transform fasta to tab (not really tab separated, only the last column) format to ease the editing.
seqkit fx2tab /home/datos_usuarios/dkleinman/snpEff/data/genomes/LYRU.23.fa > LYRU.23.tab

#Next, edit the Rufus fasta in order to generate the Ancestral fasta:
screen -S fixing_fasta
script fixing_fasta.log
rm ANCESTRAL.23.tab
#First copy all the scaffolds that will remain unchanged:
grep -v -f <(cut -f1 /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | sort | uniq) LYRU.23.tab | awk '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' > ANCESTRAL.23.tab
#Next loop over the inconsistent variants (those for which the polarisation is the reverse or are now deemed unpolarisable), grep the scaffold which they belong to, edit the base, and use that file as the input for the next variant in the same scaffold
COUNTER=0
PREV_SCAFFOLD=("lp23.s00000")
OLD_SCAFFOLD=$(head -n1 LYRU.23.tab | awk '{printf ("%s\n",$1)}')
TOTAL=$(wc -l < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed)
while read -r SCAFFOLD START STOP SYNTENY ANCESTRAL RUFUS; do
  #If this is the first variant in the scaffold, grep the Rufus sequence from that scaffold to use as input.
  if [[ "$SCAFFOLD" != "$PREV_SCAFFOLD" ]]
    then
    grep "$SCAFFOLD" LYRU.23.tab > $SCAFFOLD.LYRU.23.tab
    echo "generating input file for scaffold" $SCAFFOLD
  fi
  PREV_SCAFFOLD=$SCAFFOLD
  #Print the sequence replacing only the current variant, and replace the previous input with this output:
  awk -v stop=$STOP -v ancestral=$ANCESTRAL '{printf ("%s\t%s\t%s\t%s%s%s\n", $1,$2,$3,substr($4,1,stop-1),ancestral,substr($4,stop+1))}' $SCAFFOLD.LYRU.23.tab > $SCAFFOLD.tmp && mv $SCAFFOLD.tmp $SCAFFOLD.LYRU.23.tab
  #If there is a change in scaffold, the editing of the previous scaffold is now complete and can be appended to the new ancestral file.
  if [[ "$SCAFFOLD" != "$OLD_SCAFFOLD" ]]
    then
    cat $OLD_SCAFFOLD.LYRU.23.tab >> ANCESTRAL.23.tab
    echo "advancing to scaffold" $SCAFFOLD
    rm $OLD_SCAFFOLD.LYRU.23.tab
  fi
  OLD_SCAFFOLD=$SCAFFOLD
  ((COUNTER++))
  if [ $(( $COUNTER % 100 )) == 0 ]
    then
    echo "processed $COUNTER sites out of $TOTAL"
  fi
 done < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed
#The editing of the last scaffold is now complete and can be appended to the new ancestral file.
SCAFFOLD=$(tail -n1 /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | awk '{printf ("%s\n",$1)}')
cat $SCAFFOLD.LYRU.23.tab >> ANCESTRAL.23.tab
rm $SCAFFOLD.LYRU.23.tab


#Sort the ancestral file so that scaffolds regain their order, and place the field separators used by seqkit (two white spaces, one white space, and one tab, respectively), in order to convert it back to fasta format:
sort -k1,1 ANCESTRAL.23.tab | awk '{printf ("%s  %s %s\t%s\n", $1,$2,$3,$4)}' > ANCESTRAL_sorted.23.tab
seqkit tab2fx ANCESTRAL_sorted.23.tab > ANCESTRAL.23.fa

#Chech if it worked fine:
rm kaka.borrar
while read -r SCAFFOLD START STOP SYNTENY ANCESTRAL RUFUS; do
  OLD=$(grep "$SCAFFOLD" LYRU.23.tab | awk '{printf ("%s\n", $4)}' | cut -c$STOP)
  NEW=$(grep "$SCAFFOLD" ANCESTRAL.23.tab | awk '{printf ("%s\n", $4)}' | cut -c$STOP)
  echo -e "$SCAFFOLD\t$STOP\t$RUFUS\t$OLD\t$ANCESTRAL\t$NEW" >> kaka.borrar
 done < /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/inconsistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed
#Seems like all key positions have changed correctly, while random ones are still the same.

```

###Add ancestral state reference to the SnpEff database. Annotating against the Ancestral genome is the correct option if the VCF has been polarized based on that genome.
####Add entry to the config file
```{r Set up SnpEff, eval=FALSE, engine='bash'}

#Originally the config was just in the software folder and I didn't have writing permission. If this is the only config file available, writing permission is required, and when annotating later on, the file should be called using the -c command followed by the path to the file.
#However, in my case I believe the tech group created a copy of the file in my folder after I sent them an e-mail, and this is the one that I was able to edit.

cd /home/dkleinman/datos/snpEff
#mv /home/dkleinman/snpEff.config ./ #I move the config file that appeared in my folder to a subfolder that I created for snpEff
vi snpEff.config  #initiate the editing process

#Following the manual, I added the following two lines (use :o to start editing -watch out for the current line- and :wq to save and exit):

# Ancestral lynx genome (parsimony criteria)
LYANCESTRAL.23.genome : Ancestral lynx (parsimony) #from now on, LYANCESTRAL.23 is the snpEff code for the ancestral lynx (parsimony criteria) genome, whose original route is: /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_polarizedfixed/ANCESTRAL.23.fa

```

####Create directory and move files
```{r Set up SnpEff, eval=FALSE, engine='bash'}

#First for the regular annotation:
mkdir /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23 #create a directory inside the software's dependencies whose name matches the code
cd /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23

scp /GRUPOS/grupolince/Lyp_annotation_Apr14_final/LYPA23C.all.fix.nr.gff3 /home/dkleinman/datos/snpEff/data/LYANCESTRAL.23/ #copy the annotation file (can be gff or gtf) to the newly created directory. This gff file includes CDS, introns, exons and genes, so it's very basic. A more complex version that Maria created which includes lncRNAs, etc., will be considered as custom annotation.
mv LYPA23C.all.fix.nr.gff3 genes.gff #rename the file as the tutorial indicates

mkdir -p /home/dkleinman/datos/snpEff/data/genomes #create a directory inside the software's dependencies called genomes
cd /home/dkleinman/datos/snpEff/data/genomes
scp /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/TCRLP_polarizedfixed/ANCESTRAL.23.fa /home/dkleinman/datos/snpEff/data/genomes/LYANCESTRAL.23.fa #copy the reference genome fasta to the new genomes directory

```

####Build the Ancestral genome database
```{r Set up SnpEff, eval=FALSE, engine='bash'}

cd /home/dkleinman/datos/snpEff
screen -S build_LYANCESTRAL_snpEff_db #open a dettachable screen in case the database building takes too long
script build_LYANCESTRAL_snpEff_db.txt #initiate the log file

cd /opt/snpEff
java -jar snpEff.jar build -gff3 -v LYANCESTRAL.23 -c /home/dkleinman/datos/snpEff/snpEff.config -dataDir /home/dkleinman/datos/snpEff/data #build the database. Use the -gff3 command for gff files and -gtf22 for gtf files. Use -v for verbose (expanded information on the processes and the warnings/errors that may appear). Use -c to indicate the path to my own config file. Then use -dataDir to override the data directory from the config file (by default the software thinks that the data folder with the genome and the genes files is located where config is, so it's necessary to give it the correct path).

ctrl + D #terminate the script
ctrl + D #terminate the screen

```

##3: Annotate the VCF.
```{r Annotate using SnpEff, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/
screen -S ${CALLING}
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
script ${CALLING}-polarizedfixed.lr_ann.log
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd $O_PATH #run this code from the directory where the config is located.
java -Xmx16g -jar $S_PATH/snpEff.jar LYANCESTRAL.23 -v -s $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.html -csvStats $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.csv -interval $C_PATH/data/LYPA23C.CDS.GENE_promoters.GENE_introns.UTRs.ncRNA.lncRNA.lncRNA_introns.lncRNA_promoters.UCNE.intergenic.nr.bed $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.vcf > $V_PATH/$CALLING/TCRLP_polarizedfixed/${CALLING}_polarizedfixed.lr_ann.vcf #run this code from the directory where the config is located.

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
grep -v '#' "${CALLING}_polarizedfixed.lr_ann.vcf" | wc -l 
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671526
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov (XL nr filtered) 5783764
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov (XL nr filtered) 5839239
#c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov (XL nr filtered) 6312383

```

##4: Filter the annotated VCF. 
###Subset the VCF files in order to keep only good quality biallelic SNP variants.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_filtered_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
#The following short loop defines the OTHER variable as the opposite of the TYPE variable (SNP or INDEL)
if [ $TYPE = "SNP" ]
  then
  OTHER=(INDEL)
elif [ $TYPE = "INDEL" ]
  then
  OTHER=(SNP)
fi

if [ $TYPE != "SNP" ] && [ $TYPE != "INDEL" ] #Don't apply filters if $TYPE is invalid
  then
  echo "Invalid value for variable TYPE"
  echo "Filtering aborted"
  else #Apply filters if $TYPE is valid
  echo "Initializing filtering for $TYPE variants"
  
  if [ -f ${CALLING}"_polarized_filtered1.lr_ann.vcf" ] #Since filter 1 is common for both types of variants, skip it if it's been performed before
    then
    echo "Repetitive and low mappability regions already filtered out"
    echo "Skipping this step"
    else
    #Filter 1: Remove repetitive regions and those with low mappability:
    echo "Filtering out repetitive and low mappability regions"
    bedtools subtract -a ${CALLING}_polarizedfixed.lr_ann.vcf -b /GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/repeats_and_lowcomp_no_redundant_mappability.k75_lessthan90.bed -header | uniq > ${CALLING}_polarized_filtered1.lr_ann.vcf
    
    grep -v '#' ${CALLING}"_polarized_filtered1.lr_ann.vcf" | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov (XL nr filtered) 5671908
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 5783764
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 5839239
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 6312383
    #If the file has more than the unfiltered one it's due to some weird behaviour of bedtools subtract with some INDELs that become duplicated. These will be removed in the subsequent step.

  fi
  #Filter 2: During this step, all multiallelic variants as well as all variants from the other type (SNPs/INDELs) will be dropped from the respective VCFs.
  echo "Filtering out multiallelic variants and $OTHER variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -selectType ${TYPE} \
  -restrictAllelesTo BIALLELIC \
  -R $REF \
  -V ${CALLING}"_polarized_filtered1.lr_ann.vcf" \
  -o ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4782660
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4865867
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4907765
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5237095
  
  #Filter 3: Remove polarized fixed variants (AF=0 or AF=1) or those that weren't polarizable (AA different from either REF or ALT):
  echo "Filtering out non-polarizable and fixed variants"
  $BCF view -e '(INFO/AA!=REF & INFO/AA!=ALT) | INFO/AF=0.00 | INFO/AF=1.00' ${CALLING}"_polarized_filtered2_"${TYPE}".lr_ann.vcf" > ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4676648
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4758637
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4798043
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 5103863
  
  #Filter 4: Apply GATK's recommended hard-filters, and then some.
  echo "Filtering out low quality and unreliable variants"
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -select "QUAL >= 30 && QD >= 2.0 && FS <= 60.0 && MQ >= 40.0 && MQRankSum >= -12.5 && ReadPosRankSum >= -8.0" \
  -R $REF \
  -V ${CALLING}"_polarized_filtered3_"${TYPE}".lr_ann.vcf" \
  -o ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4548968
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4555453
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4565640
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4710686
  
  #Filter 5: For each species exclude those positions that have more than 15% missing genotypes (i.e. that have low depth in any dataset).
  echo "Filtering out high missingness variants"
  $BCF filter -e "F_MISSING > 0.15" -Ov -o ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf" ${CALLING}"_polarized_filtered4_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4332653
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4420467
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4439054
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4617432
  
  #Filter 6: Finally, exclude sites that have low depth globally.
  echo "Filtering out low depth variants"
  $BCF filter -e "DP < 200" -Ov -o ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" ${CALLING}"_polarized_filtered5_"${TYPE}".lr_ann.vcf"
  
  grep -v '#' ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" | wc -l 
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 4241437
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 4391212
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 4412177
  #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nmNnmN_origcov 4602025
fi

```

###Separate variants and substitutions.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_separate_variants_substitutions_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)

if [[ $CALLING == "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3"* ]] #the double brackets turns the test into a regex
  then
    for s in ${SPECIES[@]}
      do
      echo "retrieving 1 and 0 positions from ${s}"
      bcftools query -l "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf | cut -c1-12 | sort | uniq | grep "${s}" > "${s}"_samples.txt
      N_SAMPLES=$(cat "${s}"_samples.txt | wc -l)
      #AF_THRES=$(echo "scale=4; ($N_SAMPLES*2-2)/($N_SAMPLES*2)" | bc)
      bcftools view -S "${s}"_samples.txt "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf | bcftools view -i "AC/AN = 0 | AC/AN = 1" -Ov -o "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf #grab only those positions that have AF=0 or AF~1 (more exactly, AF>(num_alleles-2)/num_alleles, i.e. at most one ancestral allele). Use AC/AN instead of AF since the latter isn't recalculated for the subset of samples
      grep -v '#' "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".vcf | cut -f1,2 | awk '{printf ("%s\t%s\t%s\n", $1, $2-1, $2)}' >  "${CALLING}"_"${s}"_1_and_0_positions_"$TYPE".bed
      echo "${s} 1 and 0 positions retrieved"
      done
    bedtools intersect -a *c_lp_1_and_0_positions_"$TYPE".bed -b *c_ll_1_and_0_positions_"$TYPE".bed > "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed #inner join (retrieves only positions that have AF=0 or AF=1 in both species simultaneously, dropping from both species those that are variable within any)
    bedtools intersect -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_substitutions_"$TYPE".lr_ann.vcf
    echo "substitutions retrieved"
    bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header > "${CALLING}"_polarized_variants_"$TYPE".lr_ann.vcf
    echo "variants retrieved"
    grep -v '#' "${CALLING}"_polarized_substitutions_"$TYPE".lr_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 1382501
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 1421816
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 1420110
    grep -v '#' "${CALLING}"_polarized_variants_"$TYPE".lr_ann.vcf | wc -l
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 2858936
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 2969396
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm3nm3_origcov 2992067
    #bedtools subtract -a "${CALLING}"_polarized_filtered6_"$TYPE".lr_ann.vcf -b "${CALLING}"_joined_1_and_0_positions_"$TYPE".bed -header | grep -v '#' | wc -l #sanity check that counts the number of discarded variants. This number should equal the difference between _filtered6 (not anymore, now filtered6 is a different thing) and _substitutions. It is for both treatments:
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_samecov 70598
    #c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov 65219
    else
    echo "the code for this calling hasn't been written yet"
  fi

```

###Separate segregating and fixed sites. These are defined at the species level.
```{r Filter the annotated VCF, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov) #write down name of the calling
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${TYPE}"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}
script "${CALLING}_polarized_separate_segregating_fixed_${TYPE}.lr_ann.log"
CALLING=${STY#*.}
CALLING=${CALLING%-*}
TYPE=${STY#*-}

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
POPS=$(echo $CALLING | fold -w8 | cut -c1-7 | head -n$N_POPS | sort | uniq)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
FILE=$(echo ${CALLING}_polarized_filteredall_varssubs_${TYPE}.lr_ann.vcf) #This file was generated in section 11 after applying the per dataset depth filtering to the varssubs file.
echo "input file is" $FILE

if [[ $CALLING == "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3"* ]] #the double brackets turns the test into a regex
  then
  for s in ${SPECIES[@]}
    do
    bcftools query -l $FILE | cut -c1-12 | sort | uniq | grep ${s} > ${s}_samples.txt
    echo "retrieving derived varssubs positions for species" $s
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V $FILE \
    -o ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf \
    -env \
    --sample_file ${s}_samples.txt
    VARSSUBS_N=$(grep -v '#' ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf | wc -l) #
    echo "varssubs total is" $VARSSUBS_N
    echo "retrieving derived segregating positions for species" $s
    bcftools view -i "AC/AN > 0 & AC/AN < 1" ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf -Ov -o ${s}_${NM_COV}_persp_segregating_${TYPE}.lr_ann.vcf
    SEGR_N=$(grep -v '#' ${s}_${NM_COV}_persp_segregating_${TYPE}.lr_ann.vcf | wc -l) #
    echo "segregating total is" $SEGR_N
    echo "retrieving derived fixed positions for species" $s
    bcftools view -i "AC/AN = 1" ${s}_${NM_COV}_persp_varssubs_${TYPE}.lr_ann.vcf -Ov -o ${s}_${NM_COV}_persp_fixed_${TYPE}.lr_ann.vcf
    FIXED_N=$(grep -v '#' ${s}_${NM_COV}_persp_fixed_${TYPE}.lr_ann.vcf | wc -l) #
    echo "fixed total is" $FIXED_N
    done
  else
  echo "the code for this calling hasn't been written yet"
fi

```

##5: Obtain per dataset VCFs.
###For varssubs, variants and substitutions. All of these should be filtered next.
```{r Obtain per dataset VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perdataset_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

#Define input variant:
if [ $VAR == "varssubs" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf")
elif [ $VAR == "variants" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_variants_"${TYPE}".lr_ann.vcf")
elif [ $VAR == "substitutions" ]
  then
  INPUT_FILE=$(echo ${CALLING}"_polarized_substitutions_"${TYPE}".lr_ann.vcf")
else
  INPUT_FILE=()
fi
echo $INPUT_FILE

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
for j in ${DATASETS[@]}
  do
  echo "${j}"
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${j}"_samples
  mkdir -p "${j}"_"${NM_COV}"_perdataset
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V $INPUT_FILE \
  -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" \
  -env \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  grep -v '#' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" | wc -l #
  done

```

###For segregating and fixed (true variants and substitutions). These come from the already filtered varssubs, so steps 6 and 7 should be skipped. Go straight to step 8 after this.
```{r Obtain per dataset VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perdataset_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed

for j in ${DATASETS[@]}
  do
  echo ${j}
  SPECIES=$(echo ${j} | cut -c1-4)
  INPUT_FILE=$(echo ${SPECIES}_${NM_COV}_persp_${VAR}_${TYPE}.lr_ann.vcf)
  echo $INPUT_FILE
  cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  mkdir -p ${j}_${NM_COV}_perdataset
  java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
  -T SelectVariants \
  -R $REF \
  -V $INPUT_FILE \
  -o ${j}_${NM_COV}_perdataset/${j}_${NM_COV}_perdataset_filtered_${VAR}_${TYPE}.lr_ann.vcf \
  -env \
  --sample_file /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/${j}_samples
  grep -v '#' ${j}_${NM_COV}_perdataset/${j}_${NM_COV}_perdataset_filtered_${VAR}_${TYPE}.lr_ann.vcf | wc -l #
  done

```

##6: Depth range calculus. Obtain depth range for each species in order to filter high depth positions as part of the next section's many filterings.
###A: write ANGSD depth calculus and store it as .sh
```{r Depth range calculus, eval=FALSE, engine='bash'}

#I'll modify Maria's code to calculate depth. Since these populations are big, we'll be using Elena's captured intergenic fraction of the genome. Save it as .sh and upload it to the server.

CALLING=$(pwd | rev | cut -d'/' -f1 | cut -d'_' -f2- | rev)
POP=$(echo ${STY#*.} | cut -d'.' -f1)
DATASET=$(echo ${STY#*.} | cut -d'_' -f1,2,3)
COVERAGE=$(echo ${STY#*.} | cut -d'_' -f4)
REF="/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa"
THREADS=10
REGIONFILE="/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf"

awk -F ":|-" '{printf ("%s\n", $3-$2)}' /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_intergenic_capture/BAM_intergenic_capture_filtered/no_genes_Lypa_10000longest_center_final_slop20_dot.rf | paste -sd+ | bc

rm "$POP".bamlist
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
SAMPLES=$(cat "$DATASET"_samples)
for var in $SAMPLES; do if [ ${var} = "h_ll_pv_0223" ]; then realpath ${var}_sorted_indelrealigner_marked_sorted.nm*.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; elif [ $COVERAGE = "origcov" ] && [ -e ${var}_recal_round-1_25x.nm3.bam ]; then realpath ${var}_recal_round-1_25x.nm3.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; else realpath ${var}_recal_round-1.nm*.bam >> /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist; fi; done
cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/"$POP".bamlist
BAMLIST="$POP".bamlist

cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
OUT_NAME=/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/$POP.qc
NUMBER_IND=$(printf "%03d" `wc -l $BAMLIST | cut -f1 -d " "`)
MAXDEPTH=$(expr $NUMBER_IND \* 1000)

#Sanity checks: 
ls $BAMLIST
echo $OUT_NAME
echo $NUMBER_IND
echo $MAXDEPTH

angsd \
-P $THREADS \
-b $BAMLIST \
-ref $REF \
-out $OUT_NAME \
-uniqueOnly 1 \
-remove_bads 1 \
-only_proper_pairs 1 \
-rf $REGIONFILE \
-baq 1 \
-C 50 \
-doQsDist 1 \
-doDepth 1 \
-doCounts 1 \
-maxDepth $MAXDEPTH

#Save it in a text editor as depth_calculus_polarizedfixed.sh, upload it to the server, and chmod +x it:
mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed

scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/depth_calculus_polarizedfixed.sh dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/depth_calculus_polarizedfixed.sh

```

###B: define sample sets and run depth calculus 
```{r Depth range calculus, eval=FALSE, engine='bash'}

#Change calling variable
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)

mkdir -p /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NL=$'\n'
for i in ${DATASETS[@]}
  do
    N_SIZE0=$(cat /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered/"${i}_samples" | wc -l)
    N_SIZE=$(printf "%03d" $N_SIZE0)
    cd /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed
    screen -dmS "${i}_${COVERAGE}_n${N_SIZE}.log"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "script ${i}_${COVERAGE}_n${N_SIZE}.log$NL"
    screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "./depth_calculus_polarizedfixed.sh; exec bash$NL"
    #screen -S "${i}_${COVERAGE}_n${N_SIZE}.log" -p 0 -X stuff "exit$NL"
    done

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
mkdir -p /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_polarizedfixed
scp dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/*depthGlobal /Users/dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/${CALLING}_polarizedfixed

```

###C: compile statistics and draw graphs
```{r Depth range calculus}

calling <- "c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed"

#Now we use R to plot the depth distribution and to obtain a summary table:

library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)

##Functions:
get_mean <- function(dat) { with(dat, sum(as.numeric(freq)*value)/sum(as.numeric(freq))) }
get_sd <- function(dat) { mu <- get_mean (dat) 
with (dat, sqrt(sum(as.numeric(freq)*(value-mu)^2)/(sum(as.numeric(freq))-1))) } 

#*******************************************************************************************

my_files_depthGlobal = list.files(path = paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling),pattern="*.depthGlobal$") #"5x|GP|MG|LD"

for (i in 1:length(my_files_depthGlobal)) {
  assign(my_files_depthGlobal[i], (scan(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""), sep = " ", dec = ".")) %>% .[!is.na(.)])
  }
mean_folds = 0.95
depth_per_sample <- data.frame()

#Compute globaldepth for all populations found
#*******************************************************************************************

for (i in 1:length(my_files_depthGlobal)) {
  DF = read.table(paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],sep=""),head=F, stringsAsFactors=F, check.names=FALSE)
  freq_table_DF <- data.frame (value = 1:length (DF), freq = t(DF))
  freq_table_truncated_DF <- filter(freq_table_DF, value < (nrow(freq_table_DF)))
  #Mean depth:
  my_mean_DF <-  get_mean (freq_table_DF)
  my_mean_truncated_DF <- get_mean (freq_table_truncated_DF)
  my_sd_DF <-  get_sd (freq_table_DF)
  my_sd_truncated_DF <- get_sd (freq_table_truncated_DF)
  #Max and min depth:
  maxDepth_DF = my_mean_DF + (mean_folds * my_mean_DF)
  minDepth_DF  = my_mean_DF - (mean_folds * my_mean_DF)
  #maxDepth_truncated_DF = my_mean_truncated_DF + (mean_folds * my_sd_truncated_DF)
  maxDepth_truncated_DF = my_mean_truncated_DF + (3 * my_sd_truncated_DF)
  #minDepth_truncated_DF  = my_mean_truncated_DF - (mean_folds * my_sd_truncated_DF)
  minDepth_truncated_DF = my_mean_truncated_DF - (1 * my_sd_truncated_DF)
  #Para una o más poblaciones:
  population=unlist(strsplit(my_files_depthGlobal[i],"[.]"))[1]
  depth_per_sample <- rbind(depth_per_sample, 
                            data.frame(pop = population,
                                       mean = my_mean_DF,
                                       sd = my_sd_DF, 
                                       mean_truncated = my_mean_truncated_DF,
                                       sd_truncated = my_sd_truncated_DF,
                                       maxDepth = maxDepth_DF, 
                                       minDepth = minDepth_DF,
                                       maxDepth_truncated = maxDepth_truncated_DF,
                                       minDepth_truncated = minDepth_truncated_DF)) 
  #Plotting:
  ggplot(freq_table_truncated_DF, aes(x = value, y = freq)) + 
    geom_bar(stat = "identity", color = "black") +
    scale_x_continuous(breaks = 0:250*10, limits = c(0, maxDepth_truncated_DF*1.5)) +
    scale_y_continuous(expand=c(0,0)) +
    ggtitle (paste(my_files_depthGlobal[i],"_", mean_folds, "_",maxDepth_truncated_DF, "_",maxDepth_DF) ) +
    geom_vline(xintercept=maxDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_DF,linetype="dashed", size=0.5) + 
    geom_vline(xintercept=maxDepth_truncated_DF, colour ="grey",linetype="dashed", size=0.5) + 
    geom_vline(xintercept=minDepth_truncated_DF,colour ="grey",linetype="dashed", size=0.5) + 
    theme_classic() + 
    theme(text = element_text(size=10))
  plot_name=paste0("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",my_files_depthGlobal[i],"_",mean_folds,".pdf",sep="")
  ggsave(filename = plot_name)
}

#When finished write the table

#Results for all datasets within a calling are stored in one single dataframe:
write.table(x = depth_per_sample,file = paste("/Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/",calling,"/",calling,"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_",mean_folds,".csv", sep= ""),quote=FALSE, col.names = FALSE, row.names = FALSE, sep= " ")

```

###D: separate for each sample set
```{r Depth range calculus, eval=FALSE, engine='bash'}

#From outside the server, first upload the summary table to the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed)
scp /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv dkleinman@genomics-b.ebd.csic.es:/home/dkleinman/datos/nm_depth_calculus/$CALLING

#In the server, separate in populations:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_polarizedfixed)
cd /home/dkleinman/datos/nm_depth_calculus/$CALLING
POPS=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $1}')
for POP in ${POPS[@]}
  do
  echo $POP
  grep "${POP}" /home/dkleinman/datos/nm_depth_calculus/$CALLING/"$CALLING"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv > "$POP"_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv
  done

```

##7: Perform high-depth filtering. Obtain list of sites with very high depth within each dataset, join them, and remove those sites.
###At the dataset level:
```{r Perform depth filtering, eval=FALSE, engine='bash'}

#For each dataset obtain the list of positions that have lower (higher) depth than the minimum (maximum) within 0.95 of the distribution, as calculated in the previous section, and join them to later remove all of them from all datasets:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_datasets_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome (first eight scaffolds only)
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
for j in ${DATASETS[@]}
  do
  echo "${j}"
  #MIN_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/$CALLING/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $9}') #Obtained in section 10
  MAX_DP=$(cat /home/dkleinman/datos/nm_depth_calculus/${CALLING}_polarizedfixed/${j}_${COVERAGE}*_mean_sd_depthGlobal_nm_per_dataset_mean_folds_0.95.csv | awk '{print $8}') #Obtained in section 10
  #echo $MIN_DP
  echo $MAX_DP
  $BCF filter -i "DP > ${MAX_DP}" -Ov -o ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".lr_ann.vcf" ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf"
  sed -e 's/chr//' ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".lr_ann.vcf" | awk '{OFS="\t"; if (!/^#/){print $1,$2-1,$2}}' > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #convert from VCF to BED
  done
cat *"_"${NM_COV}"_perdataset/"*"_"${NM_COV}"_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" | bedtools sort | uniq > ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" #join all BEDs
for j in ${DATASETS[@]}
  do
  echo "${j}"
  bedtools subtract -a ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_"${VAR}"_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${j}"_"${NM_COV}"_perdataset/"${j}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf"
  done
  
```

###At the global level (run the dataset level code first):
```{r Perform depth filtering, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_depth_filter_global_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

if [ $VAR == "varssubs" ]
  then
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".lr_ann.vcf"
  else
  echo $VAR
  bedtools subtract -a ${CALLING}"_polarized_"${VAR}"_"${TYPE}".lr_ann.vcf" -b ${CALLING}"_joined_minmaxdepth_to_remove_"${VAR}"_"${TYPE}".bed" -header > ${CALLING}"_polarized_filteredall_"${VAR}"_"${TYPE}".lr_ann.vcf"
fi

```

##8: Obtain per population VCFs.
```{r Obtain per population VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "perpop_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
for i in ${DATASETS[@]}
  do
  echo "${i}"
  declare POP=$(bcftools query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" | cut -c1-7 | sort | uniq)
  for j in ${POP[@]}
    do
    echo "${j}"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    $BCF query -l ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" | grep "${j}" > ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    cat ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    mkdir -p "${j}"_"${NM_COV}"_perpop
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T SelectVariants \
    -R $REF \
    -V ${i}"_"${NM_COV}"_perdataset/"${i}"_"${NM_COV}"_perdataset_filtered_"${VAR}"_"${TYPE}".lr_ann.vcf" \
    -o ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" \
    -env \
    --sample_file ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    rm ${i}"_"${NM_COV}"_perdataset/"${i}"_"${j}"_pop_list_to_remove.txt"
    grep -v '#' ${j}"_"${NM_COV}"_perpop/"${i}"_"${j}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" | wc -l #
    done
  done

```

##9: Split the population VCFs into per individual VCFs. Generate a VCF for each individual.
###Whole-genome.
```{r Split the population VCFs into per individual VCFs, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "individual_${VAR}_${CALLING}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)

S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)
cd $V_PATH/$CALLING/TCRLP_polarizedfixed
declare POP=$(bcftools query -l ${CALLING}"_polarized_filtered6_"${TYPE}".lr_ann.vcf" | cut -c1-7 | sort | uniq)
for i in ${POP[@]}
  do
  echo "${i}"
  mkdir -p "${i}"_"${NM_COV}"_individuals
  VCF_LIST=$(ls ${i}"_"${NM_COV}"_perpop/"*"_"${i}"_"${NM_COV}"_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf")
  for j in ${VCF_LIST[@]}
    do 
    INDIVIDUALS=$(bcftools query -l "${j}" | sort | uniq)
    for k in ${INDIVIDUALS[@]}
      do
      echo "${k}"
      ID=$(echo "${k}")
      java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
      -T SelectVariants \
      -R $REF \
      -V "${j}" \
      -o ${i}"_"${NM_COV}"_individuals/"${k}"_"${NM_COV}"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" \
      -env \
      -sn $ID
      done
    done
  done

```

##10: Get counts (of variants, substitutions or vars+subs).
###All sites:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for i in "${INDLIST[@]}"
  do
  echo "${i}"
  ind=$(echo "${i}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".lr_ann.txt"
  done
rm ${VAR}_*.temp.borrar

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.lr_ann.txt

```

###No ref_warnings:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.norefwarn.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".norefwarn.lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".norefwarn.lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for n in "${INDLIST[@]}"
  do
  echo "${n}"
  ind=$(echo "${n}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  grep -v 'WARNING_REF_DOES_NOT_MATCH_GENOME' ${n} > norefwarn.temporary.vcf
  i=norefwarn.temporary.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.norefwarn.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.norefwarn.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.norefwarn.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.norefwarn.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.norefwarn.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.norefwarn.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.norefwarn.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.norefwarn.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.norefwarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".norefwarn.lr_ann.txt"
  done
rm ${VAR}_*.norefwarn.temp.borrar
rm norefwarn.temporary.vcf

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.norefwarn.lr_ann.txt

```

###No warnings:
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_ann_individual_summary_${VAR}_${TYPE}.nowarn.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
if [ $VAR == "private" ]
  then
  VAR="private_segregating"
fi
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)


S_PATH=/opt/snpEff #software path
C_PATH=/home/dkleinman/datos/snpEff #config file path
O_PATH=/home/dkleinman/datos/snpEff #output path
I_PATH=/home/GRUPOS/grupolince/immunocapture/prueba_highdiv #immunocapture path
V_PATH=/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs #VCFs path
G_PATH=/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAM files path
REF=/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

cd $V_PATH/$CALLING/TCRLP_polarizedfixed
rm ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.lr_ann.txt"
echo -e "species\tpopulation\tdataset\tsample\ttotal_V\ttotal_A\tintergenic_V\tintergenic_A\tintronic_V\tintronic_A\tcoding_V\tsynonymous_V\tsynonymous_A\tmissense_V\tmissense_A\tmissense_tol_V\tmissense_tol_A\tmissense_del_V\tmissense_del_A\tnonsense_V\tnonsense_A\tUCNE_V\tUCNE_A\tUCNE_mid_V\tUCNE_mid_A\tUCNE_high_V\tUCNE_high_A\tmissense/synonymous_V\tmissense/synonymous_A\tsynonymous/intronic_V\tmissense/intronic_V" > ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.lr_ann.txt"
INDLIST=($(ls `find . -name *"_individual_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
for n in "${INDLIST[@]}"
  do
  echo "${n}"
  ind=$(echo "${n}" | awk -F'[/]' '{print $3}' | cut -c1-12)
  echo "${ind}"
  SPECIES=$(echo "${ind}" | cut -c3-4)
  POPULATION=$(echo "${ind}" | cut -c6-7)
  DATASET=$(if [ $ind = "c_lp_sm_0221" ]; then echo "REF"; elif [ $ind = "c_ll_ki_0090" ]; then echo "MG"; elif [ $ind = "h_ll_pv_0223" ]; then echo "LD"; elif grep -Fxq $ind /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/c_lp_5x_samples || [ $SPECIES = "ll" ]; then echo "5x"; else echo "GP"; fi)
  SAMPLE=$(echo "${ind}" | cut -c9-12)
  grep -v 'WARNING' ${n} > nowarn.temporary.vcf
  i=nowarn.temporary.vcf
  TOTAL_V=$(grep -v '#' ${i} | wc -l)
  TOTAL_A=$(grep -v '#' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTERGENIC_V=$(grep 'intergenic' ${i} | wc -l)
  INTERGENIC_A=$(grep 'intergenic' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  INTRONIC_V=$(grep 'intron_variant' ${i} | wc -l)
  INTRONIC_A=$(grep 'intron_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  CODING_V=$(grep 'CDS' ${i} | wc -l)
  SYNONYMOUS_V=$(grep 'synonymous_variant' ${i} | wc -l)
  SYNONYMOUS_A=$(grep 'synonymous_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_V=$(grep 'missense_variant' ${i} | wc -l)
  MISSENSE_A=$(grep 'missense_variant' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${VAR}_mis_tol.nowarn.temp.borrar
  MISSENSE_TOL_V=$(wc -l < ${VAR}_mis_tol.nowarn.temp.borrar)
  MISSENSE_TOL_A=$(cut -f8 ${VAR}_mis_tol.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${VAR}_mis_del.nowarn.temp.borrar
  MISSENSE_DEL_V=$(wc -l < ${VAR}_mis_del.nowarn.temp.borrar)
  MISSENSE_DEL_A=$(cut -f8 ${VAR}_mis_del.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  NONSENSE_V=$(grep '|HIGH|' ${i} | wc -l)
  NONSENSE_A=$(grep '|HIGH|' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  UCNE_V=$(grep 'UCNE' ${i} | wc -l)
  UCNE_A=$(grep 'UCNE' ${i} | cut -f8 | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt2lt5.gerp.bed > ${VAR}_ucne_mid.nowarn.temp.borrar
  UCNE_MID_V=$(wc -l < ${VAR}_ucne_mid.nowarn.temp.borrar)
  UCNE_MID_A=$(cut -f8 ${VAR}_ucne_mid.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  bedtools intersect -a ${i} -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov/annotation/ucne_database/gerp_analysis/c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov.UCNE.derived_gt5.gerp.bed > ${VAR}_ucne_high.nowarn.temp.borrar
  UCNE_HIGH_V=$(wc -l < ${VAR}_ucne_high.nowarn.temp.borrar)
  UCNE_HIGH_A=$(cut -f8 ${VAR}_ucne_high.nowarn.temp.borrar | cut -d';' -f2 | cut -d'=' -f2 | paste -sd+ | bc)
  MISSENSE_SYNONYMOUS_V=$(echo "scale=4; $MISSENSE_V/$SYNONYMOUS_V" | bc)
  MISSENSE_SYNONYMOUS_A=$(echo "scale=4; $MISSENSE_A/$SYNONYMOUS_A" | bc)
  SYNONYMOUS_INTRONIC_V=$(echo "scale=4; $SYNONYMOUS_V/$INTRONIC_V" | bc)
  MISSENSE_INTRONIC_V=$(echo "scale=4; $MISSENSE_V/$INTRONIC_V" | bc)
  echo -e "$SPECIES\t$POPULATION\t$DATASET\t$SAMPLE\t$TOTAL_V\t$TOTAL_A\t$INTERGENIC_V\t$INTERGENIC_A\t$INTRONIC_V\t$INTRONIC_A\t$CODING_V\t$SYNONYMOUS_V\t$SYNONYMOUS_A\t$MISSENSE_V\t$MISSENSE_A\t$MISSENSE_TOL_V\t$MISSENSE_TOL_A\t$MISSENSE_DEL_V\t$MISSENSE_DEL_A\t$NONSENSE_V\t$NONSENSE_A\t$UCNE_V\t$UCNE_A\t$UCNE_MID_V\t$UCNE_MID_A\t$UCNE_HIGH_V\t$UCNE_HIGH_A\t$MISSENSE_SYNONYMOUS_V\t$MISSENSE_SYNONYMOUS_A\t$SYNONYMOUS_INTRONIC_V\t$MISSENSE_INTRONIC_V" >> ${CALLING}"_ann_individual_summary_"${VAR}"_"${TYPE}".nowarn.lr_ann.txt"
  done
rm ${VAR}_*.nowarn.temp.borrar
rm nowarn.temporary.vcf

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_individual_summary_TCRLP_${VAR}_${TYPE}.nowarn.lr_ann.txt

```

##11: Calculate population averages.
```{r Get annotation statistics, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed

#First, generate some headers and info files.
head -n1 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | head -n1) | cut -f-27 > ind_headers.txt #Retrieve headers for files with individuals
cut -f2,5- ind_headers.txt > pop_headers.txt #Retrieve headers for files with populations
tail -n+2 <$(ls ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | head -n1) | cut -f-4 > ids.txt #Retrieve first 4 columns with individual data

#Next, obtain the population average for the empirical data (5x only!!):
cat pop_headers.txt <(gawk '$3=="5x" {N[$2]++; for (i=5;i<=NF;i++) {sum[$2"."i] += $i};} END {for (p in N) {printf "%s\t", p; for (i=5;i<NF;i++) printf("%.3f\t",sum[p"."i]/N[p]); printf("%.3f\n",sum[p"."NF]/N[p]);}}' <(tail -n+2 ${CALLING}_ann_individual_summary_${VAR}_${TYPE}.lr_ann.txt | cut -f-27)) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt

cut -f1 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | tail -n+2 > pops.txt #Retrieve column with population data

#In order to relativise by the Kirov population average, divide the population average by the Kirov empirical population averages:
cat pop_headers.txt <(paste pops.txt <(cat <(grep 'ki' ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | cut -f2-) <(tail -n+2 ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean.lr_ann.txt | cut -f2-) | awk 'BEGIN {OFS = "\t"} NR == 1 {cols = split($0,m);next} NF == cols {for (i=1; i<=NF; i++) $i = sprintf ("%.5f", $i/m[i])}1')) > ${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt


#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(varssubs) #varssubs #variants #substitutions #segregating #fixed #private_segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-a.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/${CALLING}_ann_5xpopulation_average_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/${CALLING}_ann_5xpopulation_average_TCRLP_${VAR}_${TYPE}.empirmean_ki_rel.lr_ann.txt

```

##12. Plot counts.
###Derived allele counts relative to Kirov.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
variants_and_subst_wg <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_individual_summary_TCRLP_",type,"_SNP.lr_ann.txt")) %>% select(.,species,population,dataset,sample,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) 

variants_and_subst_wg$dataset <- as.factor(variants_and_subst_wg$dataset)
variants_and_subst_wg$dataset = factor(variants_and_subst_wg$dataset,levels=c("REF","GP","5x","MG")) #Reorder factor levels to: REF, GP, 5x, MG
variants_and_subst_wg$population = factor(variants_and_subst_wg$population,levels=c("ki","no","po","sm","do"))
print.data.frame(variants_and_subst_wg)

variants_and_subst_wg_alleleR <- variants_and_subst_wg %>% gather(ratio,value,-species,-population,-dataset,-sample,factor_key=T)
variants_and_subst_wg_alleleR

r_average_vector <- c()
for (r in unique(variants_and_subst_wg_alleleR$ratio)) {
  print(r)
  r_average <- filter(variants_and_subst_wg_alleleR,r==ratio & population=="ki") %>% select(value) %>% unlist(.,use.names=F) %>% mean()
  r_average_vector <- c(r_average_vector,rep(r_average,nrow(filter(variants_and_subst_wg_alleleR,r==ratio))))
}
print(r_average_vector)

relativised_variants_and_subst_wg_alleleR <- mutate(variants_and_subst_wg_alleleR, ki_relative_value=value/r_average_vector)

#Obtain per population averages and standard errors:
se <- function(x) sqrt(var(x)/length(x)) #first define the standard error function

average_relativised_variants_and_subst_wg_alleleR <- data_frame("species"=character(0),"population"=character(0),"ratio"=character(0),"avg_ki_relative_value"=character(0),"se_ki_relative_value"=character(0)) #next, create the empty dataframe

for (pop in unique(relativised_variants_and_subst_wg_alleleR$population)) { #then loop over each population and feature to get the (relativised) mean and standard error, and feed the dataframe
  print(pop)
  species <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(species) %>% unlist(.,use.names=F) %>% unique()
  for (r in unique(relativised_variants_and_subst_wg_alleleR$ratio)) {
    print(r)
    pop_mean <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% mean()
    #print(paste0(pop," feature ",r," average is ",pop_mean))
    pop_se <- filter(relativised_variants_and_subst_wg_alleleR,ratio==r & population==pop) %>% select(ki_relative_value) %>% unlist(.,use.names=F) %>% se()
    #print(paste0(pop," feature ",r," std error is ",pop_se))
    row_data <- cbind(species,pop,r,pop_mean,pop_se)
    colnames(row_data) <- c("species","population","ratio","avg_ki_relative_value","se_ki_relative_value")
    average_relativised_variants_and_subst_wg_alleleR <- rbind(average_relativised_variants_and_subst_wg_alleleR,row_data,stringsAsFactors=F)
  }
}
average_relativised_variants_and_subst_wg_alleleR$population = factor(average_relativised_variants_and_subst_wg_alleleR$population,levels=c("ki","no","po","sm","do"))
levels(average_relativised_variants_and_subst_wg_alleleR$population)[levels(average_relativised_variants_and_subst_wg_alleleR$population)=="sm"] <- "an"
average_relativised_variants_and_subst_wg_alleleR$ratio = factor(average_relativised_variants_and_subst_wg_alleleR$ratio,levels=c("total","intergenic","intronic","synonymous","syn_pref","syn_unpref","missense","missense_tol","missense_del","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high"))
levels(average_relativised_variants_and_subst_wg_alleleR$ratio) <- c("total","intergenic","introns","synonymous","synonymous_pref","synonymous_unpref","missense","missense_tolerated","missense_deleterious","nonsense","UCNE","UCNE_low","UCNE_mid","UCNE_high")
average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$avg_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value <- as.numeric(average_relativised_variants_and_subst_wg_alleleR$se_ki_relative_value)
average_relativised_variants_and_subst_wg_alleleR
#(average_relativised_variants_and_subst_wg_alleleR,paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/",type,"_derived_allele_allele_ratio_relative2introns_mean.csv"))

#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.60,0.95,0.75,0.5),"max"=c(1.1,1.2,1.75,3.5),"breaks"=c(0.05,0.1,0.2,0.5))

average_relativised_derived_allele_allele_ratio_up <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('total|intergenic|introns|\\<synonymous\\>',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_up

average_relativised_derived_allele_allele_ratio_middle <- ggplot(data=filter(average_relativised_variants_and_subst_wg_alleleR,grepl('\\<missense\\>|nonsense|^UCNE$',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_middle

average_relativised_derived_allele_allele_ratio_down <- ggplot(filter(average_relativised_variants_and_subst_wg_alleleR,grepl('_tolerated|_deleterious|_mid|_high',ratio)), aes(population,avg_ki_relative_value,colour=population)) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point() +
  #geom_errorbar(aes(ymin=avg_ki_relative_value-se_ki_relative_value, ymax=avg_ki_relative_value+se_ki_relative_value), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  #ylab("Average genetic load relative to ki") +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=12,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=30,hjust=1,size=12,colour="black"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(size=12,colour="black"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA,size=1.5),
      strip.background=element_rect(colour="black",size=1.5),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
average_relativised_derived_allele_allele_ratio_down


average_relativised_derived_allele_allele_ratio_combined <- grid.arrange(set_panel_size(average_relativised_derived_allele_allele_ratio_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_middle,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(average_relativised_derived_allele_allele_ratio_down,width=unit(4.5,"cm"),height=unit(10,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))

ggsave(paste0(type,"_TCRLP_genetic_load_relative2Kirov_definitive.pdf"), width=26, height=38, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",average_relativised_derived_allele_allele_ratio_combined)

```

###Derived allele counts 5xonly manuscript version.
```{r Plot variant count results}

library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(grid)
library(gridExtra)
library(egg)

type="varssubs" #varssubs #variants #substitutions #segregating #fixed #private_segregating

wd_path <- ("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios/")
averages <- read_tsv(paste0(wd_path,"c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov_ann_5xpopulation_average_TCRLP_",type,"_SNP.empirmean_ki_rel.lr_ann.txt")) %>% select(.,population,contains("_A"),-contains("/")) %>% rename_at(vars(ends_with("_A")),funs(gsub("_A","",.))) %>% mutate(species=ifelse(population=="ki" | population=="po" | population=="no","ll","lp"),size=ifelse(population=="ki" | population=="sm","large","small"))
averages$population = factor(averages$population,levels=c("ki","no","po","sm","do"))
averages$species = factor(averages$species,levels=c("ll","lp"))
averages$size = factor(averages$size,levels=c("large","small"))
print.data.frame(averages)

averages_tidy <- averages %>% gather(ratio,value,-population,-species,-size,factor_key=T)
averages_tidy

colnames(averages_tidy) <- c("population","species","size","ratio","mean")
averages_tidy$ratio <- gsub('intronic', 'introns', averages_tidy$ratio)
averages_tidy$ratio <- gsub('coding', 'CDS', averages_tidy$ratio)
averages_tidy$ratio <- gsub('synonymous', 'syn.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_tol', 'm. tol.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('missense_del', 'm. del.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('nonsense', 'LoF', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_low', 'UCNE low', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_mid', 'UCNE mod.', averages_tidy$ratio)
averages_tidy$ratio <- gsub('UCNE_high', 'UCNE high', averages_tidy$ratio)
averages_tidy$population = factor(averages_tidy$population,levels=c("ki","po","no","sm","do"))
levels(averages_tidy$population) <- c("KIR","POL","NOR","AND","DON")
#levels(averages_tidy$population)[levels(averages_tidy$population)=="sm"] <- "an"
averages_tidy$ratio = factor(averages_tidy$ratio,levels=c("total","intergenic","introns","CDS","syn.","syn_pref","syn_unpref","missense","m. tol.","m. del.","LoF","UCNE","UCNE low","UCNE mod.","UCNE high")) 


#Separate plots:
twodecimalsFUN <- function(x) sprintf("%.2f", x)
type_range <- data.frame("var_type"=c("varssubs","varssubs","fixed","fixed"),"plot"=c("main","other","main","other"),"min"=c(0.6,0.6,0.5,0.5),"max"=c(1.2,1.5,2,4),"breaks"=c(0.1,0.1,0.2,0.5))

ggplot_up <- ggplot(data=filter(averages_tidy,grepl('total|intergenic|introns|syn\\.',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  #ggtitle(paste0("ratio of ",type," relative to synonymous and Kirov")) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.2),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_up

ggplot_middle <- ggplot(data=filter(averages_tidy,grepl('\\<missense\\>|LoF|^UCNE$',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_middle

ggplot_down <- ggplot(data=filter(averages_tidy,grepl('tol|del|mod|high',ratio)), aes(population,mean,colour=interaction(species,size),alpha=interaction(species,size))) +
  #facet_wrap(feature ~ species,nrow=6,ncol=2,scales="free") +
  facet_grid(. ~ ratio) +
  geom_point(size=0.5) +
  #geom_errorbar(aes(ymin=mean-error, ymax=mean+error), position=position_dodge(), width=0.5) +
  #ggtitle("Proportion of reads at different NM") +
  xlab("Population") +
  ylab(ifelse(type=="varssubs","Average genetic load relative to ki",ifelse(type=="fixed","Derived fixation rate relative to ki", "Check code"))) +
  scale_y_continuous(labels=twodecimalsFUN, breaks=seq(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F), filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F), by = filter(type_range,var_type==type & plot=="main") %>% select(breaks) %>% unlist(.,use.names=F)), limits=c(filter(type_range,var_type==type & plot=="main") %>% select(min) %>% unlist(.,use.names=F),filter(type_range,var_type==type & plot=="main") %>% select(max) %>% unlist(.,use.names=F))) +
  scale_colour_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
  scale_alpha_manual(values=c(1,1,0.4,0.4)) +
  theme_bw() +
  theme(text=element_text(size=9,face="bold"),
      rect=element_rect(size=1),
      axis.line=element_blank(),
      axis.title=element_text(size=16),
      axis.title.x=element_blank(),
      axis.title.y=element_blank(),
      axis.text.x=element_text(angle=45,hjust=1,colour="black",face="bold"),
      axis.text.y=element_text(colour="black",face="bold"),
      #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
      #axis.title.y=element_text(margin=unit(c(0,0.5,0,0),"cm")),
      panel.background=element_blank(),
      panel.border=element_rect(colour="black",fill=NA),
      panel.spacing.x=unit(0.075,"cm"),
      strip.background=element_rect(colour="black"),
      strip.text=element_text(size=8),
      #panel.grid=element_blank(),
      #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
      #plot.margin=unit(c(0.5,1,0.5,0.4),"cm"),
      #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
      legend.background=element_rect(linetype="solid", colour="black", size=.5),
      #legend.justification=c(0,0),
      legend.key=element_rect(colour="white"),
      legend.key.size=unit(0.5,"cm"),
      legend.position="none",
      legend.title=element_blank()
  )
ggplot_down

#New:
if(type=="varssubs") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_middle,width=unit(1.65,"cm"),height=unit(4,"cm")), set_panel_size(ggplot_down,width=unit(1.65,"cm"),height=unit(4,"cm")),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=10,fontface="bold")),left=textGrob(expression(bold("Average genomic load relative to KIR")), rot=90,gp=gpar(fontsize=10,fontface="bold"),vjust=1))
} else if (type=="fixed") {
  ggplot_combined <- grid.arrange(set_panel_size(ggplot_up,width=unit(4.5,"cm"),height=unit(10,"cm")), set_panel_size(ggplot_down,width=unit(4.5,"cm"),height=unit(10,"cm")),set_panel_size(ggplot_other,width=unit(4.5,"cm"),height=unit(10,"cm")),widths=c(4,2.3,0.2),layout_matrix=rbind(c(1,1,NA),c(2,NA,3)),bottom=textGrob(expression(bold("Population")),gp=gpar(fontsize=18,fontface="bold")),left=textGrob(expression(bold("Derived fixation rate relative to KIR")), rot=90,gp=gpar(fontsize=18,fontface="bold"),vjust=3))
}

#New:
ggsave(paste0(type,"_TCRLP_genetic_load_5xrelative2Kirov_manuscriptlike.pdf"), width=8.2, height=17, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/snpeff_summary_ratios",ggplot_combined)

```

##13: Derived allele count spectrum.
###Combine per population and feature allele count files:
```{r Calculate derived allele frequency ratio, eval=FALSE, engine='bash'}

CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
screen -S "${CALLING}-${VAR}-${TYPE}"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
script "${CALLING}_derived_counts_spectrum_${VAR}_${TYPE}.lr_ann.log"
CALLING=$(echo ${STY#*.} | cut -d'-' -f1)
VAR=$(echo ${STY#*.} | cut -d'-' -f2)
TYPE=$(echo ${STY#*.} | cut -d'-' -f3)
 
cd /GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final/BAM_nm_filtered
N_POPS=$(awk -F"_" '{print (NF-2)/3}' <<< $CALLING)
SPECIES=$(echo $CALLING | fold -w8 | cut -c1-4 | head -n$N_POPS | sort | uniq)
DATASETS=$(for i in ${SPECIES[@]}; do ls ${i}*_samples | cut -d'_' -f1,2,3; done)
COVERAGE=$(echo "${CALLING}" | rev | cut -d'_' -f1 | rev)
NM_COV=$(echo "${CALLING}" | rev | cut -d'_' -f1,2 | rev)

cd /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed
mkdir -p derived_allele_counts_spectrum
scp /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt 
GREP=$(cat derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f1)
POP_VCFS=($(ls `find . -path *"_perpop/c_*5x*_perpop_"${VAR}"_"${TYPE}".lr_ann.vcf" -print`))
rm ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
for p in ${POP_VCFS[@]}
  do
  SP_DATASET=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f1-3)
  SHORT_POP=$(echo ${p} | cut -d'/' -f3 | cut -d'_' -f4-6)
  echo "working with pop" $SHORT_POP "and vcf" $p
  echo "extracting derived allele counts from" $SHORT_POP
  for g in ${GREP[@]}
    do
    #echo "grepping: ${g}"
    FEATURE=$(grep "${g}" derived_allele_counts_spectrum/features_derived_allele_freq_ratio.txt | cut -f2)
    echo "extracting from feature:" $FEATURE
    grep "${g}" "${p}" | awk -F"\t|;|=" '{printf ("%s\t%s\t%s\t%s\n", $1,$2-1,$2,$11)}' > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}
    echo "joining frequency files"
    awk -v pop="$SHORT_POP" -v feat="$FEATURE" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
    if [ $FEATURE == "NSYN" ]
      then
      FEATURE2=(NTOL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/provean/missense_variants_provean_scores_tolerated.txt > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE2}_${TYPE}.lr_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE2"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
      FEATURE2=(NDEL)
      echo "extracting from feature:" $FEATURE2
      bedtools intersect -a <(awk -F"\t|_" '{printf ("%s\t%s\t%s\t%s\n", $1,$2,$3,$4)}' ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE}_${TYPE}.lr_ann.ac}) -b /GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/annotation/provean/missense_variants_provean_scores_deleterious.txt > ${p/perpop_${VAR}_${TYPE}.lr_ann.vcf/perpop_${VAR}_${FEATURE2}_${TYPE}.lr_ann.ac}
      echo "joining frequency files"
      awk -v pop="$SHORT_POP" -v feat="$FEATURE2" '{print pop,feat,$0}' OFS="\t" $SHORT_POP"_"$NM_COV"_perpop"/$SP_DATASET"_"$SHORT_POP"_"$NM_COV"_perpop_"$VAR"_"$FEATURE2"_"$TYPE".lr_ann.ac" >> ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac"
    fi
    done
  done


#Generate version with consistent polarised sites only.
bedtools intersect -a <(awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $3,$4,$5,$6,$1,$2)}' ${CALLING}"_5x_perpop_ALL_features_"${VAR}"_"${TYPE}".lr_ann.ac") -b /GRUPOS/grupolince/copia_fabascal/MAPPINGS/with_rufus_dani/consistent_ancestral_state_tiger_cat_lynxrufus_lynxlynx_lynxpardinus.sorted.dani_variants.bed | awk -F"\t" '{printf ("%s\t%s\t%s\t%s\t%s\t%s\n", $5,$6,$1,$2,$3,$4)}' > ${CALLING}"_5x_perpop_ALL_features_consistent_"${VAR}"_"${TYPE}".lr_ann.ac"

#From outside the server:
CALLING=(c_lp_sm_c_lp_do_c_ll_ki_c_ll_no_c_ll_po_nm2nm3_origcov)
VAR=(segregating) #varssubs #variants #substitutions #segregating
TYPE=(SNP) #write down SNP or INDEL
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/*5x_perpop_ALL_features_${VAR}_${TYPE}.lr_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/
scp dkleinman@genomics-b.ebd.csic.es:/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani/nmVCFs/$CALLING/TCRLP_polarizedfixed/*5x_perpop_ALL_features_consistent_${VAR}_${TYPE}.lr_ann.ac /Users/Dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/

```

###Plot spectra:
####Whole dataset.
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP", pattern="*ALL_features*"),pattern='consistent', invert=T, value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- data_frame("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP")
  }
}

```

####Consistent polarisation only:
```{r}

library(readr)
library(dplyr)
library(ggplot2)

callings_ac_files <- grep(list.files("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP", pattern="*ALL_features*"),pattern='consistent', value=T)

#var_type <- c("varssubs","variants","substitutions")
var_type <- c("segregating")

for (type in var_type) {
  print(type)
  all_plot_data <- tibble("pop"=character(0),"feat"=factor(0),"ac"=double(0),"n"=numeric(0),"n_bis"=numeric(0))
  calling_ac <- read_tsv(paste0("/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/",callings_ac_files[grep(type,callings_ac_files)]),col_names=c("pop","feat","sc","start","stop","ac"))
  pop_size_data <- data_frame("pop"=unique(calling_ac$pop)) %>% mutate(size=ifelse(pop=="c_ll_ki" | pop=="c_lp_sm",12,8))
  min_size <- min(pop_size_data$size)
  for (p in unique(calling_ac$pop)) {
    print(p)
    p_size <- pop_size_data[which(pop_size_data$pop==p),2] %>% unlist(use.names=F)
    pop_ac_data <- filter(calling_ac,pop==p)
    #popsize=ifelse(p=="c_lp_sm"|p=="c_ll_ki",12,8)
    pop_plot_data <- pop_ac_data %>% group_by(ac,feat) %>% summarize(n=n(),pop=pop[n]) %>% arrange(feat) %>% mutate(n_bis=n*p_size/min_size) %>% select(pop,feat,ac,n,n_bis) %>% as.data.frame(.)
    #pop_ac_data %>% mutate(ac_groups=cut(ac,breaks=seq(0,1.1,by=1/(2*popsize)))) %>% group_by(ac_groups,feat) %>% summarize(n=n()) #problem with the binning due to rounded allele frequencies
    all_plot_data <- rbind(all_plot_data,pop_plot_data)
    }
  all_plot_data$feat <- as.factor(all_plot_data$feat)
  all_plot_data$feat = factor(all_plot_data$feat,levels=c("INTER","INTR","SYN","NSYN","NTOL","NDEL","LOF","UCNE")) #Reorder factor levels.
  levels(all_plot_data$feat) <- c("intergenic","introns","syn.","missense","m. tol.","m. del.","LoF","UCNE")
  all_plot_data$pop = factor(all_plot_data$pop,levels=c("c_ll_ki","c_ll_po","c_ll_no","c_lp_sm","c_lp_do")) #Reorder factor levels.
  levels(all_plot_data$pop) <- c("KIR","POL","NOR","AND","DON")
  all_plot_data <- all_plot_data %>% arrange(pop,feat,ac) %>% mutate(species=ifelse(pop=="KIR" | pop=="POL" | pop=="NOR","ll","lp"),size=ifelse(pop=="KIR" | pop=="AND","large","small"))
  all_plot_data$species = factor(all_plot_data$species,levels=c("ll","lp"))
  all_plot_data$size = factor(all_plot_data$size,levels=c("large","small"))
  all_plot_data
  
  all_nbis_ggplot <- ggplot(data=all_plot_data,aes(ac,n_bis,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue4","indianred4","steelblue4","indianred4")) +
    scale_alpha_manual(values=c(1,1,0.4,0.4)) +
    scale_x_continuous(breaks=seq(4,24,by=4)) +
    theme_bw() +
    theme(text=element_text(size=9,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=10),
          axis.text.x=element_text(colour="black",face="bold"),
          axis.text.y=element_text(colour="black",face="bold"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          panel.spacing=unit(0.075,"cm"),
          strip.background=element_rect(colour="black"),
          strip.text=element_text(size=8),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          #plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_nbis_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_consistent_nbis.pdf"), width=16.9, height=24, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

    all_n_ggplot <- ggplot(data=all_plot_data,aes(ac,n,fill=interaction(species,size),alpha=interaction(species,size))) +
    geom_col() +
    facet_grid(feat~pop,scales="free",space="free_x") +
    #ggtitle(paste(type,"derived allele counts spectrum")) +
    ylab("Number of sites") +
    xlab("Derived allele count") +
    scale_fill_manual(values=c("steelblue3","indianred3","steelblue3","indianred3")) +
    scale_alpha_manual(values=c(1,1,0.5,0.5)) +
    theme_bw() +
    theme(text=element_text(size=14,face="bold"),
          rect=element_rect(size=1),
          axis.line=element_line(colour="black"),
          axis.title=element_text(size=18),
          axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
          axis.text.y=element_text(size=14,colour="black"),
          #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
          panel.background=element_blank(),
          panel.border=element_rect(colour="black"),
          strip.background=element_rect(colour="black",size=1.5),
          strip.text=element_text(size=14),
          panel.grid=element_blank(),
          #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
          plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
          #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
          legend.background=element_rect(linetype="solid", colour="black", size=.5),
          #legend.justification=c(0,0),
          legend.key=element_rect(colour="white"),
          #legend.key.size=unit(1.3,"cm"),
          legend.position="none",
          legend.title=element_blank()
    )
    all_n_ggplot
    ggsave(paste0(type,"_ALL_derived_allele_counts_spectrum_consistent_n.pdf"), width=30, height=40, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")

  for (f in unique(all_plot_data$feat)) {
    feat_nbis_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n_bis,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_nbis_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_consistent_nbis.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
    
    feat_n_ggplot <- ggplot(data=filter(all_plot_data,feat==f),aes(ac,n,fill=pop)) +
      geom_col() +
      facet_grid(~pop,scales="free_x",space="free_x") +
      ggtitle(paste(type,f,"derived allele counts spectrum")) +
      ylab("N") +
      xlab("AC") +
      theme_bw() +
      theme(text=element_text(size=14,face="bold"),
            rect=element_rect(size=1),
            axis.line=element_line(colour="black"),
            axis.title=element_text(size=18),
            axis.text.x=element_text(angle=30,hjust=1,size=14,colour="black"),
            axis.text.y=element_text(size=14,colour="black"),
            #axis.title.y=element_text(size=30,margin=margin(r=0.5,unit="cm")),
            panel.background=element_blank(),
            panel.border=element_rect(colour="black"),
            strip.background=element_rect(colour="black",size=1.5),
            strip.text=element_text(size=14),
            panel.grid=element_blank(),
            #panel.grid.major=element_line(colour="grey", linetype="dashed", size=0.4),
            plot.margin=unit(c(0.5,1,0.5,0.5),"cm"),
            #plot.title=element_text(size=36, face="bold", margin=margin(b=0.5, unit="cm")),
            legend.background=element_rect(linetype="solid", colour="black", size=.5),
            #legend.justification=c(0,0),
            legend.key=element_rect(colour="white"),
            #legend.key.size=unit(1.3,"cm"),
            legend.position="none",
            legend.title=element_blank()
      )
      feat_n_ggplot
      ggsave(paste0(type,"_",f,"_derived_allele_counts_spectrum_consistent_n.pdf"), width=30, height=8, units="cm", device="pdf", path="/Users/dani/ownCloud/backup/g-w_analysis/genetic_load/derived_allele_counts_spectrum/TCRLP/")
  }
}

```
