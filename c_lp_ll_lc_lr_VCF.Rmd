---
title: "c_lp_ll_VCF"
author: "Dani"
date: "20 de febrero de 2018"
output: html_document
---


#0a: Define paths.

```{r Define paths, eval=FALSE, engine='bash'}

B_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/BAM_files_final #BAMs path
G_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/gVCFs #gVCFs path
V_PATH=/home/GRUPOS/grupolince/lynx_genomes_5x/VCFs_Dani #VCFs path
REF=/home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/lp23.fa #path to reference genome
GATK=/opt/GATK-3.7/GenomeAnalysisTK.jar #GATK software path
BCF=/opt/bcftools-1.6/bcftools #BCFtools software path

```

#0b: Prepare reference genome. Prepare two files with data from the reference genome: a dictionary with contig names and sizes, and a fasta index file. This step should only be performed once (per reference genome).

```{r Prepare reference genome, eval=FALSE, engine='bash'}

#Karolina's code to prepare the reference genome. This should only be performed once per reference genome.
cd /home/GRUPOS/grupolince/reference_genomes/lynx_pardinus_genome/
java -jar /home/tmp/Software/Picard/picard-tools-1.66/CreateSequenceDictionary.jar \
 R=lp23.fa \
 O=lp23.dict
samtools faidx lp23.fa

```

#1a: Produce gVCF files. Perform a calling per sample to produce a gVCF file with variant information for every position in the genome (variant or not).

```{r Produce gVCF files, eval=FALSE, engine='bash'}

#We'll be using one 25x sample from each species: c_lp_sm_0298_recal_round-1_25x, c_ll_ki_0090_recal_round-1_25x, c_lc_zz_0001_recal_round-1_25x, c_lr_zz_0001_recal_round-1_25x. The gVCF for lp_sm_0298 was already created months ago as part of the following loop (in the c_lp_ll_VCF script):

cd $B_PATH/genome_project_samples_25x #this works for the 25x samples
POP=("*_lp")
for pop in ${POP[@]}
  do
  echo "${pop}"
  ls ${pop}_*_recal_round-1_25x.bam > ${pop/*_lp/lp}_recal_round-1_25x.bam.list;
  INPUT_BAMS_FOR_CALLING=($(cat ${pop/*_lp/lp}_recal_round-1_25x.bam.list)) 
  for id in ${INPUT_BAMS_FOR_CALLING[@]}
    do
    echo "${id}"
    java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar $GATK \
    -T HaplotypeCaller \
    -R $REF \
    -I ${id} \
    --emitRefConfidence GVCF \
    -o $G_PATH/genome_project_samples_25x/${id/.bam/.g.vcf.gz}
    done
  done


#The remaining three gVCFs were produced as follows:
    
#This was only used to produce the gVCF file for the original (not subsampled) Macrogen Kirov sample:
cd $B_PATH/MACROGEN_samples_25x
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T HaplotypeCaller \
    -R $REF \
    -I c_ll_ki_0090_recal_round-1_25x.bam \
    --emitRefConfidence GVCF \
    -o $G_PATH/c_ll_ki_0090_recal_round-1_25x.g.vcf.gz

#This was only used to produce the gVCF file for the original (not subsampled) Macrogen Lynx canadensis sample:
cd $B_PATH/MACROGEN_samples_25x
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T HaplotypeCaller \
    -R $REF \
    -I c_lc_zz_0001_recal_round-1_25x.bam \
    --emitRefConfidence GVCF \
    -o $G_PATH/c_lc_zz_0001_recal_round-1_25x.g.vcf.gz
    
#This was only used to produce the gVCF file for the original (not subsampled) Macrogen Lynx rufus sample:
cd $B_PATH/MACROGEN_samples_25x
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -Xms16g -Xmx32g -jar $GATK \
    -T HaplotypeCaller \
    -R $REF \
    -I c_lr_zz_0001_recal_round-1_25x.bam \
    --emitRefConfidence GVCF \
    -o $G_PATH/c_lr_zz_0001_recal_round-1_25x.g.vcf.gz

```

#1b: Perform sanity checks on gVCFs. Perform various sanity checks on all gVCFs.

```{r Perform sanity checks on gVCFs, eval=FALSE, engine='bash'}

cd $G_PATH
shopt -s extglob #the extglob shell option gives you more powerful pattern matching in the command line.
SAMPLELIST=($(ls c_*.g.vcf.gz | cut -d "." -f1 | sort | uniq))
rm c_gVCF_raw.stats
echo "sample_name,total_SNPs,homoz_ref,heteroz,homoz_alt,unaccounted" > c_gVCF_raw.stats 
for sample in "${SAMPLELIST[@]}"
  do
  echo "${sample}"
  #done
  NAME="${sample}"
  TOTAL_SNPS="$(zgrep -v '#' "$G_PATH/${sample}".g.vcf.gz | wc -l)"
  echo $TOTAL_SNPS
  TOTAL_00="$(zgrep -v '#' "$G_PATH/${sample}".g.vcf.gz | zgrep '0/0:' | wc -l)"
  echo $TOTAL_00
  TOTAL_01="$(zgrep -v '#' "$G_PATH/${sample}".g.vcf.gz | zgrep '0/1:' | wc -l)"
  echo $TOTAL_01
  TOTAL_11="$(zgrep -v '#' "$G_PATH/${sample}".g.vcf.gz | zgrep '1/1:' | wc -l)"
  echo $TOTAL_11
  UNACCOUNTED="$(($TOTAL_SNPS - $TOTAL_00 - $TOTAL_01 - $TOTAL_11))"
  echo $UNACCOUNTED
  echo "$NAME,$TOTAL_SNPS,$TOTAL_00,$TOTAL_01,$TOTAL_11,$UNACCOUNTED" >> c_gVCF_raw.stats
  done
shopt -u extglob #disable extglob

#Save locally the .stats file
scp dkleinman@genomics-b.ebd.csic.es:$G_PATH/c_gVCF_raw.stats /Users/Dani/ownCloud/backup/annotation/gVCFs_analysis/

```

#1c: Analyse the sanity checks file. Perform per individual analyses on the sanity checks file.

```{r Analyse the sanity checks file}
library("readr")
library("dplyr")
library("ggplot2")

local_repo <- file.path("/Users/Dani/ownCloud/backup/annotation/gVCFs_analysis/")

sanity_checks <- read_csv("/Users/Dani/ownCloud/backup/annotation/gVCFs_analysis/c_gVCF_raw.stats")
sanity_checks
rowSums(sanity_checks[,-c(1,2)])==sanity_checks[,2] #check if the sum of AA, AB and BB SNPs equal the total SNP count (for each individual)
pop_summary_sc <- sanity_checks %>% 
  mutate(species=substr(sanity_checks$sample_name,3,4),population=substr(sanity_checks$sample_name,6,7)) %>%
  group_by(species,population) %>%
  summarise(N=n(),mean_total_SNPs=mean(total_SNPs),mean_homoz_ref=mean(homoz_ref),mean_heteroz=mean(heteroz),mean_homoz_alt=mean(homoz_alt),mean_unaccounted=mean(unaccounted))
pop_summary_sc

plot_pop_total_SNPs <- ggplot(pop_summary_sc, aes(population,mean_total_SNPs)) + geom_col() + facet_grid(. ~ species,scales="free_x",space="free_x")
plot_pop_total_SNPs

plot_pop_heteroz <- ggplot(pop_summary_sc, aes(population,mean_heteroz)) + geom_col() + facet_grid(. ~ species,scales="free_x",space="free_x")
plot_pop_heteroz

plot_indiv_total_SNPs <- ggplot(sanity_checks, aes(x=substr(sample_name,0,12),y=total_SNPs,fill=substr(sample_name,0,7))) + geom_col() + theme(axis.text.x=element_text(angle=90,hjust=0,size=6,colour="black")) 
plot_indiv_total_SNPs

plot_indiv_heteroz <- ggplot(sanity_checks[grep("c_ll",sanity_checks$sample_name),], aes(x=substr(sample_name,0,12),y=heteroz,fill=substr(sample_name,6,7))) + 
  geom_col() +
  ggtitle("0/1 positions per sample (in gVCF)") +
  theme_bw() +
  labs(x="sample",y="N",fill="population") +
  theme(plot.title=element_text(hjust=0.5),
        axis.text.x=element_text(angle=90, hjust=0, size=6,colour="black"),
        legend.key.size=unit(0.4,"cm")
  )
plot_indiv_heteroz
ggsave("gVCFs_SNPs_per_sample.pdf", width=30, height=10, units="cm", device="pdf", path=local_repo)

```

#2a: Combine gVCF into VCF. Run joint genotyping of all desired gVCF files to produce a multisample VCF file.

```{r Combine gVCF into VCF, eval=FALSE, engine='bash'}

#Create an array with the path to all desired files:
GVCF_LIST=($G_PATH/genome_project_samples_25x/c_lp_sm_0298_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_ll_ki_0090_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_lc_zz_0001_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_lr_zz_0001_recal_round-1_25x.g.vcf.gz)

#Combine gVCF files into a VCF that conserves all sites, including non-variable sites (this will be important later on to compare callable sites and uncovered sites with total sites):
cd $G_PATH
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar $GATK \
-T GenotypeGVCFs \
-R $REF \
$(for var in ${GVCF_LIST[@]}; do echo -V ${var}" ";done) \
--includeNonVariantSites \
-o $V_PATH/c_lp_ll_lc_lr_all_sites.vcf

#Combine gVCF files into a VCF with all variant sites:
cd $G_PATH
java -XX:MaxMetaspaceSize=1g -XX:+UseG1GC -XX:+UseStringDeduplication -jar $GATK \
-T GenotypeGVCFs \
-R $REF \
$(for var in ${GVCF_LIST[@]}; do echo -V ${var}" ";done) \
-o $V_PATH/c_lp_ll_lc_lr_variant_sites.vcf

#Get the number of SNPs of the VCFs:
grep -v '#' c_lp_ll_lc_lr_all_sites.vcf | wc -l #1170283050 (con más de 24h de computación pendientes)
grep -v '#' c_lp_ll_lc_lr_variant_sites.vcf | wc -l #30079077


```

#2b: Fix sample names in the VCF.

```{r Fix sample names in the VCF, eval=FALSE, engine='bash'}

#It's important to rename those samples in the global VCF that don't have the proper name (the 3 that were sequenced at Macrogen).

#First, do it for the variants-only VCF:
cd $V_PATH
$BCF query -l c_lp_ll_lc_lr_variant_sites.vcf #checks sample names
#!/bin/bash
#cat << "EOF" > list_to_remove.txt #Unmark this line when running it (I marked it in R because it doesn't understand it and messes the colours of subsequent lines). It should include all incorrect names.
LC1_rgsm c_lc_zz_0001
LL90_rgsm c_ll_ki_0090
LR1_rgsm c_lr_zz_0001
EOF

$BCF reheader -s list_to_remove.txt -o c_lp_ll_lc_lr_variant_sites_renamed.vcf c_lp_ll_lc_lr_variant_sites.vcf #copy the VCF and rename the wrong named samples in the new VCF

cd $V_PATH
$BCF query -l c_lp_ll_lc_lr_variant_sites_renamed.vcf #checks if samples have been renamed properly


#Then, repeat it for the all-sites VCF:
cd $V_PATH
$BCF query -l c_lp_ll_lc_lr_all_sites.vcf #checks sample names
#!/bin/bash
#cat << "EOF" > list_to_remove.txt #Unmark this line when running it (I marked it in R because it doesn't understand it and messes the colours of subsequent lines). It should include all incorrect names.
LC1_rgsm c_lc_zz_0001
LL90_rgsm c_ll_ki_0090
LR1_rgsm c_lr_zz_0001
EOF

$BCF reheader -s list_to_remove.txt -o c_lp_ll_lc_lr_all_sites_renamed.vcf c_lp_ll_lc_lr_all_sites.vcf #copy the VCF and rename the wrong named samples in the new VCF

cd $V_PATH
$BCF query -l c_lp_ll_lc_lr_all_sites_renamed.vcf #checks if samples have been renamed properly

```

#3: Split the VCF into per species VCFs. Generate a VCF for the Iberian lynx and another one for the Eurasian lynx, and check whether the reference allele has changed.

```{r Split the VCF into per population VCFs, eval=FALSE, engine='bash'}

#Split the VCF in order to get one for each species. Contrary to our objective with the lp & ll VCF, here it's important to keep all substitutions.

cd $G_PATH
GVCF_LIST=($G_PATH/genome_project_samples_25x/c_lp_sm_0298_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_ll_ki_0090_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_lc_zz_0001_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_lr_zz_0001_recal_round-1_25x.g.vcf.gz)
for i in ${GVCF_LIST[@]}
  do
  echo "${i}"
  INPUT=$(echo "${i}" | cut -d$'.' -f1)
  echo $INPUT
  !!!!!CHECK HOW THE FILES ARE NAMED WITHIN THE VCF
  $BCF view -s ${i} -Ov -o $V_PATH/$INPUT.vcf $V_PATH/c_lp_ll_lc_lr_all_sites.vcf
  done

grep -v '#' c_lp_sm_0298_recal_round-1_25x.vcf | wc -l #
grep -v '#' c_ll_ki_0090_recal_round-1_25x.vcf | wc -l #
grep -v '#' c_lc_zz_0001_recal_round-1_25x.vcf | wc -l #
grep -v '#' c_lr_zz_0001_recal_round-1_25x.vcf | wc -l #

#Obtain VCF for the eurasian and the rufus:
cd $G_PATH
GVCF_LIST=($G_PATH/genome_project_samples_25x/c_lp_sm_0298_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_ll_ki_0090_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_lc_zz_0001_recal_round-1_25x.g.vcf.gz $G_PATH/macrogen_samples_25x/c_lr_zz_0001_recal_round-1_25x.g.vcf.gz)
!!!!!CHECK HOW THE FILES ARE NAMED WITHIN THE VCF
$BCF view -s c_ll_ki_0090_recal_round-1_25x.g.vcf.gz c_lr_zz_0001_recal_round-1_25x.g.vcf.gz -Ov -o $V_PATH/c_ll_ki_0090_plus_c_lr_zz_0001_recal_round-1_25x.vcf $V_PATH/c_lp_ll_lc_lr_all_sites.vcf

#Check whether the reference allele has changed between VCFs. To this end, let's compare all SNPs common to both species' variants list.
grep -v '#' $V_PATH/c_lp_sm_0298_recal_round-1_25x.vcf | cut -d$'\t' -f1,2,4,5 | awk '{print $1"_"$2" "$3" "$4}' | sort -k 1,1 > $V_PATH/c_lp_sm_0298_recal_round-1_25x_variants.txt #creates variants list for lp.
grep -v '#' $V_PATH/c_ll_ki_0090_recal_round-1_25x.vcf | cut -d$'\t' -f1,2,4,5 | awk '{print $1"_"$2" "$3" "$4}' | sort -k 1,1 > $V_PATH/c_ll_ki_0090_recal_round-1_25x_variants.txt #creates variants list for ll.
join -1 1 -2 1 -e0 -o'0,1.2,1.3,2.2,2.3' $V_PATH/c_lp_sm_0298_recal_round-1_25x_variants.txt $V_PATH/c_ll_ki_0090_recal_round-1_25x_variants.txt > c_lp_sm_0298_c_ll_ki_0090_joined_variants.txt #joins both lists and outputs only the common SNPs.
awk '{if($2 == $4) print 1; else print 0; }' c_lp_sm_0298_c_ll_ki_0090_joined_variants.txt | sort | uniq #this should only return the value "1" when all SNPs share the same reference allele, or both "0" and "1" if some SNPs have different reference alleles between species. In this case it only returns "1", so everything is fine.
cat c_lp_sm_0298_c_ll_ki_0090_joined_variants.txt | awk '{if($2 == $4) print $0" 1"; else print $0" 0"; }' c_lp_sm_0298_c_ll_ki_0090_joined_variants.txt | awk '$6 == 0' #in case there's any row where the reference allele has changed, return those rows. In this case, none are returned.

```

#4: Get substitutions between ll and lr. Build allele counts file with all positions in ll and lr, and mark all substitutions.

```{r Get substitutions between ll and lr, eval=FALSE, engine='bash'}

MODIFICAR TODO!!!

#First create the allelic counts file for Eurasian lynx (without the root):
cd $V_PATH
shopt -s extglob #the extglob shell option gives you more powerful pattern matching in the command line.
POPLIST=($(ls ll*[^pv]_perpop_standard_filter.vcf | cut -d "_" -f1,2 | sort | uniq)) #selects all populations except for País Vasco
cd $O_PATH
rm SNP_names_treemix_input.txt
SNP_LIST="$(ls "$V_PATH"/ll*_perpop_standard_filter.vcf | head -1)" #any population will be useful to retrieve the SNP list because I didn't trim the subVCFs so all populations have all the SNPs (from their species)
grep -v '#' $SNP_LIST | cut -d$'\t' -f1,2,8 | cut -d$';' -f1,3 --output-delimiter=' ' | LANG=en_EN sort -k1,1 -k2,2n | awk '{print $1"_"$2}' > SNP_names_treemix_input.txt
unset POPNAMES #removes the variable so that it starts all over again inside the loop
POPNAMES="SNP"
#echo "pop_name,total_SNPs,homoz_ref,heteroz,homoz_alt,unaccounted,unaccounted_cat" > c_VCF_raw.stats 
for pop in "${POPLIST[@]}"
  do
  echo "${pop}"
  NAME="${pop}"
  POPNAMES=$POPNAMES" "$NAME
  echo $POPNAMES
  #done
  SAMPLE_NUMBER="$(/opt/bcftools-1.6/bcftools query -l "$V_PATH/${pop}"_perpop_standard_filter.vcf | wc -l)"
  echo $SAMPLE_NUMBER
  TOTAL_SNPS="$(grep -v '#' "$V_PATH/${pop}"_perpop_standard_filter.vcf | wc -l)"
  echo $TOTAL_SNPS
  #done
  grep -v '#' "$V_PATH/${pop}"_perpop_standard_filter.vcf | cut -d$'\t' -f1,2,8 | cut -d$';' -f1,3 --output-delimiter=' ' | cut -d$'=' -f1,2,3 --output-delimiter=' ' | awk '{print $1" "$2" "$6-$4","$4}' | LANG=en_EN sort -k1,1 -k2,2n | awk '{print $1"_"$2" "$3}' > temp_SNP_counts.txt
  #LANG=en_EN join -j 1 <(LANG=en_EN sort -k1,1 -k2,2n SNP_names_treemix_input.txt | awk '{print $1"_"$2}') <(LANG=en_EN sort -k1,1 -k2,2n temp_SNP_counts.txt | awk '{print $1"_"$2" "$3}') > intermediate_file.borrar.txt
  LANG=en_EN join -j 1 SNP_names_treemix_input.txt temp_SNP_counts.txt > intermediate_file.borrar.txt
  mv intermediate_file.borrar.txt SNP_names_treemix_input.txt
  done
rm temp_SNP_counts.txt
LONGNAMES=$(echo $POPNAMES | sed -e "s/ll_ba/Balkans/g; s/ll_cr/Carpathians/g; s/ll_ka/Khentii/g; s/ll_ki/Kirov/g; s/ll_la/Latvia/g; s/ll_no/Norway/g; s/ll_og/Ömnögovi/g; s/ll_po/Bialowieza/g; s/ll_to/Töv/g; s/ll_tu/Tuva/g; s/ll_ur/Urals/g; s/ll_vl/Vladivostok/g; s/ll_ya/Yakutia/g; s/lp_sm/Sierra Morena/g; s/lp_do/Doñana/g; s/lr_zz/Rufus/g") #swaps the short names with the full names
echo $LONGNAMES
sed -i -e '1i'"$LONGNAMES"'\' SNP_names_treemix_input.txt #adds the headers
#sed -i "1s/.*/$LONGNAMES/" SNP_names_treemix_input.txt #substitutes old headers

grep -v ' 0,0 ' SNP_names_treemix_input.txt | grep -v ' 0,0$' | cut -d$' ' -f 2- | gzip > treemix_input.txt.gz #removes rows with any missing data, and also the SNP names
shopt -u extglob #disable extglob

#Get a version of the TreeMix input without Balkans:
cut -d$' ' -f2 --complement SNP_names_treemix_input.txt > SNP_names_treemix_input_wout_ba.txt #removes the Balkans column
grep -v ' 0,0 ' SNP_names_treemix_input_wout_ba.txt | grep -v ' 0,0$' | cut -d$' ' -f 2- | gzip > treemix_input_wout_ba.txt.gz #removes rows with any missing data, and also the SNP names

#Get a version of the TreeMix input that includes Lynx rufus as the outgroup:
cd $O_PATH
#LANG=en_EN sort -k1,1 -k2,2n SNP_names_treemix_input.txt
grep -v '#' $V_PATH/c_lr_SNPs.vcf | cut -d$'\t' -f1,2,8 | cut -d$';' -f1,3 --output-delimiter=' ' | cut -d$'=' -f1,2,3 --output-delimiter=' ' | LANG=en_EN sort -k1,1 -k2,2n | awk '{print $1"_"$2" "$6-$4","$4}' > c_lr_SNP_counts.txt #gets the allele counts for all variable positions within the rufus individual
sed -i -e '1i'"SNP Rufus"'\' c_lr_SNP_counts.txt #adds column names
LANG=en_EN join -a1 -e 2,0 -o auto -j 1 <(LANG=en_EN sort -k1 SNP_names_treemix_input.txt | tail -n +2) <(LANG=en_EN sort -k1 c_lr_SNP_counts.txt | tail -n +2) | cut -d$'_' -f1,2 --output-delimiter=' ' | LANG=en_EN sort -k1,1 -k2,2n | awk '{print $1"_"$2" "$3" "$4" "$5" "$6" "$7" "$8" "$9" "$10" "$11" "$12" "$13" "$14" "$15" "$16}' > intermediate_file.borrar.txt #joins the eurasian lynx allelic counts with the rufus allelic counts, assigning "2,0" for all missing positions from Rufus
LANG=en_EN join -a2 -e 'NA' -o auto -j 1 <(LANG=en_EN sort -k1 SNP_names_treemix_input.txt | tail -n +2) <(LANG=en_EN sort -k1 c_lr_SNP_counts.txt | tail -n +2) | cut -d$'_' -f1,2 --output-delimiter=' ' | LANG=en_EN sort -k1,1 -k2,2n | awk '{print $1"_"$2" "$3" "$4" "$5" "$6" "$7" "$8" "$9" "$10" "$11" "$12" "$13" "$14" "$15" "$16}' > intermediate_file_2.borrar.txt #joins the eurasian lynx allelic counts with the rufus allelic counts, assigning "NA" for all missing positions from Eurasian
LANG=en_EN join -a1 -a2 -j 1 <(LANG=en_EN sort -k1 intermediate_file.borrar.txt) <(LANG=en_EN sort -k1 intermediate_file_2.borrar.txt) | cut -d$'_' -f1,2 --output-delimiter=' ' | LANG=en_EN sort -k1,1 -k2,2n | awk '{print $1"_"$2" "$3" "$4" "$5" "$6" "$7" "$8" "$9" "$10" "$11" "$12" "$13" "$14" "$15" "$16}' > intermediate_file_joined.borrar.txt #joins both previous allelic count files in a single one with all variable positions
cp intermediate_file_joined.borrar.txt intermediate_file_joined_2.borrar.txt #duplicates the joined intermediate file
sed -i 's/NA NA NA NA NA NA NA NA NA NA NA NA NA/6,0 12,0 8,0 26,0 12,0 16,0 4,0 16,0 4,0 12,0 12,0 16,0 16,0/g' intermediate_file_joined_2.borrar.txt #replaces all rows with NA in the Eurasian fields with max allelic counts for the reference allele
mv intermediate_file_joined_2.borrar.txt SNP_names_treemix_input_rooted.txt #final name
sed -i -e '1i'"$LONGNAMES Rufus"'\' SNP_names_treemix_input_rooted.txt #adds headers with population names
grep -v ' 0,0 ' SNP_names_treemix_input_rooted.txt | grep -v ' 0,0$' | cut -d$' ' -f 2- | gzip > treemix_input_rooted.txt.gz #removes rows with any missing data, and also the SNP names
rm *.borrar.txt #removes all intermediate files

#Get a version of the rufus-rooted TreeMix input without Balkans:
cut -d$' ' -f2 --complement SNP_names_treemix_input_rooted.txt > SNP_names_treemix_input_rooted_wout_ba.txt #removes the Balkans column
grep -v ' 0,0 ' SNP_names_treemix_input_rooted_wout_ba.txt | grep -v ' 0,0$' | cut -d$' ' -f 2- | gzip > treemix_input_rooted_wout_ba.txt.gz #removes rows with any missing data, and also the SNP names

#Get a version of the rufus-rooted TreeMix input with Khentii, Töv & Ömnögovi
cut -d$' ' -f1,4,8,10  SNP_names_treemix_input_rooted.txt | cut -d$',' -f1,2,3,4 --output-delimiter=' ' | cut -d$' ' -f1,2,3,4,5,6,7 | awk '{print $1" "$2+$4+$6","$3+$5+$7}' > SNP_names_threepop_input_ka_om_to.txt #sums allele counts for the three Mongolian populations
sed -i '1s/.*/SNP Mongolia/' SNP_names_threepop_input_ka_om_to.txt #adds correct column names
awk -v f2=SNP_names_treemix_input_rooted.txt '{ c = $2; getline < f2; print $0, c; }' SNP_names_threepop_input_ka_om_to.txt > SNP_names_treemix_input_rooted_w_mo.txt #copies the Mongolia column to a new TreeMix input that includes all prior populations plus Mongolia

```
